1
00:03:09,920 --> 00:03:12,550

So, we're going to continue

2
00:03:12,550 --> 00:03:12,560
So, we're going to continue
 

3
00:03:12,560 --> 00:03:15,350
So, we're going to continue
uh where we left off. We're about a

4
00:03:15,350 --> 00:03:15,360
uh where we left off. We're about a
 

5
00:03:15,360 --> 00:03:16,550
uh where we left off. We're about a
little bit behind. So, I'm going to try

6
00:03:16,550 --> 00:03:16,560
little bit behind. So, I'm going to try
 

7
00:03:16,560 --> 00:03:18,229
little bit behind. So, I'm going to try
to finish what I wanted to cover and

8
00:03:18,229 --> 00:03:18,239
to finish what I wanted to cover and
 

9
00:03:18,239 --> 00:03:19,830
to finish what I wanted to cover and
then hand it over. So I want to finish

10
00:03:19,830 --> 00:03:19,840
then hand it over. So I want to finish
 

11
00:03:19,840 --> 00:03:22,390
then hand it over. So I want to finish
up the states self-s supervision stuff

12
00:03:22,390 --> 00:03:22,400
up the states self-s supervision stuff
 

13
00:03:22,400 --> 00:03:24,070
up the states self-s supervision stuff
and we'll switch to going back to the

14
00:03:24,070 --> 00:03:24,080
and we'll switch to going back to the
 

15
00:03:24,080 --> 00:03:25,589
and we'll switch to going back to the
statesbased model idea of how to make

16
00:03:25,589 --> 00:03:25,599
statesbased model idea of how to make
 

17
00:03:25,599 --> 00:03:29,750
statesbased model idea of how to make
recurrent things actually work in a

18
00:03:29,750 --> 00:03:29,760
recurrent things actually work in a
 

19
00:03:29,760 --> 00:03:32,550
recurrent things actually work in a
modern context.

20
00:03:32,550 --> 00:03:32,560
modern context.
 

21
00:03:32,560 --> 00:03:34,229
modern context.
So

22
00:03:34,229 --> 00:03:34,239
So
 

23
00:03:34,239 --> 00:03:37,030
So
um recall last time what we did was we

24
00:03:37,030 --> 00:03:37,040
um recall last time what we did was we
 

25
00:03:37,040 --> 00:03:39,910
um recall last time what we did was we
used this example of you know common

26
00:03:39,910 --> 00:03:39,920
used this example of you know common
 

27
00:03:39,920 --> 00:03:42,470
used this example of you know common
filtering where we have a linear system.

28
00:03:42,470 --> 00:03:42,480
filtering where we have a linear system.
 

29
00:03:42,480 --> 00:03:44,149
filtering where we have a linear system.
We know if we knew everything about it

30
00:03:44,149 --> 00:03:44,159
We know if we knew everything about it
 

31
00:03:44,159 --> 00:03:46,630
We know if we knew everything about it
how we could make the optimal estimator

32
00:03:46,630 --> 00:03:46,640
how we could make the optimal estimator
 

33
00:03:46,640 --> 00:03:49,190
how we could make the optimal estimator
for it based on the observations for the

34
00:03:49,190 --> 00:03:49,200
for it based on the observations for the
 

35
00:03:49,200 --> 00:03:51,190
for it based on the observations for the
estimating the state. But we asked the

36
00:03:51,190 --> 00:03:51,200
estimating the state. But we asked the
 

37
00:03:51,200 --> 00:03:53,589
estimating the state. But we asked the
question how could we learn that if we

38
00:03:53,589 --> 00:03:53,599
question how could we learn that if we
 

39
00:03:53,599 --> 00:03:55,750
question how could we learn that if we
had labels and then we said what could

40
00:03:55,750 --> 00:03:55,760
had labels and then we said what could
 

41
00:03:55,760 --> 00:03:57,830
had labels and then we said what could
we do if we didn't have ground truth

42
00:03:57,830 --> 00:03:57,840
we do if we didn't have ground truth
 

43
00:03:57,840 --> 00:03:59,750
we do if we didn't have ground truth
labels of the underlying state? Can you

44
00:03:59,750 --> 00:03:59,760
labels of the underlying state? Can you
 

45
00:03:59,760 --> 00:04:01,030
labels of the underlying state? Can you
still learn anything? And we said yes,

46
00:04:01,030 --> 00:04:01,040
still learn anything? And we said yes,
 

47
00:04:01,040 --> 00:04:02,710
still learn anything? And we said yes,
you could. And now we want to step back

48
00:04:02,710 --> 00:04:02,720
you could. And now we want to step back
 

49
00:04:02,720 --> 00:04:05,509
you could. And now we want to step back
and like learn from that example a more

50
00:04:05,509 --> 00:04:05,519
and like learn from that example a more
 

51
00:04:05,519 --> 00:04:08,550
and like learn from that example a more
general idea of self-supervision.

52
00:04:08,550 --> 00:04:08,560
general idea of self-supervision.
 

53
00:04:08,560 --> 00:04:11,350
general idea of self-supervision.
And so recall the basic story in

54
00:04:11,350 --> 00:04:11,360
And so recall the basic story in
 

55
00:04:11,360 --> 00:04:13,910
And so recall the basic story in
self-supervision is there's a pattern I

56
00:04:13,910 --> 00:04:13,920
self-supervision is there's a pattern I
 

57
00:04:13,920 --> 00:04:16,069
self-supervision is there's a pattern I
want to learn that I believe exists and

58
00:04:16,069 --> 00:04:16,079
want to learn that I believe exists and
 

59
00:04:16,079 --> 00:04:19,830
want to learn that I believe exists and
is visible in the data. However,

60
00:04:19,830 --> 00:04:19,840
is visible in the data. However,
 

61
00:04:19,840 --> 00:04:22,069
is visible in the data. However,
my training algorithms that I have need

62
00:04:22,069 --> 00:04:22,079
my training algorithms that I have need
 

63
00:04:22,079 --> 00:04:23,990
my training algorithms that I have need
labels to train. I need losses and

64
00:04:23,990 --> 00:04:24,000
labels to train. I need losses and
 

65
00:04:24,000 --> 00:04:26,230
labels to train. I need losses and
labels, things like this. But I don't

66
00:04:26,230 --> 00:04:26,240
labels, things like this. But I don't
 

67
00:04:26,240 --> 00:04:29,670
labels, things like this. But I don't
have any labels. So what can I do? So

68
00:04:29,670 --> 00:04:29,680
have any labels. So what can I do? So
 

69
00:04:29,680 --> 00:04:31,670
have any labels. So what can I do? So
the answer is if I don't have them and I

70
00:04:31,670 --> 00:04:31,680
the answer is if I don't have them and I
 

71
00:04:31,680 --> 00:04:33,909
the answer is if I don't have them and I
need them, I'll make them from the data

72
00:04:33,909 --> 00:04:33,919
need them, I'll make them from the data
 

73
00:04:33,919 --> 00:04:35,990
need them, I'll make them from the data
I have.

74
00:04:35,990 --> 00:04:36,000
I have.
 

75
00:04:36,000 --> 00:04:38,070
I have.
And so the lessons we learned was that

76
00:04:38,070 --> 00:04:38,080
And so the lessons we learned was that
 

77
00:04:38,080 --> 00:04:40,070
And so the lessons we learned was that
you know it is in fact possible to learn

78
00:04:40,070 --> 00:04:40,080
you know it is in fact possible to learn
 

79
00:04:40,080 --> 00:04:43,350
you know it is in fact possible to learn
a partial pattern. Uh so in the case

80
00:04:43,350 --> 00:04:43,360
a partial pattern. Uh so in the case
 

81
00:04:43,360 --> 00:04:45,670
a partial pattern. Uh so in the case
that we did before, we said look if you

82
00:04:45,670 --> 00:04:45,680
that we did before, we said look if you
 

83
00:04:45,680 --> 00:04:49,030
that we did before, we said look if you
ran this with only the um input output

84
00:04:49,030 --> 00:04:49,040
ran this with only the um input output
 

85
00:04:49,040 --> 00:04:51,110
ran this with only the um input output
behavior, you could never learn what the

86
00:04:51,110 --> 00:04:51,120
behavior, you could never learn what the
 

87
00:04:51,120 --> 00:04:52,710
behavior, you could never learn what the
actual underlying state was because

88
00:04:52,710 --> 00:04:52,720
actual underlying state was because
 

89
00:04:52,720 --> 00:04:55,350
actual underlying state was because
there's you know change of coordinates.

90
00:04:55,350 --> 00:04:55,360
there's you know change of coordinates.
 

91
00:04:55,360 --> 00:04:57,110
there's you know change of coordinates.
But you can basically learn it up to

92
00:04:57,110 --> 00:04:57,120
But you can basically learn it up to
 

93
00:04:57,120 --> 00:04:58,950
But you can basically learn it up to
change of coordinates.

94
00:04:58,950 --> 00:04:58,960
change of coordinates.
 

95
00:04:58,960 --> 00:05:01,510
change of coordinates.
Um, and we saw that you we need

96
00:05:01,510 --> 00:05:01,520
Um, and we saw that you we need
 

97
00:05:01,520 --> 00:05:03,270
Um, and we saw that you we need
scaffolding parts of the neural net that

98
00:05:03,270 --> 00:05:03,280
scaffolding parts of the neural net that
 

99
00:05:03,280 --> 00:05:05,270
scaffolding parts of the neural net that
you train, namely that artificial lay

100
00:05:05,270 --> 00:05:05,280
you train, namely that artificial lay
 

101
00:05:05,280 --> 00:05:06,950
you train, namely that artificial lay
that artificial output layer that we

102
00:05:06,950 --> 00:05:06,960
that artificial output layer that we
 

103
00:05:06,960 --> 00:05:09,510
that artificial output layer that we
created um that we needed to basically

104
00:05:09,510 --> 00:05:09,520
created um that we needed to basically
 

105
00:05:09,520 --> 00:05:11,990
created um that we needed to basically
be able to run our loss. And we saw in

106
00:05:11,990 --> 00:05:12,000
be able to run our loss. And we saw in
 

107
00:05:12,000 --> 00:05:14,629
be able to run our loss. And we saw in
the context of the sequential uh common

108
00:05:14,629 --> 00:05:14,639
the context of the sequential uh common
 

109
00:05:14,639 --> 00:05:16,870
the context of the sequential uh common
filtering type model that there's this

110
00:05:16,870 --> 00:05:16,880
filtering type model that there's this
 

111
00:05:16,880 --> 00:05:19,189
filtering type model that there's this
generic idea of next thing prediction in

112
00:05:19,189 --> 00:05:19,199
generic idea of next thing prediction in
 

113
00:05:19,199 --> 00:05:21,590
generic idea of next thing prediction in
causal sequence modeling. So if you're

114
00:05:21,590 --> 00:05:21,600
causal sequence modeling. So if you're
 

115
00:05:21,600 --> 00:05:23,510
causal sequence modeling. So if you're
trying to predict something and you

116
00:05:23,510 --> 00:05:23,520
trying to predict something and you
 

117
00:05:23,520 --> 00:05:25,510
trying to predict something and you
believe there's a causal pattern, you

118
00:05:25,510 --> 00:05:25,520
believe there's a causal pattern, you
 

119
00:05:25,520 --> 00:05:27,590
believe there's a causal pattern, you
can try to predict the next thing and

120
00:05:27,590 --> 00:05:27,600
can try to predict the next thing and
 

121
00:05:27,600 --> 00:05:28,950
can try to predict the next thing and
hope that you can catch something from

122
00:05:28,950 --> 00:05:28,960
hope that you can catch something from
 

123
00:05:28,960 --> 00:05:30,710
hope that you can catch something from
that. It's very natural in the common

124
00:05:30,710 --> 00:05:30,720
that. It's very natural in the common
 

125
00:05:30,720 --> 00:05:32,790
that. It's very natural in the common
filtering setting. It comes out of the

126
00:05:32,790 --> 00:05:32,800
filtering setting. It comes out of the
 

127
00:05:32,800 --> 00:05:34,390
filtering setting. It comes out of the
ideas of system editification more

128
00:05:34,390 --> 00:05:34,400
ideas of system editification more
 

129
00:05:34,400 --> 00:05:37,029
ideas of system editification more
generally in control, but it's more

130
00:05:37,029 --> 00:05:37,039
generally in control, but it's more
 

131
00:05:37,039 --> 00:05:39,029
generally in control, but it's more
broadly useful.

132
00:05:39,029 --> 00:05:39,039
broadly useful.
 

133
00:05:39,039 --> 00:05:41,270
broadly useful.
So what I want to do is I mentioned this

134
00:05:41,270 --> 00:05:41,280
So what I want to do is I mentioned this
 

135
00:05:41,280 --> 00:05:42,870
So what I want to do is I mentioned this
last time is I want to step back and

136
00:05:42,870 --> 00:05:42,880
last time is I want to step back and
 

137
00:05:42,880 --> 00:05:44,230
last time is I want to step back and
connect on supervised learning in

138
00:05:44,230 --> 00:05:44,240
connect on supervised learning in
 

139
00:05:44,240 --> 00:05:47,350
connect on supervised learning in
classical ML. And recall there's two

140
00:05:47,350 --> 00:05:47,360
classical ML. And recall there's two
 

141
00:05:47,360 --> 00:05:49,670
classical ML. And recall there's two
things that you learned about. Um

142
00:05:49,670 --> 00:05:49,680
things that you learned about. Um
 

143
00:05:49,680 --> 00:05:51,990
things that you learned about. Um
there's dimensionality reduction and

144
00:05:51,990 --> 00:05:52,000
there's dimensionality reduction and
 

145
00:05:52,000 --> 00:05:53,510
there's dimensionality reduction and
clustering.

146
00:05:53,510 --> 00:05:53,520
clustering.
 

147
00:05:53,520 --> 00:05:55,749
clustering.
Uh you also learned possibly about

148
00:05:55,749 --> 00:05:55,759
Uh you also learned possibly about
 

149
00:05:55,759 --> 00:05:57,350
Uh you also learned possibly about
density estimation and we also mentioned

150
00:05:57,350 --> 00:05:57,360
density estimation and we also mentioned
 

151
00:05:57,360 --> 00:05:59,029
density estimation and we also mentioned
before that generative modeling is a

152
00:05:59,029 --> 00:05:59,039
before that generative modeling is a
 

153
00:05:59,039 --> 00:06:00,550
before that generative modeling is a
kind of unsupervised learning but we're

154
00:06:00,550 --> 00:06:00,560
kind of unsupervised learning but we're
 

155
00:06:00,560 --> 00:06:03,510
kind of unsupervised learning but we're
not going to engage with that part here.

156
00:06:03,510 --> 00:06:03,520
not going to engage with that part here.
 

157
00:06:03,520 --> 00:06:05,909
not going to engage with that part here.
And so we said look think about PCA

158
00:06:05,909 --> 00:06:05,919
And so we said look think about PCA
 

159
00:06:05,919 --> 00:06:07,110
And so we said look think about PCA
which is the dimensionality reduction

160
00:06:07,110 --> 00:06:07,120
which is the dimensionality reduction
 

161
00:06:07,120 --> 00:06:08,870
which is the dimensionality reduction
idea you know and we said look you have

162
00:06:08,870 --> 00:06:08,880
idea you know and we said look you have
 

163
00:06:08,880 --> 00:06:11,749
idea you know and we said look you have
an algorithm that you know and the

164
00:06:11,749 --> 00:06:11,759
an algorithm that you know and the
 

165
00:06:11,759 --> 00:06:14,150
an algorithm that you know and the
algorithm that you have is you have x's

166
00:06:14,150 --> 00:06:14,160
algorithm that you have is you have x's
 

167
00:06:14,160 --> 00:06:16,230
algorithm that you have is you have x's
you have no labels no y's just have x's

168
00:06:16,230 --> 00:06:16,240
you have no labels no y's just have x's
 

169
00:06:16,240 --> 00:06:17,670
you have no labels no y's just have x's
but you believe that there's some

170
00:06:17,670 --> 00:06:17,680
but you believe that there's some
 

171
00:06:17,680 --> 00:06:19,350
but you believe that there's some
interesting distribution underlying it

172
00:06:19,350 --> 00:06:19,360
interesting distribution underlying it
 

173
00:06:19,360 --> 00:06:20,550
interesting distribution underlying it
and you want to understand it from a

174
00:06:20,550 --> 00:06:20,560
and you want to understand it from a
 

175
00:06:20,560 --> 00:06:22,950
and you want to understand it from a
kind of linear or gaussian perspective

176
00:06:22,950 --> 00:06:22,960
kind of linear or gaussian perspective
 

177
00:06:22,960 --> 00:06:24,550
kind of linear or gaussian perspective
and so what you're thinking about is

178
00:06:24,550 --> 00:06:24,560
and so what you're thinking about is
 

179
00:06:24,560 --> 00:06:25,990
and so what you're thinking about is
that even though this is in a high

180
00:06:25,990 --> 00:06:26,000
that even though this is in a high
 

181
00:06:26,000 --> 00:06:27,670
that even though this is in a high
dimensional space it actually exists in

182
00:06:27,670 --> 00:06:27,680
dimensional space it actually exists in
 

183
00:06:27,680 --> 00:06:29,670
dimensional space it actually exists in
a lower dimensional space that's what's

184
00:06:29,670 --> 00:06:29,680
a lower dimensional space that's what's
 

185
00:06:29,680 --> 00:06:31,510
a lower dimensional space that's what's
interesting about it and the PCA

186
00:06:31,510 --> 00:06:31,520
interesting about it and the PCA
 

187
00:06:31,520 --> 00:06:34,950
interesting about it and the PCA
approach neglecting the main parts is

188
00:06:34,950 --> 00:06:34,960
approach neglecting the main parts is
 

189
00:06:34,960 --> 00:06:37,830
approach neglecting the main parts is
you construct a matrix X which has your

190
00:06:37,830 --> 00:06:37,840
you construct a matrix X which has your
 

191
00:06:37,840 --> 00:06:39,590
you construct a matrix X which has your
data points as its rows. You could also

192
00:06:39,590 --> 00:06:39,600
data points as its rows. You could also
 

193
00:06:39,600 --> 00:06:40,870
data points as its rows. You could also
do it with columns. I'm just using rows

194
00:06:40,870 --> 00:06:40,880
do it with columns. I'm just using rows
 

195
00:06:40,880 --> 00:06:42,390
do it with columns. I'm just using rows
to match what we saw in linear

196
00:06:42,390 --> 00:06:42,400
to match what we saw in linear
 

197
00:06:42,400 --> 00:06:46,550
to match what we saw in linear
regression. You comput it SVD

198
00:06:46,550 --> 00:06:46,560
regression. You comput it SVD
 

199
00:06:46,560 --> 00:06:48,469
regression. You comput it SVD
and then you take the top K singular

200
00:06:48,469 --> 00:06:48,479
and then you take the top K singular
 

201
00:06:48,479 --> 00:06:49,830
and then you take the top K singular
vectors and you use those for

202
00:06:49,830 --> 00:06:49,840
vectors and you use those for
 

203
00:06:49,840 --> 00:06:51,350
vectors and you use those for
dimensionality reduction. So you say

204
00:06:51,350 --> 00:06:51,360
dimensionality reduction. So you say
 

205
00:06:51,360 --> 00:06:54,150
dimensionality reduction. So you say
those top K vectors the V's are the same

206
00:06:54,150 --> 00:06:54,160
those top K vectors the V's are the same
 

207
00:06:54,160 --> 00:06:58,070
those top K vectors the V's are the same
size right as the uh X's. Those V

208
00:06:58,070 --> 00:06:58,080
size right as the uh X's. Those V
 

209
00:06:58,080 --> 00:07:00,629
size right as the uh X's. Those V
vectors represent the directions of

210
00:07:00,629 --> 00:07:00,639
vectors represent the directions of
 

211
00:07:00,639 --> 00:07:02,390
vectors represent the directions of
greatest variability from the PCA

212
00:07:02,390 --> 00:07:02,400
greatest variability from the PCA
 

213
00:07:02,400 --> 00:07:03,670
greatest variability from the PCA
perspective. That's where the

214
00:07:03,670 --> 00:07:03,680
perspective. That's where the
 

215
00:07:03,680 --> 00:07:06,550
perspective. That's where the
distribution is actually moving around.

216
00:07:06,550 --> 00:07:06,560
distribution is actually moving around.
 

217
00:07:06,560 --> 00:07:08,390
distribution is actually moving around.
And so you can use it for another

218
00:07:08,390 --> 00:07:08,400
And so you can use it for another
 

219
00:07:08,400 --> 00:07:10,070
And so you can use it for another
problem to do dimensionality reduction

220
00:07:10,070 --> 00:07:10,080
problem to do dimensionality reduction
 

221
00:07:10,080 --> 00:07:12,710
problem to do dimensionality reduction
by simply projecting to the lower

222
00:07:12,710 --> 00:07:12,720
by simply projecting to the lower
 

223
00:07:12,720 --> 00:07:14,710
by simply projecting to the lower
dimension using those V's. Okay, so

224
00:07:14,710 --> 00:07:14,720
dimension using those V's. Okay, so
 

225
00:07:14,720 --> 00:07:17,830
dimension using those V's. Okay, so
that's something you've seen and the

226
00:07:17,830 --> 00:07:17,840
that's something you've seen and the
 

227
00:07:17,840 --> 00:07:19,749
that's something you've seen and the
you learned this in your machine

228
00:07:19,749 --> 00:07:19,759
you learned this in your machine
 

229
00:07:19,759 --> 00:07:22,629
you learned this in your machine
learning class. However, this feels very

230
00:07:22,629 --> 00:07:22,639
learning class. However, this feels very
 

231
00:07:22,639 --> 00:07:24,070
learning class. However, this feels very
different than supervised learning when

232
00:07:24,070 --> 00:07:24,080
different than supervised learning when
 

233
00:07:24,080 --> 00:07:26,469
different than supervised learning when
you look at it because there's no loss,

234
00:07:26,469 --> 00:07:26,479
you look at it because there's no loss,
 

235
00:07:26,479 --> 00:07:28,550
you look at it because there's no loss,
there's no labels, there's no gradients,

236
00:07:28,550 --> 00:07:28,560
there's no labels, there's no gradients,
 

237
00:07:28,560 --> 00:07:30,790
there's no labels, there's no gradients,
and there's no optimizer. So, literally

238
00:07:30,790 --> 00:07:30,800
and there's no optimizer. So, literally
 

239
00:07:30,800 --> 00:07:33,270
and there's no optimizer. So, literally
every single thing that we've been

240
00:07:33,270 --> 00:07:33,280
every single thing that we've been
 

241
00:07:33,280 --> 00:07:34,950
every single thing that we've been
studying in deep learning is not present

242
00:07:34,950 --> 00:07:34,960
studying in deep learning is not present
 

243
00:07:34,960 --> 00:07:37,510
studying in deep learning is not present
here seemingly. So, that's where we kind

244
00:07:37,510 --> 00:07:37,520
here seemingly. So, that's where we kind
 

245
00:07:37,520 --> 00:07:39,430
here seemingly. So, that's where we kind
of ended. We kind of zipped in the last

246
00:07:39,430 --> 00:07:39,440
of ended. We kind of zipped in the last
 

247
00:07:39,440 --> 00:07:40,710
of ended. We kind of zipped in the last
two minutes. I want to make sure

248
00:07:40,710 --> 00:07:40,720
two minutes. I want to make sure
 

249
00:07:40,720 --> 00:07:42,469
two minutes. I want to make sure
everyone with me on this. We have to

250
00:07:42,469 --> 00:07:42,479
everyone with me on this. We have to
 

251
00:07:42,479 --> 00:07:45,909
everyone with me on this. We have to
start here. Okay. So

252
00:07:45,909 --> 00:07:45,919
start here. Okay. So
 

253
00:07:45,919 --> 00:07:49,430
start here. Okay. So
you think back and ask why was this PCA

254
00:07:49,430 --> 00:07:49,440
you think back and ask why was this PCA
 

255
00:07:49,440 --> 00:07:51,430
you think back and ask why was this PCA
approach reasonable

256
00:07:51,430 --> 00:07:51,440
approach reasonable
 

257
00:07:51,440 --> 00:07:53,189
approach reasonable
and one way to understand his

258
00:07:53,189 --> 00:07:53,199
and one way to understand his
 

259
00:07:53,199 --> 00:07:55,189
and one way to understand his
reasonability is to think about the

260
00:07:55,189 --> 00:07:55,199
reasonability is to think about the
 

261
00:07:55,199 --> 00:07:58,150
reasonability is to think about the
echert young mki theorem for forbinius

262
00:07:58,150 --> 00:07:58,160
echert young mki theorem for forbinius
 

263
00:07:58,160 --> 00:08:00,070
echert young mki theorem for forbinius
norm. So what does that say? What that

264
00:08:00,070 --> 00:08:00,080
norm. So what does that say? What that
 

265
00:08:00,080 --> 00:08:03,510
norm. So what does that say? What that
theorem says is if you look at a matrix

266
00:08:03,510 --> 00:08:03,520
theorem says is if you look at a matrix
 

267
00:08:03,520 --> 00:08:08,230
theorem says is if you look at a matrix
X and you want to find a rank at most K

268
00:08:08,230 --> 00:08:08,240
X and you want to find a rank at most K
 

269
00:08:08,240 --> 00:08:11,029
X and you want to find a rank at most K
approximation of X where the closeness

270
00:08:11,029 --> 00:08:11,039
approximation of X where the closeness
 

271
00:08:11,039 --> 00:08:12,469
approximation of X where the closeness
of the approximation you're going to

272
00:08:12,469 --> 00:08:12,479
of the approximation you're going to
 

273
00:08:12,479 --> 00:08:15,830
of the approximation you're going to
measure in a norm which norm provenius

274
00:08:15,830 --> 00:08:15,840
measure in a norm which norm provenius
 

275
00:08:15,840 --> 00:08:17,670
measure in a norm which norm provenius
norm so proven norm just says I would

276
00:08:17,670 --> 00:08:17,680
norm so proven norm just says I would
 

277
00:08:17,680 --> 00:08:19,589
norm so proven norm just says I would
like to match every entry of that matrix

278
00:08:19,589 --> 00:08:19,599
like to match every entry of that matrix
 

279
00:08:19,599 --> 00:08:21,990
like to match every entry of that matrix
as well as I could and the average mean

280
00:08:21,990 --> 00:08:22,000
as well as I could and the average mean
 

281
00:08:22,000 --> 00:08:23,189
as well as I could and the average mean
squareed error across all the entries of

282
00:08:23,189 --> 00:08:23,199
squareed error across all the entries of
 

283
00:08:23,199 --> 00:08:25,510
squareed error across all the entries of
the matrix.

284
00:08:25,510 --> 00:08:25,520
the matrix.
 

285
00:08:25,520 --> 00:08:27,029
the matrix.
So if you think about minimizing this

286
00:08:27,029 --> 00:08:27,039
So if you think about minimizing this
 

287
00:08:27,039 --> 00:08:30,309
So if you think about minimizing this
inbinous norm, this theorem tells you

288
00:08:30,309 --> 00:08:30,319
inbinous norm, this theorem tells you
 

289
00:08:30,319 --> 00:08:33,269
inbinous norm, this theorem tells you
that the way to do it is just to take

290
00:08:33,269 --> 00:08:33,279
that the way to do it is just to take
 

291
00:08:33,279 --> 00:08:37,670
that the way to do it is just to take
the outer product form of the SVD and

292
00:08:37,670 --> 00:08:37,680
the outer product form of the SVD and
 

293
00:08:37,680 --> 00:08:40,949
the outer product form of the SVD and
just truncate it. Cut it at K. Just keep

294
00:08:40,949 --> 00:08:40,959
just truncate it. Cut it at K. Just keep
 

295
00:08:40,959 --> 00:08:43,990
just truncate it. Cut it at K. Just keep
the top K singular uh values and their

296
00:08:43,990 --> 00:08:44,000
the top K singular uh values and their
 

297
00:08:44,000 --> 00:08:45,750
the top K singular uh values and their
corresponding singular vectors to

298
00:08:45,750 --> 00:08:45,760
corresponding singular vectors to
 

299
00:08:45,760 --> 00:08:49,350
corresponding singular vectors to
construct your rank K matrix. Okay, so

300
00:08:49,350 --> 00:08:49,360
construct your rank K matrix. Okay, so
 

301
00:08:49,360 --> 00:08:54,150
construct your rank K matrix. Okay, so
this is the theorem that uh you've seen

302
00:08:54,150 --> 00:08:54,160
this is the theorem that uh you've seen
 

303
00:08:54,160 --> 00:08:56,470
this is the theorem that uh you've seen
in your optimization class. Um it's a

304
00:08:56,470 --> 00:08:56,480
in your optimization class. Um it's a
 

305
00:08:56,480 --> 00:08:57,829
in your optimization class. Um it's a
very interesting theorem, right? Because

306
00:08:57,829 --> 00:08:57,839
very interesting theorem, right? Because
 

307
00:08:57,839 --> 00:09:02,150
very interesting theorem, right? Because
rank kess is a very non-convex

308
00:09:02,150 --> 00:09:02,160
rank kess is a very non-convex
 

309
00:09:02,160 --> 00:09:04,389
rank kess is a very non-convex
condition. The sum of two rank k things

310
00:09:04,389 --> 00:09:04,399
condition. The sum of two rank k things
 

311
00:09:04,399 --> 00:09:05,750
condition. The sum of two rank k things
or the average of two ranky things is

312
00:09:05,750 --> 00:09:05,760
or the average of two ranky things is
 

313
00:09:05,760 --> 00:09:09,030
or the average of two ranky things is
definitely not rank k. Um well typically

314
00:09:09,030 --> 00:09:09,040
definitely not rank k. Um well typically
 

315
00:09:09,040 --> 00:09:13,590
definitely not rank k. Um well typically
not rank k. Um so that but you can all

316
00:09:13,590 --> 00:09:13,600
not rank k. Um so that but you can all
 

317
00:09:13,600 --> 00:09:17,190
not rank k. Um so that but you can all
you can solve this this way. So what

318
00:09:17,190 --> 00:09:17,200
you can solve this this way. So what
 

319
00:09:17,200 --> 00:09:21,670
you can solve this this way. So what
this provides us is a a way to think

320
00:09:21,670 --> 00:09:21,680
this provides us is a a way to think
 

321
00:09:21,680 --> 00:09:25,030
this provides us is a a way to think
about what PCA is doing in a different

322
00:09:25,030 --> 00:09:25,040
about what PCA is doing in a different
 

323
00:09:25,040 --> 00:09:27,509
about what PCA is doing in a different
light because here you have something

324
00:09:27,509 --> 00:09:27,519
light because here you have something
 

325
00:09:27,519 --> 00:09:29,829
light because here you have something
that looks like a loss, right? It's

326
00:09:29,829 --> 00:09:29,839
that looks like a loss, right? It's
 

327
00:09:29,839 --> 00:09:31,430
that looks like a loss, right? It's
actually good oldfashioned mean square

328
00:09:31,430 --> 00:09:31,440
actually good oldfashioned mean square
 

329
00:09:31,440 --> 00:09:33,430
actually good oldfashioned mean square
error,

330
00:09:33,430 --> 00:09:33,440
error,
 

331
00:09:33,440 --> 00:09:36,550
error,
right? So suddenly you can think about

332
00:09:36,550 --> 00:09:36,560
right? So suddenly you can think about
 

333
00:09:36,560 --> 00:09:39,590
right? So suddenly you can think about
what it is that PCA is doing as

334
00:09:39,590 --> 00:09:39,600
what it is that PCA is doing as
 

335
00:09:39,600 --> 00:09:42,150
what it is that PCA is doing as
minimizing a certain loss. But that's

336
00:09:42,150 --> 00:09:42,160
minimizing a certain loss. But that's
 

337
00:09:42,160 --> 00:09:45,990
minimizing a certain loss. But that's
good, right, for us. So now let's like

338
00:09:45,990 --> 00:09:46,000
good, right, for us. So now let's like
 

339
00:09:46,000 --> 00:09:48,630
good, right, for us. So now let's like
expand on this.

340
00:09:48,630 --> 00:09:48,640
expand on this.
 

341
00:09:48,640 --> 00:09:51,030
expand on this.
So we interpret this in neural net

342
00:09:51,030 --> 00:09:51,040
So we interpret this in neural net
 

343
00:09:51,040 --> 00:09:54,230
So we interpret this in neural net
terms. So for neural net terms what we

344
00:09:54,230 --> 00:09:54,240
terms. So for neural net terms what we
 

345
00:09:54,240 --> 00:09:55,990
terms. So for neural net terms what we
need so I've written there no loss no

346
00:09:55,990 --> 00:09:56,000
need so I've written there no loss no
 

347
00:09:56,000 --> 00:09:59,509
need so I've written there no loss no
labels no gradients right it also has uh

348
00:09:59,509 --> 00:09:59,519
labels no gradients right it also has uh
 

349
00:09:59,519 --> 00:10:04,630
labels no gradients right it also has uh
let me just add to that list

350
00:10:04,630 --> 00:10:04,640

 

351
00:10:04,640 --> 00:10:09,509

no mini batches

352
00:10:09,509 --> 00:10:09,519

 

353
00:10:09,519 --> 00:10:12,310

right it has training data x but there's

354
00:10:12,310 --> 00:10:12,320
right it has training data x but there's
 

355
00:10:12,320 --> 00:10:15,670
right it has training data x but there's
no no like batches that you're running

356
00:10:15,670 --> 00:10:15,680
no no like batches that you're running
 

357
00:10:15,680 --> 00:10:17,509
no no like batches that you're running
so we want to interpret this in neural

358
00:10:17,509 --> 00:10:17,519
so we want to interpret this in neural
 

359
00:10:17,519 --> 00:10:19,750
so we want to interpret this in neural
net terms and to do that we're going to

360
00:10:19,750 --> 00:10:19,760
net terms and to do that we're going to
 

361
00:10:19,760 --> 00:10:21,829
net terms and to do that we're going to
say first thing I'm going to try to that

362
00:10:21,829 --> 00:10:21,839
say first thing I'm going to try to that
 

363
00:10:21,839 --> 00:10:24,069
say first thing I'm going to try to that
is something that corresponds to a mini

364
00:10:24,069 --> 00:10:24,079
is something that corresponds to a mini
 

365
00:10:24,079 --> 00:10:27,829
is something that corresponds to a mini
batch size one. Okay, so I want to take

366
00:10:27,829 --> 00:10:27,839
batch size one. Okay, so I want to take
 

367
00:10:27,839 --> 00:10:30,470
batch size one. Okay, so I want to take
a batch type perspective. So to do that

368
00:10:30,470 --> 00:10:30,480
a batch type perspective. So to do that
 

369
00:10:30,480 --> 00:10:31,829
a batch type perspective. So to do that
I'm going to take a rowby row

370
00:10:31,829 --> 00:10:31,839
I'm going to take a rowby row
 

371
00:10:31,839 --> 00:10:34,790
I'm going to take a rowby row
perspective on x hat. So if you think

372
00:10:34,790 --> 00:10:34,800
perspective on x hat. So if you think
 

373
00:10:34,800 --> 00:10:38,710
perspective on x hat. So if you think
about it in Fbinius norm right if this

374
00:10:38,710 --> 00:10:38,720
about it in Fbinius norm right if this
 

375
00:10:38,720 --> 00:10:47,030
about it in Fbinius norm right if this
is X

376
00:10:47,030 --> 00:10:47,040

 

377
00:10:47,040 --> 00:10:48,710

and

378
00:10:48,710 --> 00:10:48,720
and
 

379
00:10:48,720 --> 00:10:57,030
and
this is X hat

380
00:10:57,030 --> 00:10:57,040

 

381
00:10:57,040 --> 00:11:02,710

okay let's label these

382
00:11:02,710 --> 00:11:02,720

 

383
00:11:02,720 --> 00:11:04,630

so I'm just writing these X and X hat

384
00:11:04,630 --> 00:11:04,640
so I'm just writing these X and X hat
 

385
00:11:04,640 --> 00:11:06,470
so I'm just writing these X and X hat
together

386
00:11:06,470 --> 00:11:06,480
together
 

387
00:11:06,480 --> 00:11:09,030
together
because I want to approximate this in

388
00:11:09,030 --> 00:11:09,040
because I want to approximate this in
 

389
00:11:09,040 --> 00:11:14,150
because I want to approximate this in
Finius norm. I want X1 hat transpose

390
00:11:14,150 --> 00:11:14,160
Finius norm. I want X1 hat transpose
 

391
00:11:14,160 --> 00:11:17,430
Finius norm. I want X1 hat transpose
this row to be as close as possible to

392
00:11:17,430 --> 00:11:17,440
this row to be as close as possible to
 

393
00:11:17,440 --> 00:11:20,630
this row to be as close as possible to
this row. Does everyone see that there's

394
00:11:20,630 --> 00:11:20,640
this row. Does everyone see that there's
 

395
00:11:20,640 --> 00:11:22,470
this row. Does everyone see that there's
an overall constraint that this matrix

396
00:11:22,470 --> 00:11:22,480
an overall constraint that this matrix
 

397
00:11:22,480 --> 00:11:26,230
an overall constraint that this matrix
should be rank K, but I want to match it

398
00:11:26,230 --> 00:11:26,240
should be rank K, but I want to match it
 

399
00:11:26,240 --> 00:11:28,470
should be rank K, but I want to match it
row by row in closeness in mean squed

400
00:11:28,470 --> 00:11:28,480
row by row in closeness in mean squed
 

401
00:11:28,480 --> 00:11:32,550
row by row in closeness in mean squed
error. So that's very good, right? from

402
00:11:32,550 --> 00:11:32,560
error. So that's very good, right? from
 

403
00:11:32,560 --> 00:11:34,310
error. So that's very good, right? from
our point of view because if I want to

404
00:11:34,310 --> 00:11:34,320
our point of view because if I want to
 

405
00:11:34,320 --> 00:11:37,509
our point of view because if I want to
say I want to use as my mini batch idea

406
00:11:37,509 --> 00:11:37,519
say I want to use as my mini batch idea
 

407
00:11:37,519 --> 00:11:40,310
say I want to use as my mini batch idea
the rows of X it tells me that there's

408
00:11:40,310 --> 00:11:40,320
the rows of X it tells me that there's
 

409
00:11:40,320 --> 00:11:43,430
the rows of X it tells me that there's
something to loss it against namely that

410
00:11:43,430 --> 00:11:43,440
something to loss it against namely that
 

411
00:11:43,440 --> 00:11:44,870
something to loss it against namely that
row of X hat yeah

412
00:11:44,870 --> 00:11:44,880
row of X hat yeah
 

413
00:11:44,880 --> 00:11:48,790
row of X hat yeah
>> is there anything special

414
00:11:48,790 --> 00:11:48,800

 

415
00:11:48,800 --> 00:11:50,470

>> as I said before we can do this also by

416
00:11:50,470 --> 00:11:50,480
>> as I said before we can do this also by
 

417
00:11:50,480 --> 00:11:51,190
>> as I said before we can do this also by
columns

418
00:11:51,190 --> 00:11:51,200
columns
 

419
00:11:51,200 --> 00:11:53,030
columns
>> I just I'm just using rows because we

420
00:11:53,030 --> 00:11:53,040
>> I just I'm just using rows because we
 

421
00:11:53,040 --> 00:11:54,230
>> I just I'm just using rows because we
did linear regression you put our data

422
00:11:54,230 --> 00:11:54,240
did linear regression you put our data
 

423
00:11:54,240 --> 00:11:55,910
did linear regression you put our data
in rows so

424
00:11:55,910 --> 00:11:55,920
in rows so
 

425
00:11:55,920 --> 00:11:58,870
in rows so
>> that's all

426
00:11:58,870 --> 00:11:58,880
>> that's all
 

427
00:11:58,880 --> 00:12:01,269
>> that's all
nothing is nothing is specific about

428
00:12:01,269 --> 00:12:01,279
nothing is nothing is specific about
 

429
00:12:01,279 --> 00:12:06,230
nothing is nothing is specific about
rows here. Um, okay. So then we can say

430
00:12:06,230 --> 00:12:06,240
rows here. Um, okay. So then we can say
 

431
00:12:06,240 --> 00:12:07,990
rows here. Um, okay. So then we can say
great, let me try to interpret this in

432
00:12:07,990 --> 00:12:08,000
great, let me try to interpret this in
 

433
00:12:08,000 --> 00:12:11,030
great, let me try to interpret this in
neural net terms fully. So now I can

434
00:12:11,030 --> 00:12:11,040
neural net terms fully. So now I can
 

435
00:12:11,040 --> 00:12:13,509
neural net terms fully. So now I can
think of X as a D- dimensional vector.

436
00:12:13,509 --> 00:12:13,519
think of X as a D- dimensional vector.
 

437
00:12:13,519 --> 00:12:15,750
think of X as a D- dimensional vector.
So now I'm going to flip it to go to

438
00:12:15,750 --> 00:12:15,760
So now I'm going to flip it to go to
 

439
00:12:15,760 --> 00:12:17,829
So now I'm going to flip it to go to
columns. Up here I was thinking about

440
00:12:17,829 --> 00:12:17,839
columns. Up here I was thinking about
 

441
00:12:17,839 --> 00:12:19,509
columns. Up here I was thinking about
it, but I can always now think about in

442
00:12:19,509 --> 00:12:19,519
it, but I can always now think about in
 

443
00:12:19,519 --> 00:12:21,350
it, but I can always now think about in
terms of columns. Think about this as a

444
00:12:21,350 --> 00:12:21,360
terms of columns. Think about this as a
 

445
00:12:21,360 --> 00:12:23,990
terms of columns. Think about this as a
dimensional vector and I'll have an X

446
00:12:23,990 --> 00:12:24,000
dimensional vector and I'll have an X
 

447
00:12:24,000 --> 00:12:26,470
dimensional vector and I'll have an X
hat, which is it reconstruction, right?

448
00:12:26,470 --> 00:12:26,480
hat, which is it reconstruction, right?
 

449
00:12:26,480 --> 00:12:29,590
hat, which is it reconstruction, right?
Supposed to be close to it.

450
00:12:29,590 --> 00:12:29,600
Supposed to be close to it.
 

451
00:12:29,600 --> 00:12:34,230
Supposed to be close to it.
And now I want to minimize this regular

452
00:12:34,230 --> 00:12:34,240
And now I want to minimize this regular
 

453
00:12:34,240 --> 00:12:35,910
And now I want to minimize this regular
squared uklidian norm regular mean

454
00:12:35,910 --> 00:12:35,920
squared uklidian norm regular mean
 

455
00:12:35,920 --> 00:12:38,150
squared uklidian norm regular mean
squared error.

456
00:12:38,150 --> 00:12:38,160
squared error.
 

457
00:12:38,160 --> 00:12:39,910
squared error.
The only thing that remains is I have to

458
00:12:39,910 --> 00:12:39,920
The only thing that remains is I have to
 

459
00:12:39,920 --> 00:12:43,430
The only thing that remains is I have to
enforce the rank k constraint.

460
00:12:43,430 --> 00:12:43,440
enforce the rank k constraint.
 

461
00:12:43,440 --> 00:12:45,509
enforce the rank k constraint.
So I can encode the rank k constraint

462
00:12:45,509 --> 00:12:45,519
So I can encode the rank k constraint
 

463
00:12:45,519 --> 00:12:47,910
So I can encode the rank k constraint
that I want structurally

464
00:12:47,910 --> 00:12:47,920
that I want structurally
 

465
00:12:47,920 --> 00:12:49,829
that I want structurally
as

466
00:12:49,829 --> 00:12:49,839
as
 

467
00:12:49,839 --> 00:12:51,350
as
how do I make sure that something's rank

468
00:12:51,350 --> 00:12:51,360
how do I make sure that something's rank
 

469
00:12:51,360 --> 00:12:54,150
how do I make sure that something's rank
k. I make it the product of two matrices

470
00:12:54,150 --> 00:12:54,160
k. I make it the product of two matrices
 

471
00:12:54,160 --> 00:12:57,110
k. I make it the product of two matrices
that are structurally at rank at most k.

472
00:12:57,110 --> 00:12:57,120
that are structurally at rank at most k.
 

473
00:12:57,120 --> 00:13:00,389
that are structurally at rank at most k.
then it can't grow. Right? So I say I

474
00:13:00,389 --> 00:13:00,399
then it can't grow. Right? So I say I
 

475
00:13:00,399 --> 00:13:02,470
then it can't grow. Right? So I say I
make W1 such that it takes a

476
00:13:02,470 --> 00:13:02,480
make W1 such that it takes a
 

477
00:13:02,480 --> 00:13:04,230
make W1 such that it takes a
D-dimensional vector to a K- dimensional

478
00:13:04,230 --> 00:13:04,240
D-dimensional vector to a K- dimensional
 

479
00:13:04,240 --> 00:13:06,550
D-dimensional vector to a K- dimensional
vector and it's a linear linear

480
00:13:06,550 --> 00:13:06,560
vector and it's a linear linear
 

481
00:13:06,560 --> 00:13:08,710
vector and it's a linear linear
transformation and then I take another

482
00:13:08,710 --> 00:13:08,720
transformation and then I take another
 

483
00:13:08,720 --> 00:13:10,550
transformation and then I take another
linear transformation that takes K

484
00:13:10,550 --> 00:13:10,560
linear transformation that takes K
 

485
00:13:10,560 --> 00:13:11,910
linear transformation that takes K
dimensional vectors to Dimensional

486
00:13:11,910 --> 00:13:11,920
dimensional vectors to Dimensional
 

487
00:13:11,920 --> 00:13:14,550
dimensional vectors to Dimensional
vectors. There's no way this product is

488
00:13:14,550 --> 00:13:14,560
vectors. There's no way this product is
 

489
00:13:14,560 --> 00:13:16,629
vectors. There's no way this product is
going to have rank more than K. Does

490
00:13:16,629 --> 00:13:16,639
going to have rank more than K. Does
 

491
00:13:16,639 --> 00:13:18,710
going to have rank more than K. Does
everyone see that? So now what I've done

492
00:13:18,710 --> 00:13:18,720
everyone see that? So now what I've done
 

493
00:13:18,720 --> 00:13:21,829
everyone see that? So now what I've done
is I've taken the thing that I want and

494
00:13:21,829 --> 00:13:21,839
is I've taken the thing that I want and
 

495
00:13:21,839 --> 00:13:23,430
is I've taken the thing that I want and
I've encoded it into a neural net

496
00:13:23,430 --> 00:13:23,440
I've encoded it into a neural net
 

497
00:13:23,440 --> 00:13:25,350
I've encoded it into a neural net
architecture.

498
00:13:25,350 --> 00:13:25,360
architecture.
 

499
00:13:25,360 --> 00:13:27,190
architecture.
Okay, the regularity I want into an

500
00:13:27,190 --> 00:13:27,200
Okay, the regularity I want into an
 

501
00:13:27,200 --> 00:13:32,230
Okay, the regularity I want into an
architecture. And now I can say great,

502
00:13:32,230 --> 00:13:32,240
architecture. And now I can say great,
 

503
00:13:32,240 --> 00:13:35,350
architecture. And now I can say great,
I'll just train with this loss over the

504
00:13:35,350 --> 00:13:35,360
I'll just train with this loss over the
 

505
00:13:35,360 --> 00:13:39,190
I'll just train with this loss over the
entire data set using batches.

506
00:13:39,190 --> 00:13:39,200
entire data set using batches.
 

507
00:13:39,200 --> 00:13:42,230
entire data set using batches.
Everyone with me?

508
00:13:42,230 --> 00:13:42,240
Everyone with me?
 

509
00:13:42,240 --> 00:13:46,230
Everyone with me?
If I get to the optimum, whatever it is,

510
00:13:46,230 --> 00:13:46,240
If I get to the optimum, whatever it is,
 

511
00:13:46,240 --> 00:13:48,629
If I get to the optimum, whatever it is,
I know by Eert Young that I'm going to

512
00:13:48,629 --> 00:13:48,639
I know by Eert Young that I'm going to
 

513
00:13:48,639 --> 00:13:51,350
I know by Eert Young that I'm going to
be here

514
00:13:51,350 --> 00:13:51,360
be here
 

515
00:13:51,360 --> 00:13:54,790
be here
in terms of the actual reconstructions.

516
00:13:54,790 --> 00:13:54,800
in terms of the actual reconstructions.
 

517
00:13:54,800 --> 00:13:57,750
in terms of the actual reconstructions.
Everyone with me?

518
00:13:57,750 --> 00:13:57,760
Everyone with me?
 

519
00:13:57,760 --> 00:13:59,990
Everyone with me?
Okay, I'll make sure I pause here for a

520
00:13:59,990 --> 00:14:00,000
Okay, I'll make sure I pause here for a
 

521
00:14:00,000 --> 00:14:03,910
Okay, I'll make sure I pause here for a
minute.

522
00:14:03,910 --> 00:14:03,920

 

523
00:14:03,920 --> 00:14:05,829

Okay, all we're doing is we're saying

524
00:14:05,829 --> 00:14:05,839
Okay, all we're doing is we're saying
 

525
00:14:05,839 --> 00:14:07,750
Okay, all we're doing is we're saying
because we have this theorem that tells

526
00:14:07,750 --> 00:14:07,760
because we have this theorem that tells
 

527
00:14:07,760 --> 00:14:10,629
because we have this theorem that tells
us another way of understanding what the

528
00:14:10,629 --> 00:14:10,639
us another way of understanding what the
 

529
00:14:10,639 --> 00:14:13,670
us another way of understanding what the
solution to PCA is that we can interpret

530
00:14:13,670 --> 00:14:13,680
solution to PCA is that we can interpret
 

531
00:14:13,680 --> 00:14:15,590
solution to PCA is that we can interpret
in terms of loss, we can then turn that

532
00:14:15,590 --> 00:14:15,600
in terms of loss, we can then turn that
 

533
00:14:15,600 --> 00:14:17,590
in terms of loss, we can then turn that
into an actual training recipe for a

534
00:14:17,590 --> 00:14:17,600
into an actual training recipe for a
 

535
00:14:17,600 --> 00:14:21,269
into an actual training recipe for a
neural net. So now I'm free to do all

536
00:14:21,269 --> 00:14:21,279
neural net. So now I'm free to do all
 

537
00:14:21,279 --> 00:14:23,509
neural net. So now I'm free to do all
the things that I'm normally free to do.

538
00:14:23,509 --> 00:14:23,519
the things that I'm normally free to do.
 

539
00:14:23,519 --> 00:14:25,350
the things that I'm normally free to do.
I can change my batch size, my mini

540
00:14:25,350 --> 00:14:25,360
I can change my batch size, my mini
 

541
00:14:25,360 --> 00:14:27,590
I can change my batch size, my mini
batch size. I can choose my optimizer

542
00:14:27,590 --> 00:14:27,600
batch size. I can choose my optimizer
 

543
00:14:27,600 --> 00:14:30,710
batch size. I can choose my optimizer
how I want it. I can do anything I want,

544
00:14:30,710 --> 00:14:30,720
how I want it. I can do anything I want,
 

545
00:14:30,720 --> 00:14:32,949
how I want it. I can do anything I want,
right? I can add weight decay. All kinds

546
00:14:32,949 --> 00:14:32,959
right? I can add weight decay. All kinds
 

547
00:14:32,959 --> 00:14:34,230
right? I can add weight decay. All kinds
of stuff that I would do to train in a

548
00:14:34,230 --> 00:14:34,240
of stuff that I would do to train in a
 

549
00:14:34,240 --> 00:14:37,110
of stuff that I would do to train in a
network I can do here. And I'll still be

550
00:14:37,110 --> 00:14:37,120
network I can do here. And I'll still be
 

551
00:14:37,120 --> 00:14:38,870
network I can do here. And I'll still be
approaching in spirit what's happening

552
00:14:38,870 --> 00:14:38,880
approaching in spirit what's happening
 

553
00:14:38,880 --> 00:14:42,230
approaching in spirit what's happening
there.

554
00:14:42,230 --> 00:14:42,240

 

555
00:14:42,240 --> 00:14:44,790

Okay.

556
00:14:44,790 --> 00:14:44,800
Okay.
 

557
00:14:44,800 --> 00:14:48,389
Okay.
Very good. So now what have we achieved?

558
00:14:48,389 --> 00:14:48,399
Very good. So now what have we achieved?
 

559
00:14:48,399 --> 00:14:51,430
Very good. So now what have we achieved?
We said that look I can take the

560
00:14:51,430 --> 00:14:51,440
We said that look I can take the
 

561
00:14:51,440 --> 00:14:52,870
We said that look I can take the
dimensionality reduction technique that

562
00:14:52,870 --> 00:14:52,880
dimensionality reduction technique that
 

563
00:14:52,880 --> 00:14:55,269
dimensionality reduction technique that
you learned and I can map it into the

564
00:14:55,269 --> 00:14:55,279
you learned and I can map it into the
 

565
00:14:55,279 --> 00:14:57,189
you learned and I can map it into the
idea of self-supervision. So what do we

566
00:14:57,189 --> 00:14:57,199
idea of self-supervision. So what do we
 

567
00:14:57,199 --> 00:15:00,710
idea of self-supervision. So what do we
call what is self-supervision?

568
00:15:00,710 --> 00:15:00,720
call what is self-supervision?
 

569
00:15:00,720 --> 00:15:05,350
call what is self-supervision?
X is the input, but X is also the label.

570
00:15:05,350 --> 00:15:05,360
X is the input, but X is also the label.
 

571
00:15:05,360 --> 00:15:06,710
X is the input, but X is also the label.
Remember, the label shows up in the

572
00:15:06,710 --> 00:15:06,720
Remember, the label shows up in the
 

573
00:15:06,720 --> 00:15:09,110
Remember, the label shows up in the
loss. The input shows up at the

574
00:15:09,110 --> 00:15:09,120
loss. The input shows up at the
 

575
00:15:09,120 --> 00:15:10,150
loss. The input shows up at the
beginning of your architecture

576
00:15:10,150 --> 00:15:10,160
beginning of your architecture
 

577
00:15:10,160 --> 00:15:11,910
beginning of your architecture
somewhere.

578
00:15:11,910 --> 00:15:11,920
somewhere.
 

579
00:15:11,920 --> 00:15:13,829
somewhere.
Here, they're the same thing. So, I

580
00:15:13,829 --> 00:15:13,839
Here, they're the same thing. So, I
 

581
00:15:13,839 --> 00:15:15,750
Here, they're the same thing. So, I
self-supervise by saying I want to

582
00:15:15,750 --> 00:15:15,760
self-supervise by saying I want to
 

583
00:15:15,760 --> 00:15:19,269
self-supervise by saying I want to
encode X such that it's as close to X as

584
00:15:19,269 --> 00:15:19,279
encode X such that it's as close to X as
 

585
00:15:19,279 --> 00:15:24,550
encode X such that it's as close to X as
possible.

586
00:15:24,550 --> 00:15:24,560

 

587
00:15:24,560 --> 00:15:28,550

Okay. So, this approach has a name.

588
00:15:28,550 --> 00:15:28,560
Okay. So, this approach has a name.
 

589
00:15:28,560 --> 00:15:32,550
Okay. So, this approach has a name.
Okay. And the default ingredients are

590
00:15:32,550 --> 00:15:32,560
Okay. And the default ingredients are
 

591
00:15:32,560 --> 00:15:36,470
Okay. And the default ingredients are
your labels are X's themselves.

592
00:15:36,470 --> 00:15:36,480
your labels are X's themselves.
 

593
00:15:36,480 --> 00:15:38,230
your labels are X's themselves.
The architecture is an encoder followed

594
00:15:38,230 --> 00:15:38,240
The architecture is an encoder followed
 

595
00:15:38,240 --> 00:15:41,509
The architecture is an encoder followed
by a decoder and there's a bottleneck in

596
00:15:41,509 --> 00:15:41,519
by a decoder and there's a bottleneck in
 

597
00:15:41,519 --> 00:15:43,030
by a decoder and there's a bottleneck in
the middle. This is called an

598
00:15:43,030 --> 00:15:43,040
the middle. This is called an
 

599
00:15:43,040 --> 00:15:45,509
the middle. This is called an
autoenccoder. Autoenccoder. Encode

600
00:15:45,509 --> 00:15:45,519
autoenccoder. Autoenccoder. Encode
 

601
00:15:45,519 --> 00:15:48,310
autoenccoder. Autoenccoder. Encode
yourself to yourself

602
00:15:48,310 --> 00:15:48,320
yourself to yourself
 

603
00:15:48,320 --> 00:15:54,389
yourself to yourself
like auto regression.

604
00:15:54,389 --> 00:15:54,399

 

605
00:15:54,399 --> 00:15:57,590

Everyone happy with this? Okay. Okay, so

606
00:15:57,590 --> 00:15:57,600
Everyone happy with this? Okay. Okay, so
 

607
00:15:57,600 --> 00:16:00,470
Everyone happy with this? Okay. Okay, so
this sets up uh one kind of technique

608
00:16:00,470 --> 00:16:00,480
this sets up uh one kind of technique
 

609
00:16:00,480 --> 00:16:03,430
this sets up uh one kind of technique
that's used for uh self-s supervision.

610
00:16:03,430 --> 00:16:03,440
that's used for uh self-s supervision.
 

611
00:16:03,440 --> 00:16:05,509
that's used for uh self-s supervision.
And

612
00:16:05,509 --> 00:16:05,519
And
 

613
00:16:05,519 --> 00:16:08,629
And
in the traditional perspective here, you

614
00:16:08,629 --> 00:16:08,639
in the traditional perspective here, you
 

615
00:16:08,639 --> 00:16:10,790
in the traditional perspective here, you
can sometimes draw it this way with an

616
00:16:10,790 --> 00:16:10,800
can sometimes draw it this way with an
 

617
00:16:10,800 --> 00:16:13,990
can sometimes draw it this way with an
encoder followed by a decoder. And we

618
00:16:13,990 --> 00:16:14,000
encoder followed by a decoder. And we
 

619
00:16:14,000 --> 00:16:15,350
encoder followed by a decoder. And we
draw it with these shapes to kind of

620
00:16:15,350 --> 00:16:15,360
draw it with these shapes to kind of
 

621
00:16:15,360 --> 00:16:17,269
draw it with these shapes to kind of
emphasize that you start with something

622
00:16:17,269 --> 00:16:17,279
emphasize that you start with something
 

623
00:16:17,279 --> 00:16:19,430
emphasize that you start with something
big, you get something small, and you

624
00:16:19,430 --> 00:16:19,440
big, you get something small, and you
 

625
00:16:19,440 --> 00:16:20,790
big, you get something small, and you
take something small and you make it big

626
00:16:20,790 --> 00:16:20,800
take something small and you make it big
 

627
00:16:20,800 --> 00:16:23,030
take something small and you make it big
again.

628
00:16:23,030 --> 00:16:23,040
again.
 

629
00:16:23,040 --> 00:16:24,470
again.
Okay, these boxes are just drawn to

630
00:16:24,470 --> 00:16:24,480
Okay, these boxes are just drawn to
 

631
00:16:24,480 --> 00:16:26,230
Okay, these boxes are just drawn to
illustrate that. And if you think about

632
00:16:26,230 --> 00:16:26,240
illustrate that. And if you think about
 

633
00:16:26,240 --> 00:16:29,350
illustrate that. And if you think about
this the traditional perspective, so

634
00:16:29,350 --> 00:16:29,360
this the traditional perspective, so
 

635
00:16:29,360 --> 00:16:30,870
this the traditional perspective, so
traditional perspective PCA for

636
00:16:30,870 --> 00:16:30,880
traditional perspective PCA for
 

637
00:16:30,880 --> 00:16:32,470
traditional perspective PCA for
dimensionality reduction is the goal of

638
00:16:32,470 --> 00:16:32,480
dimensionality reduction is the goal of
 

639
00:16:32,480 --> 00:16:34,230
dimensionality reduction is the goal of
doing dimensionality reduction is to

640
00:16:34,230 --> 00:16:34,240
doing dimensionality reduction is to
 

641
00:16:34,240 --> 00:16:35,990
doing dimensionality reduction is to
have a projection

642
00:16:35,990 --> 00:16:36,000
have a projection
 

643
00:16:36,000 --> 00:16:38,790
have a projection
that you can apply on new data.

644
00:16:38,790 --> 00:16:38,800
that you can apply on new data.
 

645
00:16:38,800 --> 00:16:42,550
that you can apply on new data.
Okay? So the only thing we need to do

646
00:16:42,550 --> 00:16:42,560
Okay? So the only thing we need to do
 

647
00:16:42,560 --> 00:16:46,790
Okay? So the only thing we need to do
the projection is the encoder,

648
00:16:46,790 --> 00:16:46,800

 

649
00:16:46,800 --> 00:16:47,910

right? Because the encoder takes

650
00:16:47,910 --> 00:16:47,920
right? Because the encoder takes
 

651
00:16:47,920 --> 00:16:49,509
right? Because the encoder takes
Dimensional vectors into K dimensional

652
00:16:49,509 --> 00:16:49,519
Dimensional vectors into K dimensional
 

653
00:16:49,519 --> 00:16:53,509
Dimensional vectors into K dimensional
vectors. The decoder is just scaffolding

654
00:16:53,509 --> 00:16:53,519
vectors. The decoder is just scaffolding
 

655
00:16:53,519 --> 00:16:55,590
vectors. The decoder is just scaffolding
for training.

656
00:16:55,590 --> 00:16:55,600
for training.
 

657
00:16:55,600 --> 00:16:56,949
for training.
We need to train. So we have to put

658
00:16:56,949 --> 00:16:56,959
We need to train. So we have to put
 

659
00:16:56,959 --> 00:17:03,430
We need to train. So we have to put
something there. We put this there.

660
00:17:03,430 --> 00:17:03,440

 

661
00:17:03,440 --> 00:17:12,150

>> Okay. Yes.

662
00:17:12,150 --> 00:17:12,160

 

663
00:17:12,160 --> 00:17:14,390

>> Great question. The question was here I

664
00:17:14,390 --> 00:17:14,400
>> Great question. The question was here I
 

665
00:17:14,400 --> 00:17:16,470
>> Great question. The question was here I
just have W1 and W2. Are there weights

666
00:17:16,470 --> 00:17:16,480
just have W1 and W2. Are there weights
 

667
00:17:16,480 --> 00:17:18,309
just have W1 and W2. Are there weights
tied in any way? That's your question,

668
00:17:18,309 --> 00:17:18,319
tied in any way? That's your question,
 

669
00:17:18,319 --> 00:17:21,669
tied in any way? That's your question,
right? So uh the answer here is you

670
00:17:21,669 --> 00:17:21,679
right? So uh the answer here is you
 

671
00:17:21,679 --> 00:17:24,390
right? So uh the answer here is you
don't actually have to wait time.

672
00:17:24,390 --> 00:17:24,400
don't actually have to wait time.
 

673
00:17:24,400 --> 00:17:26,630
don't actually have to wait time.
Echert Young guarantees you in this case

674
00:17:26,630 --> 00:17:26,640
Echert Young guarantees you in this case
 

675
00:17:26,640 --> 00:17:28,950
Echert Young guarantees you in this case
that if you're going to train this thing

676
00:17:28,950 --> 00:17:28,960
that if you're going to train this thing
 

677
00:17:28,960 --> 00:17:30,789
that if you're going to train this thing
to convergence and actually the lowest

678
00:17:30,789 --> 00:17:30,799
to convergence and actually the lowest
 

679
00:17:30,799 --> 00:17:34,710
to convergence and actually the lowest
possible loss, you're guaranteed that

680
00:17:34,710 --> 00:17:34,720
possible loss, you're guaranteed that
 

681
00:17:34,720 --> 00:17:37,029
possible loss, you're guaranteed that
you have to project into this space. Now

682
00:17:37,029 --> 00:17:37,039
you have to project into this space. Now
 

683
00:17:37,039 --> 00:17:38,549
you have to project into this space. Now
you're not actually going to get the V

684
00:17:38,549 --> 00:17:38,559
you're not actually going to get the V
 

685
00:17:38,559 --> 00:17:40,789
you're not actually going to get the V
matrix necessarily because the V matrix

686
00:17:40,789 --> 00:17:40,799
matrix necessarily because the V matrix
 

687
00:17:40,799 --> 00:17:42,070
matrix necessarily because the V matrix
has this additional property of being

688
00:17:42,070 --> 00:17:42,080
has this additional property of being
 

689
00:17:42,080 --> 00:17:43,909
has this additional property of being
orthogonal. There's nothing here

690
00:17:43,909 --> 00:17:43,919
orthogonal. There's nothing here
 

691
00:17:43,919 --> 00:17:46,150
orthogonal. There's nothing here
enforcing orthogonality,

692
00:17:46,150 --> 00:17:46,160
enforcing orthogonality,
 

693
00:17:46,160 --> 00:17:47,990
enforcing orthogonality,
right? So you're going to get something

694
00:17:47,990 --> 00:17:48,000
right? So you're going to get something
 

695
00:17:48,000 --> 00:17:51,430
right? So you're going to get something
projecting into K dimensions. Um

696
00:17:51,430 --> 00:17:51,440
projecting into K dimensions. Um
 

697
00:17:51,440 --> 00:17:52,950
projecting into K dimensions. Um
but you definitely don't need to do any

698
00:17:52,950 --> 00:17:52,960
but you definitely don't need to do any
 

699
00:17:52,960 --> 00:17:54,470
but you definitely don't need to do any
weight ting to say that this is kind of

700
00:17:54,470 --> 00:17:54,480
weight ting to say that this is kind of
 

701
00:17:54,480 --> 00:17:57,669
weight ting to say that this is kind of
the opposite of that. It's just enforced

702
00:17:57,669 --> 00:17:57,679
the opposite of that. It's just enforced
 

703
00:17:57,679 --> 00:18:04,230
the opposite of that. It's just enforced
by itself.

704
00:18:04,230 --> 00:18:04,240

 

705
00:18:04,240 --> 00:18:08,150

Okay. So what I want to do next is

706
00:18:08,150 --> 00:18:08,160
Okay. So what I want to do next is
 

707
00:18:08,160 --> 00:18:10,549
Okay. So what I want to do next is
just show you some pictures of this

708
00:18:10,549 --> 00:18:10,559
just show you some pictures of this
 

709
00:18:10,559 --> 00:18:12,950
just show you some pictures of this
idea. So now you have this idea, right,

710
00:18:12,950 --> 00:18:12,960
idea. So now you have this idea, right,
 

711
00:18:12,960 --> 00:18:17,110
idea. So now you have this idea, right,
of doing this kind of thing.

712
00:18:17,110 --> 00:18:17,120
of doing this kind of thing.
 

713
00:18:17,120 --> 00:18:20,070
of doing this kind of thing.
encode, decode, have a bottleneck or

714
00:18:20,070 --> 00:18:20,080
encode, decode, have a bottleneck or
 

715
00:18:20,080 --> 00:18:22,870
encode, decode, have a bottleneck or
something in between and autoenccoder.

716
00:18:22,870 --> 00:18:22,880
something in between and autoenccoder.
 

717
00:18:22,880 --> 00:18:24,710
something in between and autoenccoder.
Now, nothing is saying that we have to

718
00:18:24,710 --> 00:18:24,720
Now, nothing is saying that we have to
 

719
00:18:24,720 --> 00:18:27,909
Now, nothing is saying that we have to
make the structure of the encoder just

720
00:18:27,909 --> 00:18:27,919
make the structure of the encoder just
 

721
00:18:27,919 --> 00:18:33,350
make the structure of the encoder just
be one matrix,

722
00:18:33,350 --> 00:18:33,360

 

723
00:18:33,360 --> 00:18:35,350

right? Nothing is I mean for PCA it's

724
00:18:35,350 --> 00:18:35,360
right? Nothing is I mean for PCA it's
 

725
00:18:35,360 --> 00:18:37,430
right? Nothing is I mean for PCA it's
one matrix. We want a linear projection

726
00:18:37,430 --> 00:18:37,440
one matrix. We want a linear projection
 

727
00:18:37,440 --> 00:18:39,029
one matrix. We want a linear projection
because we wanted a linear projection.

728
00:18:39,029 --> 00:18:39,039
because we wanted a linear projection.
 

729
00:18:39,039 --> 00:18:42,310
because we wanted a linear projection.
We chose to learn a linear projection.

730
00:18:42,310 --> 00:18:42,320
We chose to learn a linear projection.
 

731
00:18:42,320 --> 00:18:45,350
We chose to learn a linear projection.
But if you're happy, if you have some

732
00:18:45,350 --> 00:18:45,360
But if you're happy, if you have some
 

733
00:18:45,360 --> 00:18:47,029
But if you're happy, if you have some
other aspect of what you think, some

734
00:18:47,029 --> 00:18:47,039
other aspect of what you think, some
 

735
00:18:47,039 --> 00:18:48,549
other aspect of what you think, some
other knowledge of what you think the

736
00:18:48,549 --> 00:18:48,559
other knowledge of what you think the
 

737
00:18:48,559 --> 00:18:50,230
other knowledge of what you think the
underlying regularities are, you're

738
00:18:50,230 --> 00:18:50,240
underlying regularities are, you're
 

739
00:18:50,240 --> 00:18:52,390
underlying regularities are, you're
allowed to bring any neural net you want

740
00:18:52,390 --> 00:18:52,400
allowed to bring any neural net you want
 

741
00:18:52,400 --> 00:18:55,669
allowed to bring any neural net you want
into the encoder and the decoder. As

742
00:18:55,669 --> 00:18:55,679
into the encoder and the decoder. As
 

743
00:18:55,679 --> 00:18:57,350
into the encoder and the decoder. As
long as you have this architecture of

744
00:18:57,350 --> 00:18:57,360
long as you have this architecture of
 

745
00:18:57,360 --> 00:19:00,150
long as you have this architecture of
having an input followed by an encoder

746
00:19:00,150 --> 00:19:00,160
having an input followed by an encoder
 

747
00:19:00,160 --> 00:19:01,590
having an input followed by an encoder
that goes into something that's like a

748
00:19:01,590 --> 00:19:01,600
that goes into something that's like a
 

749
00:19:01,600 --> 00:19:04,070
that goes into something that's like a
bottleneck and then a decoder and you

750
00:19:04,070 --> 00:19:04,080
bottleneck and then a decoder and you
 

751
00:19:04,080 --> 00:19:06,549
bottleneck and then a decoder and you
and you have the loss be with the label

752
00:19:06,549 --> 00:19:06,559
and you have the loss be with the label
 

753
00:19:06,559 --> 00:19:07,990
and you have the loss be with the label
that's the same as the input, you're in

754
00:19:07,990 --> 00:19:08,000
that's the same as the input, you're in
 

755
00:19:08,000 --> 00:19:11,350
that's the same as the input, you're in
autoenccoder land.

756
00:19:11,350 --> 00:19:11,360
autoenccoder land.
 

757
00:19:11,360 --> 00:19:12,870
autoenccoder land.
So now let's just see it with some

758
00:19:12,870 --> 00:19:12,880
So now let's just see it with some
 

759
00:19:12,880 --> 00:19:14,789
So now let's just see it with some
pictures. So these are some great

760
00:19:14,789 --> 00:19:14,799
pictures. So these are some great
 

761
00:19:14,799 --> 00:19:16,950
pictures. So these are some great
pictures from uh Sergey Livian's

762
00:19:16,950 --> 00:19:16,960
pictures from uh Sergey Livian's
 

763
00:19:16,960 --> 00:19:20,870
pictures from uh Sergey Livian's
lectures 22 from 2021.

764
00:19:20,870 --> 00:19:20,880
lectures 22 from 2021.
 

765
00:19:20,880 --> 00:19:25,590
lectures 22 from 2021.
So it says okay let's think about this.

766
00:19:25,590 --> 00:19:25,600
So it says okay let's think about this.
 

767
00:19:25,600 --> 00:19:27,830
So it says okay let's think about this.
You can do this for images. So for an

768
00:19:27,830 --> 00:19:27,840
You can do this for images. So for an
 

769
00:19:27,840 --> 00:19:31,830
You can do this for images. So for an
image what's going on here is images go

770
00:19:31,830 --> 00:19:31,840
image what's going on here is images go
 

771
00:19:31,840 --> 00:19:34,789
image what's going on here is images go
in and the encoder is presumably some

772
00:19:34,789 --> 00:19:34,799
in and the encoder is presumably some
 

773
00:19:34,799 --> 00:19:36,390
in and the encoder is presumably some
kind of neural net architecture that's

774
00:19:36,390 --> 00:19:36,400
kind of neural net architecture that's
 

775
00:19:36,400 --> 00:19:39,669
kind of neural net architecture that's
tied to images like a CNN.

776
00:19:39,669 --> 00:19:39,679
tied to images like a CNN.
 

777
00:19:39,679 --> 00:19:42,230
tied to images like a CNN.
So you have an encoder and then you go

778
00:19:42,230 --> 00:19:42,240
So you have an encoder and then you go
 

779
00:19:42,240 --> 00:19:45,590
So you have an encoder and then you go
to some hidden smaller dimensional thing

780
00:19:45,590 --> 00:19:45,600
to some hidden smaller dimensional thing
 

781
00:19:45,600 --> 00:19:48,549
to some hidden smaller dimensional thing
for example 128. So this is a 100 by 100

782
00:19:48,549 --> 00:19:48,559
for example 128. So this is a 100 by 100
 

783
00:19:48,559 --> 00:19:50,789
for example 128. So this is a 100 by 100
image. So it's if it was black and white

784
00:19:50,789 --> 00:19:50,799
image. So it's if it was black and white
 

785
00:19:50,799 --> 00:19:53,909
image. So it's if it was black and white
it would be 10,000 uh dimensional. If it

786
00:19:53,909 --> 00:19:53,919
it would be 10,000 uh dimensional. If it
 

787
00:19:53,919 --> 00:19:56,150
it would be 10,000 uh dimensional. If it
was color like this picture is it would

788
00:19:56,150 --> 00:19:56,160
was color like this picture is it would
 

789
00:19:56,160 --> 00:19:58,549
was color like this picture is it would
be 30,000 dimensional.

790
00:19:58,549 --> 00:19:58,559
be 30,000 dimensional.
 

791
00:19:58,559 --> 00:20:01,669
be 30,000 dimensional.
And then you just map it down to a small

792
00:20:01,669 --> 00:20:01,679
And then you just map it down to a small
 

793
00:20:01,679 --> 00:20:04,470
And then you just map it down to a small
space that's 128. So these kind of small

794
00:20:04,470 --> 00:20:04,480
space that's 128. So these kind of small
 

795
00:20:04,480 --> 00:20:06,150
space that's 128. So these kind of small
spaces are sometimes just called latent

796
00:20:06,150 --> 00:20:06,160
spaces are sometimes just called latent
 

797
00:20:06,160 --> 00:20:09,590
spaces are sometimes just called latent
spaces from kind of the generative model

798
00:20:09,590 --> 00:20:09,600
spaces from kind of the generative model
 

799
00:20:09,600 --> 00:20:13,669
spaces from kind of the generative model
uh tradition uh point of view.

800
00:20:13,669 --> 00:20:13,679
uh tradition uh point of view.
 

801
00:20:13,679 --> 00:20:15,669
uh tradition uh point of view.
So you have this output. Now you want

802
00:20:15,669 --> 00:20:15,679
So you have this output. Now you want
 

803
00:20:15,679 --> 00:20:17,270
So you have this output. Now you want
this to be the desired output. So this

804
00:20:17,270 --> 00:20:17,280
this to be the desired output. So this
 

805
00:20:17,280 --> 00:20:19,029
this to be the desired output. So this
is the label just copied over what was

806
00:20:19,029 --> 00:20:19,039
is the label just copied over what was
 

807
00:20:19,039 --> 00:20:21,110
is the label just copied over what was
here.

808
00:20:21,110 --> 00:20:21,120
here.
 

809
00:20:21,120 --> 00:20:23,669
here.
So you have to use a loss. So you can

810
00:20:23,669 --> 00:20:23,679
So you have to use a loss. So you can
 

811
00:20:23,679 --> 00:20:25,750
So you have to use a loss. So you can
use any relevant loss function to train

812
00:20:25,750 --> 00:20:25,760
use any relevant loss function to train
 

813
00:20:25,760 --> 00:20:27,350
use any relevant loss function to train
this.

814
00:20:27,350 --> 00:20:27,360
this.
 

815
00:20:27,360 --> 00:20:30,149
this.
So for images for example you could say

816
00:20:30,149 --> 00:20:30,159
So for images for example you could say
 

817
00:20:30,159 --> 00:20:33,510
So for images for example you could say
I just do mean squared error on RGB.

818
00:20:33,510 --> 00:20:33,520
I just do mean squared error on RGB.
 

819
00:20:33,520 --> 00:20:35,669
I just do mean squared error on RGB.
That's totally reasonable. Um, but you

820
00:20:35,669 --> 00:20:35,679
That's totally reasonable. Um, but you
 

821
00:20:35,679 --> 00:20:38,230
That's totally reasonable. Um, but you
can do other things, right? Any loss

822
00:20:38,230 --> 00:20:38,240
can do other things, right? Any loss
 

823
00:20:38,240 --> 00:20:39,430
can do other things, right? Any loss
that you think is reasonable for your

824
00:20:39,430 --> 00:20:39,440
that you think is reasonable for your
 

825
00:20:39,440 --> 00:20:41,990
that you think is reasonable for your
application can be used. What happens?

826
00:20:41,990 --> 00:20:42,000
application can be used. What happens?
 

827
00:20:42,000 --> 00:20:44,549
application can be used. What happens?
You have a loss. You will then get

828
00:20:44,549 --> 00:20:44,559
You have a loss. You will then get
 

829
00:20:44,559 --> 00:20:46,950
You have a loss. You will then get
gradients. Everything is a neural net

830
00:20:46,950 --> 00:20:46,960
gradients. Everything is a neural net
 

831
00:20:46,960 --> 00:20:48,630
gradients. Everything is a neural net
and so is differentable. So the

832
00:20:48,630 --> 00:20:48,640
and so is differentable. So the
 

833
00:20:48,640 --> 00:20:50,230
and so is differentable. So the
gradients will back prop through here.

834
00:20:50,230 --> 00:20:50,240
gradients will back prop through here.
 

835
00:20:50,240 --> 00:20:52,390
gradients will back prop through here.
They can train this thing. They will go

836
00:20:52,390 --> 00:20:52,400
They can train this thing. They will go
 

837
00:20:52,400 --> 00:20:55,350
They can train this thing. They will go
here. They will go back here. They will

838
00:20:55,350 --> 00:20:55,360
here. They will go back here. They will
 

839
00:20:55,360 --> 00:20:56,870
here. They will go back here. They will
train this thing and everything will

840
00:20:56,870 --> 00:20:56,880
train this thing and everything will
 

841
00:20:56,880 --> 00:20:59,029
train this thing and everything will
just keep training.

842
00:20:59,029 --> 00:20:59,039
just keep training.
 

843
00:20:59,039 --> 00:21:02,230
just keep training.
So historically autoenccoders um

844
00:21:02,230 --> 00:21:02,240
So historically autoenccoders um
 

845
00:21:02,240 --> 00:21:04,470
So historically autoenccoders um
actually came out right they were

846
00:21:04,470 --> 00:21:04,480
actually came out right they were
 

847
00:21:04,480 --> 00:21:06,470
actually came out right they were
they've been known for a very long time

848
00:21:06,470 --> 00:21:06,480
they've been known for a very long time
 

849
00:21:06,480 --> 00:21:09,510
they've been known for a very long time
and this style of training was very

850
00:21:09,510 --> 00:21:09,520
and this style of training was very
 

851
00:21:09,520 --> 00:21:13,029
and this style of training was very
popular at the very initial parts of the

852
00:21:13,029 --> 00:21:13,039
popular at the very initial parts of the
 

853
00:21:13,039 --> 00:21:15,270
popular at the very initial parts of the
current age of deep networks where

854
00:21:15,270 --> 00:21:15,280
current age of deep networks where
 

855
00:21:15,280 --> 00:21:17,750
current age of deep networks where
people didn't know if they could get

856
00:21:17,750 --> 00:21:17,760
people didn't know if they could get
 

857
00:21:17,760 --> 00:21:20,870
people didn't know if they could get
endto-end training with a loss working

858
00:21:20,870 --> 00:21:20,880
endto-end training with a loss working
 

859
00:21:20,880 --> 00:21:22,630
endto-end training with a loss working
and so they would do autoenccoders at

860
00:21:22,630 --> 00:21:22,640
and so they would do autoenccoders at
 

861
00:21:22,640 --> 00:21:24,310
and so they would do autoenccoders at
different layers to kind of stage

862
00:21:24,310 --> 00:21:24,320
different layers to kind of stage
 

863
00:21:24,320 --> 00:21:26,070
different layers to kind of stage
layerwise build up some initial

864
00:21:26,070 --> 00:21:26,080
layerwise build up some initial
 

865
00:21:26,080 --> 00:21:27,830
layerwise build up some initial
condition first that they thought was a

866
00:21:27,830 --> 00:21:27,840
condition first that they thought was a
 

867
00:21:27,840 --> 00:21:29,510
condition first that they thought was a
good initial condition and then they

868
00:21:29,510 --> 00:21:29,520
good initial condition and then they
 

869
00:21:29,520 --> 00:21:31,750
good initial condition and then they
would train end to end from that point.

870
00:21:31,750 --> 00:21:31,760
would train end to end from that point.
 

871
00:21:31,760 --> 00:21:33,990
would train end to end from that point.
Um but then that went away once people

872
00:21:33,990 --> 00:21:34,000
Um but then that went away once people
 

873
00:21:34,000 --> 00:21:35,110
Um but then that went away once people
figured out how to make endtoend

874
00:21:35,110 --> 00:21:35,120
figured out how to make endtoend
 

875
00:21:35,120 --> 00:21:37,669
figured out how to make endtoend
training work. Um but in an interesting

876
00:21:37,669 --> 00:21:37,679
training work. Um but in an interesting
 

877
00:21:37,679 --> 00:21:40,549
training work. Um but in an interesting
way as we'll talk about later the modern

878
00:21:40,549 --> 00:21:40,559
way as we'll talk about later the modern
 

879
00:21:40,559 --> 00:21:42,310
way as we'll talk about later the modern
perspective of foundation models in is

880
00:21:42,310 --> 00:21:42,320
perspective of foundation models in is
 

881
00:21:42,320 --> 00:21:44,149
perspective of foundation models in is
in a way a return to the idea of

882
00:21:44,149 --> 00:21:44,159
in a way a return to the idea of
 

883
00:21:44,159 --> 00:21:46,149
in a way a return to the idea of
autoenccoding as the right way to set

884
00:21:46,149 --> 00:21:46,159
autoenccoding as the right way to set
 

885
00:21:46,159 --> 00:21:49,430
autoenccoding as the right way to set
your initial conditions.

886
00:21:49,430 --> 00:21:49,440
your initial conditions.
 

887
00:21:49,440 --> 00:21:51,430
your initial conditions.
Okay. So

888
00:21:51,430 --> 00:21:51,440
Okay. So
 

889
00:21:51,440 --> 00:21:54,070
Okay. So
again this is a we call this the classic

890
00:21:54,070 --> 00:21:54,080
again this is a we call this the classic
 

891
00:21:54,080 --> 00:21:56,310
again this is a we call this the classic
vanilla autoenccoder.

892
00:21:56,310 --> 00:21:56,320
vanilla autoenccoder.
 

893
00:21:56,320 --> 00:21:59,750
vanilla autoenccoder.
But once you have this picture, you're

894
00:21:59,750 --> 00:21:59,760
But once you have this picture, you're
 

895
00:21:59,760 --> 00:22:01,990
But once you have this picture, you're
actually you should think, okay, I can

896
00:22:01,990 --> 00:22:02,000
actually you should think, okay, I can
 

897
00:22:02,000 --> 00:22:05,190
actually you should think, okay, I can
bring all of the tricks that I know to

898
00:22:05,190 --> 00:22:05,200
bring all of the tricks that I know to
 

899
00:22:05,200 --> 00:22:07,430
bring all of the tricks that I know to
bear.

900
00:22:07,430 --> 00:22:07,440
bear.
 

901
00:22:07,440 --> 00:22:11,110
bear.
So in this case, what's happening is the

902
00:22:11,110 --> 00:22:11,120
So in this case, what's happening is the
 

903
00:22:11,120 --> 00:22:13,830
So in this case, what's happening is the
regularity that you want is being

904
00:22:13,830 --> 00:22:13,840
regularity that you want is being
 

905
00:22:13,840 --> 00:22:15,510
regularity that you want is being
expressed

906
00:22:15,510 --> 00:22:15,520
expressed
 

907
00:22:15,520 --> 00:22:17,510
expressed
using

908
00:22:17,510 --> 00:22:17,520
using
 

909
00:22:17,520 --> 00:22:19,669
using
the architecture.

910
00:22:19,669 --> 00:22:19,679
the architecture.
 

911
00:22:19,679 --> 00:22:21,590
the architecture.
So you say your architecture is a connet

912
00:22:21,590 --> 00:22:21,600
So you say your architecture is a connet
 

913
00:22:21,600 --> 00:22:23,029
So you say your architecture is a connet
because you think the things you want

914
00:22:23,029 --> 00:22:23,039
because you think the things you want
 

915
00:22:23,039 --> 00:22:25,350
because you think the things you want
are captured by this locality and so on

916
00:22:25,350 --> 00:22:25,360
are captured by this locality and so on
 

917
00:22:25,360 --> 00:22:28,149
are captured by this locality and so on
that we did to derive connets.

918
00:22:28,149 --> 00:22:28,159
that we did to derive connets.
 

919
00:22:28,159 --> 00:22:31,750
that we did to derive connets.
But we learned that there's two other

920
00:22:31,750 --> 00:22:31,760
But we learned that there's two other
 

921
00:22:31,760 --> 00:22:35,750
But we learned that there's two other
ways that we can think about encoding

922
00:22:35,750 --> 00:22:35,760
ways that we can think about encoding
 

923
00:22:35,760 --> 00:22:39,750
ways that we can think about encoding
the regularities that we want.

924
00:22:39,750 --> 00:22:39,760
the regularities that we want.
 

925
00:22:39,760 --> 00:22:42,230
the regularities that we want.
Right? So

926
00:22:42,230 --> 00:22:42,240
Right? So
 

927
00:22:42,240 --> 00:22:44,390
Right? So
what what what are some of those ways?

928
00:22:44,390 --> 00:22:44,400
what what what are some of those ways?
 

929
00:22:44,400 --> 00:22:46,470
what what what are some of those ways?
So here's one.

930
00:22:46,470 --> 00:22:46,480
So here's one.
 

931
00:22:46,480 --> 00:22:47,909
So here's one.
Okay. So this is called a sparse

932
00:22:47,909 --> 00:22:47,919
Okay. So this is called a sparse
 

933
00:22:47,919 --> 00:22:50,230
Okay. So this is called a sparse
autoenccoder.

934
00:22:50,230 --> 00:22:50,240
autoenccoder.
 

935
00:22:50,240 --> 00:22:53,750
autoenccoder.
So in a sparse autoenccoder

936
00:22:53,750 --> 00:22:53,760
So in a sparse autoenccoder
 

937
00:22:53,760 --> 00:22:55,669
So in a sparse autoenccoder
what we're going to do is we're going to

938
00:22:55,669 --> 00:22:55,679
what we're going to do is we're going to
 

939
00:22:55,679 --> 00:22:57,669
what we're going to do is we're going to
take the

940
00:22:57,669 --> 00:22:57,679
take the
 

941
00:22:57,679 --> 00:23:00,310
take the
input same as before it's the label

942
00:23:00,310 --> 00:23:00,320
input same as before it's the label
 

943
00:23:00,320 --> 00:23:03,350
input same as before it's the label
outside except now instead of saying

944
00:23:03,350 --> 00:23:03,360
outside except now instead of saying
 

945
00:23:03,360 --> 00:23:05,990
outside except now instead of saying
that I'm going to go to something which

946
00:23:05,990 --> 00:23:06,000
that I'm going to go to something which
 

947
00:23:06,000 --> 00:23:08,710
that I'm going to go to something which
is much smaller a bottleneck I'll go to

948
00:23:08,710 --> 00:23:08,720
is much smaller a bottleneck I'll go to
 

949
00:23:08,720 --> 00:23:13,669
is much smaller a bottleneck I'll go to
something that's potentially even bigger

950
00:23:13,669 --> 00:23:13,679

 

951
00:23:13,679 --> 00:23:15,190

however

952
00:23:15,190 --> 00:23:15,200
however
 

953
00:23:15,200 --> 00:23:17,270
however
what I'm going to do is to make this

954
00:23:17,270 --> 00:23:17,280
what I'm going to do is to make this
 

955
00:23:17,280 --> 00:23:19,750
what I'm going to do is to make this
bottleneck actually be a bottle neck is

956
00:23:19,750 --> 00:23:19,760
bottleneck actually be a bottle neck is
 

957
00:23:19,760 --> 00:23:23,270
bottleneck actually be a bottle neck is
I'm going to try to impose an auxiliary

958
00:23:23,270 --> 00:23:23,280
I'm going to try to impose an auxiliary
 

959
00:23:23,280 --> 00:23:24,710
I'm going to try to impose an auxiliary
loss. So remember we introduced this

960
00:23:24,710 --> 00:23:24,720
loss. So remember we introduced this
 

961
00:23:24,720 --> 00:23:26,549
loss. So remember we introduced this
idea of auxiliary losses right as a way

962
00:23:26,549 --> 00:23:26,559
idea of auxiliary losses right as a way
 

963
00:23:26,559 --> 00:23:28,710
idea of auxiliary losses right as a way
to capture when we're talking about the

964
00:23:28,710 --> 00:23:28,720
to capture when we're talking about the
 

965
00:23:28,720 --> 00:23:30,870
to capture when we're talking about the
diff pool right you can capture

966
00:23:30,870 --> 00:23:30,880
diff pool right you can capture
 

967
00:23:30,880 --> 00:23:33,669
diff pool right you can capture
regularity you want using auxiliary

968
00:23:33,669 --> 00:23:33,679
regularity you want using auxiliary
 

969
00:23:33,679 --> 00:23:36,230
regularity you want using auxiliary
losses also so we can use the auxiliary

970
00:23:36,230 --> 00:23:36,240
losses also so we can use the auxiliary
 

971
00:23:36,240 --> 00:23:39,110
losses also so we can use the auxiliary
loss idea here

972
00:23:39,110 --> 00:23:39,120
loss idea here
 

973
00:23:39,120 --> 00:23:41,590
loss idea here
so in the auxiliary loss idea what we

974
00:23:41,590 --> 00:23:41,600
so in the auxiliary loss idea what we
 

975
00:23:41,600 --> 00:23:43,590
so in the auxiliary loss idea what we
can do is we can just take this thing

976
00:23:43,590 --> 00:23:43,600
can do is we can just take this thing
 

977
00:23:43,600 --> 00:23:47,110
can do is we can just take this thing
and we can stick on

978
00:23:47,110 --> 00:23:47,120
and we can stick on
 

979
00:23:47,120 --> 00:23:49,830
and we can stick on
an auxiliary loss

980
00:23:49,830 --> 00:23:49,840
an auxiliary loss
 

981
00:23:49,840 --> 00:23:52,149
an auxiliary loss
that

982
00:23:52,149 --> 00:23:52,159
that
 

983
00:23:52,159 --> 00:23:59,669
that
is sparsity seeking

984
00:23:59,669 --> 00:23:59,679

 

985
00:23:59,679 --> 00:24:01,669

So you saw in your optimization class

986
00:24:01,669 --> 00:24:01,679
So you saw in your optimization class
 

987
00:24:01,679 --> 00:24:03,669
So you saw in your optimization class
for example that we could use an L1

988
00:24:03,669 --> 00:24:03,679
for example that we could use an L1
 

989
00:24:03,679 --> 00:24:15,750
for example that we could use an L1
loss.

990
00:24:15,750 --> 00:24:15,760

 

991
00:24:15,760 --> 00:24:19,190

So we can say go ahead and encode it

992
00:24:19,190 --> 00:24:19,200
So we can say go ahead and encode it
 

993
00:24:19,200 --> 00:24:21,830
So we can say go ahead and encode it
into this large vector except I'm going

994
00:24:21,830 --> 00:24:21,840
into this large vector except I'm going
 

995
00:24:21,840 --> 00:24:27,430
into this large vector except I'm going
to penalize the L1 norm of this vector.

996
00:24:27,430 --> 00:24:27,440

 

997
00:24:27,440 --> 00:24:29,590

Okay. And what that will do is again

998
00:24:29,590 --> 00:24:29,600
Okay. And what that will do is again
 

999
00:24:29,600 --> 00:24:31,590
Okay. And what that will do is again
you'll have gradients that are going

1000
00:24:31,590 --> 00:24:31,600
you'll have gradients that are going
 

1001
00:24:31,600 --> 00:24:33,909
you'll have gradients that are going
from the standard loss back but you'll

1002
00:24:33,909 --> 00:24:33,919
from the standard loss back but you'll
 

1003
00:24:33,919 --> 00:24:35,510
from the standard loss back but you'll
also have gradients coming from the L1

1004
00:24:35,510 --> 00:24:35,520
also have gradients coming from the L1
 

1005
00:24:35,520 --> 00:24:38,390
also have gradients coming from the L1
loss back.

1006
00:24:38,390 --> 00:24:38,400
loss back.
 

1007
00:24:38,400 --> 00:24:40,230
loss back.
And if you remember the intuition of L1

1008
00:24:40,230 --> 00:24:40,240
And if you remember the intuition of L1
 

1009
00:24:40,240 --> 00:24:43,350
And if you remember the intuition of L1
loss, the L1 loss says, look,

1010
00:24:43,350 --> 00:24:43,360
loss, the L1 loss says, look,
 

1011
00:24:43,360 --> 00:24:45,990
loss, the L1 loss says, look,
I penalize everything, every dimension

1012
00:24:45,990 --> 00:24:46,000
I penalize everything, every dimension
 

1013
00:24:46,000 --> 00:24:48,710
I penalize everything, every dimension
is penalized by the same negative

1014
00:24:48,710 --> 00:24:48,720
is penalized by the same negative
 

1015
00:24:48,720 --> 00:24:50,630
is penalized by the same negative
weight, right? Like everything I want to

1016
00:24:50,630 --> 00:24:50,640
weight, right? Like everything I want to
 

1017
00:24:50,640 --> 00:24:53,029
weight, right? Like everything I want to
push it down. So it basically says if

1018
00:24:53,029 --> 00:24:53,039
push it down. So it basically says if
 

1019
00:24:53,039 --> 00:24:56,070
push it down. So it basically says if
this particular entry isn't pulling its

1020
00:24:56,070 --> 00:24:56,080
this particular entry isn't pulling its
 

1021
00:24:56,080 --> 00:24:58,549
this particular entry isn't pulling its
weight relative to the others, it'll

1022
00:24:58,549 --> 00:24:58,559
weight relative to the others, it'll
 

1023
00:24:58,559 --> 00:25:01,350
weight relative to the others, it'll
just be driven down to zero.

1024
00:25:01,350 --> 00:25:01,360
just be driven down to zero.
 

1025
00:25:01,360 --> 00:25:02,789
just be driven down to zero.
Okay? And so that's the kind of what's

1026
00:25:02,789 --> 00:25:02,799
Okay? And so that's the kind of what's
 

1027
00:25:02,799 --> 00:25:04,470
Okay? And so that's the kind of what's
the intuition for the sparsity seeking

1028
00:25:04,470 --> 00:25:04,480
the intuition for the sparsity seeking
 

1029
00:25:04,480 --> 00:25:07,269
the intuition for the sparsity seeking
behavior of L1 loss. Whereas L2 loss,

1030
00:25:07,269 --> 00:25:07,279
behavior of L1 loss. Whereas L2 loss,
 

1031
00:25:07,279 --> 00:25:08,630
behavior of L1 loss. Whereas L2 loss,
the smaller it is, the less it's

1032
00:25:08,630 --> 00:25:08,640
the smaller it is, the less it's
 

1033
00:25:08,640 --> 00:25:10,549
the smaller it is, the less it's
penalized. So there's no reason to drive

1034
00:25:10,549 --> 00:25:10,559
penalized. So there's no reason to drive
 

1035
00:25:10,559 --> 00:25:12,789
penalized. So there's no reason to drive
it all the way to zero. But in L1 loss,

1036
00:25:12,789 --> 00:25:12,799
it all the way to zero. But in L1 loss,
 

1037
00:25:12,799 --> 00:25:15,750
it all the way to zero. But in L1 loss,
it's being penalized constantly to the

1038
00:25:15,750 --> 00:25:15,760
it's being penalized constantly to the
 

1039
00:25:15,760 --> 00:25:17,510
it's being penalized constantly to the
same amount.

1040
00:25:17,510 --> 00:25:17,520
same amount.
 

1041
00:25:17,520 --> 00:25:19,190
same amount.
Okay, so this is a way to have a sparse

1042
00:25:19,190 --> 00:25:19,200
Okay, so this is a way to have a sparse
 

1043
00:25:19,200 --> 00:25:20,710
Okay, so this is a way to have a sparse
autoenccoder. Any questions on sparse

1044
00:25:20,710 --> 00:25:20,720
autoenccoder. Any questions on sparse
 

1045
00:25:20,720 --> 00:25:25,430
autoenccoder. Any questions on sparse
autoenccoding?

1046
00:25:25,430 --> 00:25:25,440

 

1047
00:25:25,440 --> 00:25:27,590

Okay, so here we use the auxiliary loss

1048
00:25:27,590 --> 00:25:27,600
Okay, so here we use the auxiliary loss
 

1049
00:25:27,600 --> 00:25:30,789
Okay, so here we use the auxiliary loss
idea to to express the regularity. So

1050
00:25:30,789 --> 00:25:30,799
idea to to express the regularity. So
 

1051
00:25:30,799 --> 00:25:32,789
idea to to express the regularity. So
what is the regularity here? By saying

1052
00:25:32,789 --> 00:25:32,799
what is the regularity here? By saying
 

1053
00:25:32,799 --> 00:25:39,029
what is the regularity here? By saying
this is sparse, we're saying that look

1054
00:25:39,029 --> 00:25:39,039

 

1055
00:25:39,039 --> 00:25:44,310

whatever this is, it's some mixture of a

1056
00:25:44,310 --> 00:25:44,320
whatever this is, it's some mixture of a
 

1057
00:25:44,320 --> 00:25:46,789
whatever this is, it's some mixture of a
few small fewer degrees of freedom that

1058
00:25:46,789 --> 00:25:46,799
few small fewer degrees of freedom that
 

1059
00:25:46,799 --> 00:25:49,750
few small fewer degrees of freedom that
are being adjusted. So in here you think

1060
00:25:49,750 --> 00:25:49,760
are being adjusted. So in here you think
 

1061
00:25:49,760 --> 00:25:51,430
are being adjusted. So in here you think
maybe from an interpretability point of

1062
00:25:51,430 --> 00:25:51,440
maybe from an interpretability point of
 

1063
00:25:51,440 --> 00:25:54,710
maybe from an interpretability point of
view that one of the entries here is

1064
00:25:54,710 --> 00:25:54,720
view that one of the entries here is
 

1065
00:25:54,720 --> 00:25:56,789
view that one of the entries here is
like doggginess,

1066
00:25:56,789 --> 00:25:56,799
like doggginess,
 

1067
00:25:56,799 --> 00:25:58,070
like doggginess,
right? And there's like a little

1068
00:25:58,070 --> 00:25:58,080
right? And there's like a little
 

1069
00:25:58,080 --> 00:25:59,590
right? And there's like a little
collection, a few of them that kind of

1070
00:25:59,590 --> 00:25:59,600
collection, a few of them that kind of
 

1071
00:25:59,600 --> 00:26:02,230
collection, a few of them that kind of
tells you what kind of dog,

1072
00:26:02,230 --> 00:26:02,240
tells you what kind of dog,
 

1073
00:26:02,240 --> 00:26:03,909
tells you what kind of dog,
right? And you wanted to basically say,

1074
00:26:03,909 --> 00:26:03,919
right? And you wanted to basically say,
 

1075
00:26:03,919 --> 00:26:05,590
right? And you wanted to basically say,
okay, this is like and then something

1076
00:26:05,590 --> 00:26:05,600
okay, this is like and then something
 

1077
00:26:05,600 --> 00:26:06,950
okay, this is like and then something
which kind of centers it and like some

1078
00:26:06,950 --> 00:26:06,960
which kind of centers it and like some
 

1079
00:26:06,960 --> 00:26:08,070
which kind of centers it and like some
things that are telling you like where

1080
00:26:08,070 --> 00:26:08,080
things that are telling you like where
 

1081
00:26:08,080 --> 00:26:10,470
things that are telling you like where
this thing is located. So if you have

1082
00:26:10,470 --> 00:26:10,480
this thing is located. So if you have
 

1083
00:26:10,480 --> 00:26:11,830
this thing is located. So if you have
described this in natural language,

1084
00:26:11,830 --> 00:26:11,840
described this in natural language,
 

1085
00:26:11,840 --> 00:26:13,830
described this in natural language,
you'll naturally kind of go for a sparse

1086
00:26:13,830 --> 00:26:13,840
you'll naturally kind of go for a sparse
 

1087
00:26:13,840 --> 00:26:15,830
you'll naturally kind of go for a sparse
type of description. So this is trying

1088
00:26:15,830 --> 00:26:15,840
type of description. So this is trying
 

1089
00:26:15,840 --> 00:26:18,149
type of description. So this is trying
to encourage that and that's why this is

1090
00:26:18,149 --> 00:26:18,159
to encourage that and that's why this is
 

1091
00:26:18,159 --> 00:26:19,750
to encourage that and that's why this is
a bottleneck. The sparsity is what's

1092
00:26:19,750 --> 00:26:19,760
a bottleneck. The sparsity is what's
 

1093
00:26:19,760 --> 00:26:21,110
a bottleneck. The sparsity is what's
creating the bottleneck.

1094
00:26:21,110 --> 00:26:21,120
creating the bottleneck.
 

1095
00:26:21,120 --> 00:26:27,750
creating the bottleneck.
>> Yeah. So this is the desired results

1096
00:26:27,750 --> 00:26:27,760

 

1097
00:26:27,760 --> 00:26:29,750

of a couple

1098
00:26:29,750 --> 00:26:29,760
of a couple
 

1099
00:26:29,760 --> 00:26:36,549
of a couple
of zero entries.

1100
00:26:36,549 --> 00:26:36,559

 

1101
00:26:36,559 --> 00:26:37,990

>> Oh yeah, great question. The question is

1102
00:26:37,990 --> 00:26:38,000
>> Oh yeah, great question. The question is
 

1103
00:26:38,000 --> 00:26:40,630
>> Oh yeah, great question. The question is
at the end of the day if I have a 128

1104
00:26:40,630 --> 00:26:40,640
at the end of the day if I have a 128
 

1105
00:26:40,640 --> 00:26:44,230
at the end of the day if I have a 128
dimensional vector or I have a 1 million

1106
00:26:44,230 --> 00:26:44,240
dimensional vector or I have a 1 million
 

1107
00:26:44,240 --> 00:26:46,390
dimensional vector or I have a 1 million
dimensional vector that only has 128

1108
00:26:46,390 --> 00:26:46,400
dimensional vector that only has 128
 

1109
00:26:46,400 --> 00:26:47,909
dimensional vector that only has 128
non-zero entries,

1110
00:26:47,909 --> 00:26:47,919
non-zero entries,
 

1111
00:26:47,919 --> 00:26:50,070
non-zero entries,
>> are these basically the same thing?

1112
00:26:50,070 --> 00:26:50,080
>> are these basically the same thing?
 

1113
00:26:50,080 --> 00:26:52,549
>> are these basically the same thing?
Right? The answer is almost. But there's

1114
00:26:52,549 --> 00:26:52,559
Right? The answer is almost. But there's
 

1115
00:26:52,559 --> 00:26:54,710
Right? The answer is almost. But there's
a big difference in that if you have a

1116
00:26:54,710 --> 00:26:54,720
a big difference in that if you have a
 

1117
00:26:54,720 --> 00:26:58,149
a big difference in that if you have a
milliondimensional vector with only 128

1118
00:26:58,149 --> 00:26:58,159
milliondimensional vector with only 128
 

1119
00:26:58,159 --> 00:26:59,830
milliondimensional vector with only 128
things that are non zero, there's

1120
00:26:59,830 --> 00:26:59,840
things that are non zero, there's
 

1121
00:26:59,840 --> 00:27:02,549
things that are non zero, there's
information in two places. What those

1122
00:27:02,549 --> 00:27:02,559
information in two places. What those
 

1123
00:27:02,559 --> 00:27:05,269
information in two places. What those
128 things actually are, that's the same

1124
00:27:05,269 --> 00:27:05,279
128 things actually are, that's the same
 

1125
00:27:05,279 --> 00:27:08,310
128 things actually are, that's the same
as the 128 dimensional vector, but also

1126
00:27:08,310 --> 00:27:08,320
as the 128 dimensional vector, but also
 

1127
00:27:08,320 --> 00:27:12,470
as the 128 dimensional vector, but also
which 128 things are on. So this this

1128
00:27:12,470 --> 00:27:12,480
which 128 things are on. So this this
 

1129
00:27:12,480 --> 00:27:14,230
which 128 things are on. So this this
information that's in this cominatorial

1130
00:27:14,230 --> 00:27:14,240
information that's in this cominatorial
 

1131
00:27:14,240 --> 00:27:16,070
information that's in this cominatorial
sense of like which particular ones

1132
00:27:16,070 --> 00:27:16,080
sense of like which particular ones
 

1133
00:27:16,080 --> 00:27:17,430
sense of like which particular ones
you're activating.

1134
00:27:17,430 --> 00:27:17,440
you're activating.
 

1135
00:27:17,440 --> 00:27:25,590
you're activating.
you're sort of also ass.

1136
00:27:25,590 --> 00:27:25,600

 

1137
00:27:25,600 --> 00:27:31,110

>> So the idea here is uh as typically in

1138
00:27:31,110 --> 00:27:31,120
>> So the idea here is uh as typically in
 

1139
00:27:31,120 --> 00:27:33,510
>> So the idea here is uh as typically in
all of deep learning, right? It goes

1140
00:27:33,510 --> 00:27:33,520
all of deep learning, right? It goes
 

1141
00:27:33,520 --> 00:27:36,310
all of deep learning, right? It goes
like this. We think that there's a

1142
00:27:36,310 --> 00:27:36,320
like this. We think that there's a
 

1143
00:27:36,320 --> 00:27:39,430
like this. We think that there's a
pattern. We think the pattern might be

1144
00:27:39,430 --> 00:27:39,440
pattern. We think the pattern might be
 

1145
00:27:39,440 --> 00:27:43,269
pattern. We think the pattern might be
well captured in this by sparse vectors.

1146
00:27:43,269 --> 00:27:43,279
well captured in this by sparse vectors.
 

1147
00:27:43,279 --> 00:27:46,070
well captured in this by sparse vectors.
We think this is true. To encourage this

1148
00:27:46,070 --> 00:27:46,080
We think this is true. To encourage this
 

1149
00:27:46,080 --> 00:27:47,590
We think this is true. To encourage this
thing that we're thinking to actually

1150
00:27:47,590 --> 00:27:47,600
thing that we're thinking to actually
 

1151
00:27:47,600 --> 00:27:49,830
thing that we're thinking to actually
happen during training, we add

1152
00:27:49,830 --> 00:27:49,840
happen during training, we add
 

1153
00:27:49,840 --> 00:27:52,710
happen during training, we add
something. Okay, so in the bottleneck

1154
00:27:52,710 --> 00:27:52,720
something. Okay, so in the bottleneck
 

1155
00:27:52,720 --> 00:27:54,070
something. Okay, so in the bottleneck
case, the thing we thought is low

1156
00:27:54,070 --> 00:27:54,080
case, the thing we thought is low
 

1157
00:27:54,080 --> 00:27:55,750
case, the thing we thought is low
dimensional. The way we did it was we

1158
00:27:55,750 --> 00:27:55,760
dimensional. The way we did it was we
 

1159
00:27:55,760 --> 00:27:57,590
dimensional. The way we did it was we
put an architectural constraint that

1160
00:27:57,590 --> 00:27:57,600
put an architectural constraint that
 

1161
00:27:57,600 --> 00:27:59,990
put an architectural constraint that
forced it to be lowdimensional. Here we

1162
00:27:59,990 --> 00:28:00,000
forced it to be lowdimensional. Here we
 

1163
00:28:00,000 --> 00:28:01,990
forced it to be lowdimensional. Here we
think it's something that's sparse. So

1164
00:28:01,990 --> 00:28:02,000
think it's something that's sparse. So
 

1165
00:28:02,000 --> 00:28:04,310
think it's something that's sparse. So
we add an auxiliary loss that encourages

1166
00:28:04,310 --> 00:28:04,320
we add an auxiliary loss that encourages
 

1167
00:28:04,320 --> 00:28:06,870
we add an auxiliary loss that encourages
sparsity. And then we just say, okay,

1168
00:28:06,870 --> 00:28:06,880
sparsity. And then we just say, okay,
 

1169
00:28:06,880 --> 00:28:08,789
sparsity. And then we just say, okay,
training run.

1170
00:28:08,789 --> 00:28:08,799
training run.
 

1171
00:28:08,799 --> 00:28:10,710
training run.
and you hope that this thing comes out

1172
00:28:10,710 --> 00:28:10,720
and you hope that this thing comes out
 

1173
00:28:10,720 --> 00:28:13,190
and you hope that this thing comes out
to be sparse. At random initialization,

1174
00:28:13,190 --> 00:28:13,200
to be sparse. At random initialization,
 

1175
00:28:13,200 --> 00:28:16,310
to be sparse. At random initialization,
this is not sparse.

1176
00:28:16,310 --> 00:28:16,320
this is not sparse.
 

1177
00:28:16,320 --> 00:28:18,070
this is not sparse.
Okay, at random initialization, this is

1178
00:28:18,070 --> 00:28:18,080
Okay, at random initialization, this is
 

1179
00:28:18,080 --> 00:28:20,389
Okay, at random initialization, this is
a really bad reconstruction. But you

1180
00:28:20,389 --> 00:28:20,399
a really bad reconstruction. But you
 

1181
00:28:20,399 --> 00:28:22,310
a really bad reconstruction. But you
hope as time goes on between the

1182
00:28:22,310 --> 00:28:22,320
hope as time goes on between the
 

1183
00:28:22,320 --> 00:28:23,590
hope as time goes on between the
auxiliary loss and the desire to

1184
00:28:23,590 --> 00:28:23,600
auxiliary loss and the desire to
 

1185
00:28:23,600 --> 00:28:25,110
auxiliary loss and the desire to
reconstruct that this thing ends up

1186
00:28:25,110 --> 00:28:25,120
reconstruct that this thing ends up
 

1187
00:28:25,120 --> 00:28:26,310
reconstruct that this thing ends up
being sparse.

1188
00:28:26,310 --> 00:28:26,320
being sparse.
 

1189
00:28:26,320 --> 00:28:27,669
being sparse.
>> What I was asking is more the idea of

1190
00:28:27,669 --> 00:28:27,679
>> What I was asking is more the idea of
 

1191
00:28:27,679 --> 00:28:29,590
>> What I was asking is more the idea of
like

1192
00:28:29,590 --> 00:28:29,600
like
 

1193
00:28:29,600 --> 00:28:34,950
like
oh if I give it a dog.

1194
00:28:34,950 --> 00:28:34,960

 

1195
00:28:34,960 --> 00:28:36,710

>> Great question. The question is when you

1196
00:28:36,710 --> 00:28:36,720
>> Great question. The question is when you
 

1197
00:28:36,720 --> 00:28:39,190
>> Great question. The question is when you
do sparse autoenccoding do you try in

1198
00:28:39,190 --> 00:28:39,200
do sparse autoenccoding do you try in
 

1199
00:28:39,200 --> 00:28:41,669
do sparse autoenccoding do you try in
advance to decide the interpretation of

1200
00:28:41,669 --> 00:28:41,679
advance to decide the interpretation of
 

1201
00:28:41,679 --> 00:28:43,830
advance to decide the interpretation of
different vector different things in

1202
00:28:43,830 --> 00:28:43,840
different vector different things in
 

1203
00:28:43,840 --> 00:28:46,710
different vector different things in
here and the answer is no. We say we

1204
00:28:46,710 --> 00:28:46,720
here and the answer is no. We say we
 

1205
00:28:46,720 --> 00:28:47,909
here and the answer is no. We say we
don't try to say that this is going to

1206
00:28:47,909 --> 00:28:47,919
don't try to say that this is going to
 

1207
00:28:47,919 --> 00:28:50,549
don't try to say that this is going to
be the doggy neuron and we'll say okay

1208
00:28:50,549 --> 00:28:50,559
be the doggy neuron and we'll say okay
 

1209
00:28:50,559 --> 00:28:53,510
be the doggy neuron and we'll say okay
we have an L1 loss on everything but the

1210
00:28:53,510 --> 00:28:53,520
we have an L1 loss on everything but the
 

1211
00:28:53,520 --> 00:29:02,310
we have an L1 loss on everything but the
doggy neuron is free for dogs.

1212
00:29:02,310 --> 00:29:02,320

 

1213
00:29:02,320 --> 00:29:04,789

>> We don't want

1214
00:29:04,789 --> 00:29:04,799
>> We don't want
 

1215
00:29:04,799 --> 00:29:07,510
>> We don't want
>> it'll different ones based on

1216
00:29:07,510 --> 00:29:07,520
>> it'll different ones based on
 

1217
00:29:07,520 --> 00:29:10,549
>> it'll different ones based on
>> so the idea yes we're hoping for the

1218
00:29:10,549 --> 00:29:10,559
>> so the idea yes we're hoping for the
 

1219
00:29:10,559 --> 00:29:12,789
>> so the idea yes we're hoping for the
idea that at the after training happens

1220
00:29:12,789 --> 00:29:12,799
idea that at the after training happens
 

1221
00:29:12,799 --> 00:29:15,430
idea that at the after training happens
that these will actually be sparse

1222
00:29:15,430 --> 00:29:15,440
that these will actually be sparse
 

1223
00:29:15,440 --> 00:29:18,389
that these will actually be sparse
during the encoding process but this is

1224
00:29:18,389 --> 00:29:18,399
during the encoding process but this is
 

1225
00:29:18,399 --> 00:29:20,149
during the encoding process but this is
only being encouraged by the auxiliary

1226
00:29:20,149 --> 00:29:20,159
only being encouraged by the auxiliary
 

1227
00:29:20,159 --> 00:29:23,750
only being encouraged by the auxiliary
loss it is not being forced

1228
00:29:23,750 --> 00:29:23,760
loss it is not being forced
 

1229
00:29:23,760 --> 00:29:24,870
loss it is not being forced
of course it could be that you train

1230
00:29:24,870 --> 00:29:24,880
of course it could be that you train
 

1231
00:29:24,880 --> 00:29:26,149
of course it could be that you train
this thing and this thing ends up being

1232
00:29:26,149 --> 00:29:26,159
this thing and this thing ends up being
 

1233
00:29:26,159 --> 00:29:28,789
this thing and this thing ends up being
not sparse in which case you're like

1234
00:29:28,789 --> 00:29:28,799
not sparse in which case you're like
 

1235
00:29:28,799 --> 00:29:32,710
not sparse in which case you're like
okay that didn't work right and you'll

1236
00:29:32,710 --> 00:29:32,720
okay that didn't work right and you'll
 

1237
00:29:32,720 --> 00:29:34,230
okay that didn't work right and you'll
go back and fiddle with something will

1238
00:29:34,230 --> 00:29:34,240
go back and fiddle with something will
 

1239
00:29:34,240 --> 00:29:35,669
go back and fiddle with something will
you fiddle Most likely the first thing

1240
00:29:35,669 --> 00:29:35,679
you fiddle Most likely the first thing
 

1241
00:29:35,679 --> 00:29:37,510
you fiddle Most likely the first thing
you'll fiddle with is you'll first

1242
00:29:37,510 --> 00:29:37,520
you'll fiddle with is you'll first
 

1243
00:29:37,520 --> 00:29:39,029
you'll fiddle with is you'll first
you'll check is the reconstruction

1244
00:29:39,029 --> 00:29:39,039
you'll check is the reconstruction
 

1245
00:29:39,039 --> 00:29:41,990
you'll check is the reconstruction
decent, right? If the reconstruction is

1246
00:29:41,990 --> 00:29:42,000
decent, right? If the reconstruction is
 

1247
00:29:42,000 --> 00:29:44,149
decent, right? If the reconstruction is
not decent, you have other problems. The

1248
00:29:44,149 --> 00:29:44,159
not decent, you have other problems. The
 

1249
00:29:44,159 --> 00:29:45,750
not decent, you have other problems. The
reconstruction is decent, you're like,

1250
00:29:45,750 --> 00:29:45,760
reconstruction is decent, you're like,
 

1251
00:29:45,760 --> 00:29:48,389
reconstruction is decent, you're like,
"Okay, maybe I should up the

1252
00:29:48,389 --> 00:29:48,399
"Okay, maybe I should up the
 

1253
00:29:48,399 --> 00:29:51,990
"Okay, maybe I should up the
the multiplier on this L1 penalty to

1254
00:29:51,990 --> 00:29:52,000
the multiplier on this L1 penalty to
 

1255
00:29:52,000 --> 00:29:54,630
the multiplier on this L1 penalty to
make it hit harder." Things like this

1256
00:29:54,630 --> 00:29:54,640
make it hit harder." Things like this
 

1257
00:29:54,640 --> 00:29:56,230
make it hit harder." Things like this
usual things one will do when you have

1258
00:29:56,230 --> 00:29:56,240
usual things one will do when you have
 

1259
00:29:56,240 --> 00:29:59,350
usual things one will do when you have
different knobs you can tweak.

1260
00:29:59,350 --> 00:29:59,360
different knobs you can tweak.
 

1261
00:29:59,360 --> 00:30:02,630
different knobs you can tweak.
>> Yes, question. this auxiliary loss. Are

1262
00:30:02,630 --> 00:30:02,640
>> Yes, question. this auxiliary loss. Are
 

1263
00:30:02,640 --> 00:30:05,350
>> Yes, question. this auxiliary loss. Are
we comparing the hidden vector to

1264
00:30:05,350 --> 00:30:05,360
we comparing the hidden vector to
 

1265
00:30:05,360 --> 00:30:06,870
we comparing the hidden vector to
anything or is it purely just like a

1266
00:30:06,870 --> 00:30:06,880
anything or is it purely just like a
 

1267
00:30:06,880 --> 00:30:07,990
anything or is it purely just like a
regularization?

1268
00:30:07,990 --> 00:30:08,000
regularization?
 

1269
00:30:08,000 --> 00:30:09,510
regularization?
>> It's like a regularization term. It's

1270
00:30:09,510 --> 00:30:09,520
>> It's like a regularization term. It's
 

1271
00:30:09,520 --> 00:30:11,750
>> It's like a regularization term. It's
just an auxiliary loss that says, "Hey,

1272
00:30:11,750 --> 00:30:11,760
just an auxiliary loss that says, "Hey,
 

1273
00:30:11,760 --> 00:30:15,269
just an auxiliary loss that says, "Hey,
I want this thing to be

1274
00:30:15,269 --> 00:30:15,279
I want this thing to be
 

1275
00:30:15,279 --> 00:30:17,510
I want this thing to be
small in L1 sense, which I know is going

1276
00:30:17,510 --> 00:30:17,520
small in L1 sense, which I know is going
 

1277
00:30:17,520 --> 00:30:19,669
small in L1 sense, which I know is going
to be yeah. So you saw in the diff pool

1278
00:30:19,669 --> 00:30:19,679
to be yeah. So you saw in the diff pool
 

1279
00:30:19,679 --> 00:30:21,350
to be yeah. So you saw in the diff pool
example, we had a auxiliary loss that

1280
00:30:21,350 --> 00:30:21,360
example, we had a auxiliary loss that
 

1281
00:30:21,360 --> 00:30:23,190
example, we had a auxiliary loss that
was doing a comparison and we had

1282
00:30:23,190 --> 00:30:23,200
was doing a comparison and we had
 

1283
00:30:23,200 --> 00:30:24,630
was doing a comparison and we had
another auxiliary loss, the entropy

1284
00:30:24,630 --> 00:30:24,640
another auxiliary loss, the entropy
 

1285
00:30:24,640 --> 00:30:27,029
another auxiliary loss, the entropy
loss, which is like a regularizer.

1286
00:30:27,029 --> 00:30:27,039
loss, which is like a regularizer.
 

1287
00:30:27,039 --> 00:30:28,870
loss, which is like a regularizer.
So all of that we can think of as

1288
00:30:28,870 --> 00:30:28,880
So all of that we can think of as
 

1289
00:30:28,880 --> 00:30:31,110
So all of that we can think of as
auxiliary losses.

1290
00:30:31,110 --> 00:30:31,120
auxiliary losses.
 

1291
00:30:31,120 --> 00:30:34,389
auxiliary losses.
So yes you know that there's

1292
00:30:34,389 --> 00:30:34,399
So yes you know that there's
 

1293
00:30:34,399 --> 00:30:36,310
So yes you know that there's
architecture

1294
00:30:36,310 --> 00:30:36,320
architecture
 

1295
00:30:36,320 --> 00:30:38,070
architecture
auxiliary losses but there's one more

1296
00:30:38,070 --> 00:30:38,080
auxiliary losses but there's one more
 

1297
00:30:38,080 --> 00:30:39,430
auxiliary losses but there's one more
thing one can do which is data

1298
00:30:39,430 --> 00:30:39,440
thing one can do which is data
 

1299
00:30:39,440 --> 00:30:42,070
thing one can do which is data
augmentations.

1300
00:30:42,070 --> 00:30:42,080
augmentations.
 

1301
00:30:42,080 --> 00:30:44,870
augmentations.
Okay so you can also do what's called a

1302
00:30:44,870 --> 00:30:44,880
Okay so you can also do what's called a
 

1303
00:30:44,880 --> 00:30:48,070
Okay so you can also do what's called a
dnoising autoenccoder

1304
00:30:48,070 --> 00:30:48,080
dnoising autoenccoder
 

1305
00:30:48,080 --> 00:30:53,029
dnoising autoenccoder
which is a data augmentation. This says

1306
00:30:53,029 --> 00:30:53,039
which is a data augmentation. This says
 

1307
00:30:53,039 --> 00:30:55,350
which is a data augmentation. This says
I can do any kind of autoenccoder I

1308
00:30:55,350 --> 00:30:55,360
I can do any kind of autoenccoder I
 

1309
00:30:55,360 --> 00:30:58,070
I can do any kind of autoenccoder I
want. This can be small. This can be

1310
00:30:58,070 --> 00:30:58,080
want. This can be small. This can be
 

1311
00:30:58,080 --> 00:31:00,710
want. This can be small. This can be
big. This can be whatever. I'm not

1312
00:31:00,710 --> 00:31:00,720
big. This can be whatever. I'm not
 

1313
00:31:00,720 --> 00:31:02,789
big. This can be whatever. I'm not
that's not really the thing I'm worried

1314
00:31:02,789 --> 00:31:02,799
that's not really the thing I'm worried
 

1315
00:31:02,799 --> 00:31:07,029
that's not really the thing I'm worried
about here. But I can take the dog. I

1316
00:31:07,029 --> 00:31:07,039
about here. But I can take the dog. I
 

1317
00:31:07,039 --> 00:31:09,029
about here. But I can take the dog. I
can do an augmentation. Here is an

1318
00:31:09,029 --> 00:31:09,039
can do an augmentation. Here is an
 

1319
00:31:09,039 --> 00:31:11,990
can do an augmentation. Here is an
adding noise augmentation that I do. And

1320
00:31:11,990 --> 00:31:12,000
adding noise augmentation that I do. And
 

1321
00:31:12,000 --> 00:31:17,350
adding noise augmentation that I do. And
then I can train it.

1322
00:31:17,350 --> 00:31:17,360

 

1323
00:31:17,360 --> 00:31:20,789

So it's interesting that

1324
00:31:20,789 --> 00:31:20,799
So it's interesting that
 

1325
00:31:20,799 --> 00:31:24,230
So it's interesting that
in all three of these examples right in

1326
00:31:24,230 --> 00:31:24,240
in all three of these examples right in
 

1327
00:31:24,240 --> 00:31:26,310
in all three of these examples right in
the autoenccoder coder style what you're

1328
00:31:26,310 --> 00:31:26,320
the autoenccoder coder style what you're
 

1329
00:31:26,320 --> 00:31:28,789
the autoenccoder coder style what you're
trying to learn is a way of

1330
00:31:28,789 --> 00:31:28,799
trying to learn is a way of
 

1331
00:31:28,799 --> 00:31:31,510
trying to learn is a way of
approximately representing the inputs in

1332
00:31:31,510 --> 00:31:31,520
approximately representing the inputs in
 

1333
00:31:31,520 --> 00:31:33,430
approximately representing the inputs in
a way that captures their most important

1334
00:31:33,430 --> 00:31:33,440
a way that captures their most important
 

1335
00:31:33,440 --> 00:31:35,990
a way that captures their most important
attributes.

1336
00:31:35,990 --> 00:31:36,000
attributes.
 

1337
00:31:36,000 --> 00:31:37,990
attributes.
So in this one you're just forcing it to

1338
00:31:37,990 --> 00:31:38,000
So in this one you're just forcing it to
 

1339
00:31:38,000 --> 00:31:40,149
So in this one you're just forcing it to
be small and importance is of course how

1340
00:31:40,149 --> 00:31:40,159
be small and importance is of course how
 

1341
00:31:40,159 --> 00:31:43,029
be small and importance is of course how
well does it reconstruct. In the sparse

1342
00:31:43,029 --> 00:31:43,039
well does it reconstruct. In the sparse
 

1343
00:31:43,039 --> 00:31:45,269
well does it reconstruct. In the sparse
autoenccoder again importance is how

1344
00:31:45,269 --> 00:31:45,279
autoenccoder again importance is how
 

1345
00:31:45,279 --> 00:31:46,310
autoenccoder again importance is how
well is it useful for doing

1346
00:31:46,310 --> 00:31:46,320
well is it useful for doing
 

1347
00:31:46,320 --> 00:31:47,590
well is it useful for doing
reconstruction but you have this

1348
00:31:47,590 --> 00:31:47,600
reconstruction but you have this
 

1349
00:31:47,600 --> 00:31:49,509
reconstruction but you have this
additional jittera that I would like

1350
00:31:49,509 --> 00:31:49,519
additional jittera that I would like
 

1351
00:31:49,519 --> 00:31:51,590
additional jittera that I would like
this thing to be maybe interpretable in

1352
00:31:51,590 --> 00:31:51,600
this thing to be maybe interpretable in
 

1353
00:31:51,600 --> 00:31:54,630
this thing to be maybe interpretable in
somewhere just by be sparse.

1354
00:31:54,630 --> 00:31:54,640
somewhere just by be sparse.
 

1355
00:31:54,640 --> 00:31:56,870
somewhere just by be sparse.
In this one we just say look I just want

1356
00:31:56,870 --> 00:31:56,880
In this one we just say look I just want
 

1357
00:31:56,880 --> 00:31:59,190
In this one we just say look I just want
to be good at reconstructing

1358
00:31:59,190 --> 00:31:59,200
to be good at reconstructing
 

1359
00:31:59,200 --> 00:32:00,470
to be good at reconstructing
and the reason it's going to capture

1360
00:32:00,470 --> 00:32:00,480
and the reason it's going to capture
 

1361
00:32:00,480 --> 00:32:03,669
and the reason it's going to capture
what's important is because I'm going to

1362
00:32:03,669 --> 00:32:03,679
what's important is because I'm going to
 

1363
00:32:03,679 --> 00:32:06,870
what's important is because I'm going to
do augmentations that try to destroy or

1364
00:32:06,870 --> 00:32:06,880
do augmentations that try to destroy or
 

1365
00:32:06,880 --> 00:32:09,430
do augmentations that try to destroy or
change things that are not important and

1366
00:32:09,430 --> 00:32:09,440
change things that are not important and
 

1367
00:32:09,440 --> 00:32:11,830
change things that are not important and
it has to be robust to that. So the only

1368
00:32:11,830 --> 00:32:11,840
it has to be robust to that. So the only
 

1369
00:32:11,840 --> 00:32:12,870
it has to be robust to that. So the only
way you're going to be able to den

1370
00:32:12,870 --> 00:32:12,880
way you're going to be able to den
 

1371
00:32:12,880 --> 00:32:15,029
way you're going to be able to den
noiseise this thing is because you'll

1372
00:32:15,029 --> 00:32:15,039
noiseise this thing is because you'll
 

1373
00:32:15,039 --> 00:32:17,190
noiseise this thing is because you'll
realize that wait actually every pixel

1374
00:32:17,190 --> 00:32:17,200
realize that wait actually every pixel
 

1375
00:32:17,200 --> 00:32:19,430
realize that wait actually every pixel
level detail isn't important. there's a

1376
00:32:19,430 --> 00:32:19,440
level detail isn't important. there's a
 

1377
00:32:19,440 --> 00:32:20,789
level detail isn't important. there's a
bigger picture of what's happening that

1378
00:32:20,789 --> 00:32:20,799
bigger picture of what's happening that
 

1379
00:32:20,799 --> 00:32:22,149
bigger picture of what's happening that
requires smoothing and looking at what's

1380
00:32:22,149 --> 00:32:22,159
requires smoothing and looking at what's
 

1381
00:32:22,159 --> 00:32:24,549
requires smoothing and looking at what's
going on around around figuring out that

1382
00:32:24,549 --> 00:32:24,559
going on around around figuring out that
 

1383
00:32:24,559 --> 00:32:27,750
going on around around figuring out that
oh okay actually this is a dog and oh

1384
00:32:27,750 --> 00:32:27,760
oh okay actually this is a dog and oh
 

1385
00:32:27,760 --> 00:32:29,990
oh okay actually this is a dog and oh
actually its eyes are here so I can like

1386
00:32:29,990 --> 00:32:30,000
actually its eyes are here so I can like
 

1387
00:32:30,000 --> 00:32:32,950
actually its eyes are here so I can like
remove the noise here better than just a

1388
00:32:32,950 --> 00:32:32,960
remove the noise here better than just a
 

1389
00:32:32,960 --> 00:32:36,149
remove the noise here better than just a
Gaussian like blur will do for removing

1390
00:32:36,149 --> 00:32:36,159
Gaussian like blur will do for removing
 

1391
00:32:36,159 --> 00:32:38,070
Gaussian like blur will do for removing
the noise and that's what I hope will

1392
00:32:38,070 --> 00:32:38,080
the noise and that's what I hope will
 

1393
00:32:38,080 --> 00:32:39,750
the noise and that's what I hope will
work and so that's what you want this

1394
00:32:39,750 --> 00:32:39,760
work and so that's what you want this
 

1395
00:32:39,760 --> 00:32:41,990
work and so that's what you want this
encoder to learn

1396
00:32:41,990 --> 00:32:42,000
encoder to learn
 

1397
00:32:42,000 --> 00:32:44,149
encoder to learn
and you want the decoder to be able to

1398
00:32:44,149 --> 00:32:44,159
and you want the decoder to be able to
 

1399
00:32:44,159 --> 00:32:45,590
and you want the decoder to be able to
carry it out so you better capture that

1400
00:32:45,590 --> 00:32:45,600
carry it out so you better capture that
 

1401
00:32:45,600 --> 00:32:48,389
carry it out so you better capture that
in this hidden hidden thing okay so

1402
00:32:48,389 --> 00:32:48,399
in this hidden hidden thing okay so
 

1403
00:32:48,399 --> 00:32:51,669
in this hidden hidden thing okay so
that's denoising auto-enccoder idea

1404
00:32:51,669 --> 00:32:51,679
that's denoising auto-enccoder idea
 

1405
00:32:51,679 --> 00:32:54,149
that's denoising auto-enccoder idea
but once you think about dnoising

1406
00:32:54,149 --> 00:32:54,159
but once you think about dnoising
 

1407
00:32:54,159 --> 00:32:56,710
but once you think about dnoising
autoenccoders

1408
00:32:56,710 --> 00:32:56,720
autoenccoders
 

1409
00:32:56,720 --> 00:33:00,070
autoenccoders
any augmentation is good.

1410
00:33:00,070 --> 00:33:00,080
any augmentation is good.
 

1411
00:33:00,080 --> 00:33:03,430
any augmentation is good.
So another very important kind of uh

1412
00:33:03,430 --> 00:33:03,440
So another very important kind of uh
 

1413
00:33:03,440 --> 00:33:05,830
So another very important kind of uh
autoenccoder family is called masked

1414
00:33:05,830 --> 00:33:05,840
autoenccoder family is called masked
 

1415
00:33:05,840 --> 00:33:07,350
autoenccoder family is called masked
autoenccoders which is another kind of

1416
00:33:07,350 --> 00:33:07,360
autoenccoders which is another kind of
 

1417
00:33:07,360 --> 00:33:09,430
autoenccoders which is another kind of
augmentation.

1418
00:33:09,430 --> 00:33:09,440
augmentation.
 

1419
00:33:09,440 --> 00:33:12,230
augmentation.
So in this augmentation what you do is

1420
00:33:12,230 --> 00:33:12,240
So in this augmentation what you do is
 

1421
00:33:12,240 --> 00:33:15,430
So in this augmentation what you do is
you take parts of the input and you say

1422
00:33:15,430 --> 00:33:15,440
you take parts of the input and you say
 

1423
00:33:15,440 --> 00:33:17,990
you take parts of the input and you say
I'm going to mask them. So remember we

1424
00:33:17,990 --> 00:33:18,000
I'm going to mask them. So remember we
 

1425
00:33:18,000 --> 00:33:19,110
I'm going to mask them. So remember we
talked about this in the context of

1426
00:33:19,110 --> 00:33:19,120
talked about this in the context of
 

1427
00:33:19,120 --> 00:33:20,789
talked about this in the context of
graph neural nets. We said we want to

1428
00:33:20,789 --> 00:33:20,799
graph neural nets. We said we want to
 

1429
00:33:20,799 --> 00:33:22,710
graph neural nets. We said we want to
take a particular node and remove it. So

1430
00:33:22,710 --> 00:33:22,720
take a particular node and remove it. So
 

1431
00:33:22,720 --> 00:33:24,950
take a particular node and remove it. So
we can do the same thing here. And so

1432
00:33:24,950 --> 00:33:24,960
we can do the same thing here. And so
 

1433
00:33:24,960 --> 00:33:27,029
we can do the same thing here. And so
for images you could just like paint it

1434
00:33:27,029 --> 00:33:27,039
for images you could just like paint it
 

1435
00:33:27,039 --> 00:33:31,909
for images you could just like paint it
gray gray blobs. That works. Um

1436
00:33:31,909 --> 00:33:31,919
gray gray blobs. That works. Um
 

1437
00:33:31,919 --> 00:33:36,470
gray gray blobs. That works. Um
if your thing is not an image,

1438
00:33:36,470 --> 00:33:36,480
if your thing is not an image,
 

1439
00:33:36,480 --> 00:33:39,029
if your thing is not an image,
you might involve having a learned mask

1440
00:33:39,029 --> 00:33:39,039
you might involve having a learned mask
 

1441
00:33:39,039 --> 00:33:40,789
you might involve having a learned mask
question mark vector that you have to

1442
00:33:40,789 --> 00:33:40,799
question mark vector that you have to
 

1443
00:33:40,799 --> 00:33:45,430
question mark vector that you have to
use. Same as we saw in in GNN's. But

1444
00:33:45,430 --> 00:33:45,440
use. Same as we saw in in GNN's. But
 

1445
00:33:45,440 --> 00:33:48,149
use. Same as we saw in in GNN's. But
again, to be able to recover from this

1446
00:33:48,149 --> 00:33:48,159
again, to be able to recover from this
 

1447
00:33:48,159 --> 00:33:50,630
again, to be able to recover from this
kind of damage, it has to be the case

1448
00:33:50,630 --> 00:33:50,640
kind of damage, it has to be the case
 

1449
00:33:50,640 --> 00:33:53,190
kind of damage, it has to be the case
that this includes what's actually going

1450
00:33:53,190 --> 00:33:53,200
that this includes what's actually going
 

1451
00:33:53,200 --> 00:33:55,110
that this includes what's actually going
on underneath so that the reconstruction

1452
00:33:55,110 --> 00:33:55,120
on underneath so that the reconstruction
 

1453
00:33:55,120 --> 00:34:01,269
on underneath so that the reconstruction
can just fill everything in.

1454
00:34:01,269 --> 00:34:01,279

 

1455
00:34:01,279 --> 00:34:05,110

Okay, so this is the kind of spirit.

1456
00:34:05,110 --> 00:34:05,120
Okay, so this is the kind of spirit.
 

1457
00:34:05,120 --> 00:34:06,870
Okay, so this is the kind of spirit.
Autoenccoders don't take that long to

1458
00:34:06,870 --> 00:34:06,880
Autoenccoders don't take that long to
 

1459
00:34:06,880 --> 00:34:08,310
Autoenccoders don't take that long to
understand the ideas. You just ask

1460
00:34:08,310 --> 00:34:08,320
understand the ideas. You just ask
 

1461
00:34:08,320 --> 00:34:10,310
understand the ideas. You just ask
questions. But what you're basically

1462
00:34:10,310 --> 00:34:10,320
questions. But what you're basically
 

1463
00:34:10,320 --> 00:34:11,669
questions. But what you're basically
trying to do is take the spirit of

1464
00:34:11,669 --> 00:34:11,679
trying to do is take the spirit of
 

1465
00:34:11,679 --> 00:34:13,510
trying to do is take the spirit of
dimensionality reduction and say

1466
00:34:13,510 --> 00:34:13,520
dimensionality reduction and say
 

1467
00:34:13,520 --> 00:34:15,190
dimensionality reduction and say
dimensionality reduction is about

1468
00:34:15,190 --> 00:34:15,200
dimensionality reduction is about
 

1469
00:34:15,200 --> 00:34:17,510
dimensionality reduction is about
finding a representation that cleanly

1470
00:34:17,510 --> 00:34:17,520
finding a representation that cleanly
 

1471
00:34:17,520 --> 00:34:20,230
finding a representation that cleanly
captures what's important.

1472
00:34:20,230 --> 00:34:20,240
captures what's important.
 

1473
00:34:20,240 --> 00:34:23,190
captures what's important.
Lowdimensionality is only one thing that

1474
00:34:23,190 --> 00:34:23,200
Lowdimensionality is only one thing that
 

1475
00:34:23,200 --> 00:34:25,030
Lowdimensionality is only one thing that
can do that. There's only one

1476
00:34:25,030 --> 00:34:25,040
can do that. There's only one
 

1477
00:34:25,040 --> 00:34:27,109
can do that. There's only one
possibility. What you actually want is

1478
00:34:27,109 --> 00:34:27,119
possibility. What you actually want is
 

1479
00:34:27,119 --> 00:34:28,470
possibility. What you actually want is
it should capture what's essentially

1480
00:34:28,470 --> 00:34:28,480
it should capture what's essentially
 

1481
00:34:28,480 --> 00:34:31,990
it should capture what's essentially
important. And think about the original

1482
00:34:31,990 --> 00:34:32,000
important. And think about the original
 

1483
00:34:32,000 --> 00:34:34,069
important. And think about the original
input as having lots of different

1484
00:34:34,069 --> 00:34:34,079
input as having lots of different
 

1485
00:34:34,079 --> 00:34:39,190
input as having lots of different
features associated with it. The

1486
00:34:39,190 --> 00:34:39,200
features associated with it. The
 

1487
00:34:39,200 --> 00:34:40,790
features associated with it. The
thing that plays the spirit of

1488
00:34:40,790 --> 00:34:40,800
thing that plays the spirit of
 

1489
00:34:40,800 --> 00:34:42,550
thing that plays the spirit of
dimensionality reduction should have

1490
00:34:42,550 --> 00:34:42,560
dimensionality reduction should have
 

1491
00:34:42,560 --> 00:34:45,510
dimensionality reduction should have
like purer features in it like better

1492
00:34:45,510 --> 00:34:45,520
like purer features in it like better
 

1493
00:34:45,520 --> 00:34:47,430
like purer features in it like better
features

1494
00:34:47,430 --> 00:34:47,440
features
 

1495
00:34:47,440 --> 00:34:49,349
features
which is a qualitative term better

1496
00:34:49,349 --> 00:34:49,359
which is a qualitative term better
 

1497
00:34:49,359 --> 00:34:51,829
which is a qualitative term better
features better in what sense good

1498
00:34:51,829 --> 00:34:51,839
features better in what sense good
 

1499
00:34:51,839 --> 00:34:57,349
features better in what sense good
enough to do the reconstruction

1500
00:34:57,349 --> 00:34:57,359

 

1501
00:34:57,359 --> 00:34:58,950

so

1502
00:34:58,950 --> 00:34:58,960
so
 

1503
00:34:58,960 --> 00:35:00,950
so
one comment about this that I want to

1504
00:35:00,950 --> 00:35:00,960
one comment about this that I want to
 

1505
00:35:00,960 --> 00:35:02,870
one comment about this that I want to
make before I move to one tiny bit of

1506
00:35:02,870 --> 00:35:02,880
make before I move to one tiny bit of
 

1507
00:35:02,880 --> 00:35:04,390
make before I move to one tiny bit of
talking about one more topic before I

1508
00:35:04,390 --> 00:35:04,400
talking about one more topic before I
 

1509
00:35:04,400 --> 00:35:09,990
talking about one more topic before I
hand it over is

1510
00:35:09,990 --> 00:35:10,000

 

1511
00:35:10,000 --> 00:35:13,589

if you have a bottleneck in your

1512
00:35:13,589 --> 00:35:13,599
if you have a bottleneck in your
 

1513
00:35:13,599 --> 00:35:15,190
if you have a bottleneck in your
architecture,

1514
00:35:15,190 --> 00:35:15,200
architecture,
 

1515
00:35:15,200 --> 00:35:16,710
architecture,
there's you can think of it as there's

1516
00:35:16,710 --> 00:35:16,720
there's you can think of it as there's
 

1517
00:35:16,720 --> 00:35:18,390
there's you can think of it as there's
no choice. If you want to be able to

1518
00:35:18,390 --> 00:35:18,400
no choice. If you want to be able to
 

1519
00:35:18,400 --> 00:35:19,750
no choice. If you want to be able to
have good reconstruction, you have to

1520
00:35:19,750 --> 00:35:19,760
have good reconstruction, you have to
 

1521
00:35:19,760 --> 00:35:22,069
have good reconstruction, you have to
distill out what's important.

1522
00:35:22,069 --> 00:35:22,079
distill out what's important.
 

1523
00:35:22,079 --> 00:35:23,750
distill out what's important.
When you eliminate the bottleneck

1524
00:35:23,750 --> 00:35:23,760
When you eliminate the bottleneck
 

1525
00:35:23,760 --> 00:35:25,349
When you eliminate the bottleneck
entirely, for example, if this was just

1526
00:35:25,349 --> 00:35:25,359
entirely, for example, if this was just
 

1527
00:35:25,359 --> 00:35:28,390
entirely, for example, if this was just
the same size as the input, then there

1528
00:35:28,390 --> 00:35:28,400
the same size as the input, then there
 

1529
00:35:28,400 --> 00:35:31,750
the same size as the input, then there
is a hypothetical fear that what the

1530
00:35:31,750 --> 00:35:31,760
is a hypothetical fear that what the
 

1531
00:35:31,760 --> 00:35:35,430
is a hypothetical fear that what the
encoder will learn is just identity.

1532
00:35:35,430 --> 00:35:35,440
encoder will learn is just identity.
 

1533
00:35:35,440 --> 00:35:39,990
encoder will learn is just identity.
and the decoder will just be identity.

1534
00:35:39,990 --> 00:35:40,000

 

1535
00:35:40,000 --> 00:35:44,069

Adding masking or adding noise blocks

1536
00:35:44,069 --> 00:35:44,079
Adding masking or adding noise blocks
 

1537
00:35:44,079 --> 00:35:47,829
Adding masking or adding noise blocks
identity from being a valid solution.

1538
00:35:47,829 --> 00:35:47,839
identity from being a valid solution.
 

1539
00:35:47,839 --> 00:35:49,430
identity from being a valid solution.
So that's the traditional way one

1540
00:35:49,430 --> 00:35:49,440
So that's the traditional way one
 

1541
00:35:49,440 --> 00:35:51,030
So that's the traditional way one
understands the value of doing masking

1542
00:35:51,030 --> 00:35:51,040
understands the value of doing masking
 

1543
00:35:51,040 --> 00:35:54,069
understands the value of doing masking
or uh denoising autoenccoders.

1544
00:35:54,069 --> 00:35:54,079
or uh denoising autoenccoders.
 

1545
00:35:54,079 --> 00:35:57,109
or uh denoising autoenccoders.
But we'll show you in the homework that

1546
00:35:57,109 --> 00:35:57,119
But we'll show you in the homework that
 

1547
00:35:57,119 --> 00:36:00,550
But we'll show you in the homework that
actually remember we said there's many

1548
00:36:00,550 --> 00:36:00,560
actually remember we said there's many
 

1549
00:36:00,560 --> 00:36:03,030
actually remember we said there's many
things that are regularizing and one of

1550
00:36:03,030 --> 00:36:03,040
things that are regularizing and one of
 

1551
00:36:03,040 --> 00:36:04,470
things that are regularizing and one of
them is actually the actions of the

1552
00:36:04,470 --> 00:36:04,480
them is actually the actions of the
 

1553
00:36:04,480 --> 00:36:06,870
them is actually the actions of the
optimizer itself and gradient descent.

1554
00:36:06,870 --> 00:36:06,880
optimizer itself and gradient descent.
 

1555
00:36:06,880 --> 00:36:08,870
optimizer itself and gradient descent.
So even the

1556
00:36:08,870 --> 00:36:08,880
So even the
 

1557
00:36:08,880 --> 00:36:10,790
So even the
just the actions of gradient descent

1558
00:36:10,790 --> 00:36:10,800
just the actions of gradient descent
 

1559
00:36:10,800 --> 00:36:13,109
just the actions of gradient descent
itself in training the autoenccoder will

1560
00:36:13,109 --> 00:36:13,119
itself in training the autoenccoder will
 

1561
00:36:13,119 --> 00:36:16,069
itself in training the autoenccoder will
also bring a regularizing effect

1562
00:36:16,069 --> 00:36:16,079
also bring a regularizing effect
 

1563
00:36:16,079 --> 00:36:18,870
also bring a regularizing effect
even if you don't have the bottleneck.

1564
00:36:18,870 --> 00:36:18,880
even if you don't have the bottleneck.
 

1565
00:36:18,880 --> 00:36:21,109
even if you don't have the bottleneck.
Okay. So that you'll see in in the

1566
00:36:21,109 --> 00:36:21,119
Okay. So that you'll see in in the
 

1567
00:36:21,119 --> 00:36:24,550
Okay. So that you'll see in in the
homework.

1568
00:36:24,550 --> 00:36:24,560

 

1569
00:36:24,560 --> 00:36:26,310

Okay,

1570
00:36:26,310 --> 00:36:26,320
Okay,
 

1571
00:36:26,320 --> 00:36:28,310
Okay,
any questions on autoenccoding? So it's

1572
00:36:28,310 --> 00:36:28,320
any questions on autoenccoding? So it's
 

1573
00:36:28,320 --> 00:36:29,910
any questions on autoenccoding? So it's
like a a classic example of self-s

1574
00:36:29,910 --> 00:36:29,920
like a a classic example of self-s
 

1575
00:36:29,920 --> 00:36:32,310
like a a classic example of self-s
supervision. The same thing masked

1576
00:36:32,310 --> 00:36:32,320
supervision. The same thing masked
 

1577
00:36:32,320 --> 00:36:34,390
supervision. The same thing masked
autoenccoders will come up when we talk

1578
00:36:34,390 --> 00:36:34,400
autoenccoders will come up when we talk
 

1579
00:36:34,400 --> 00:36:37,270
autoenccoders will come up when we talk
about uh for example BERT in the

1580
00:36:37,270 --> 00:36:37,280
about uh for example BERT in the
 

1581
00:36:37,280 --> 00:36:39,510
about uh for example BERT in the
language processing context. It's just

1582
00:36:39,510 --> 00:36:39,520
language processing context. It's just
 

1583
00:36:39,520 --> 00:36:41,270
language processing context. It's just
exactly this idea applied in language

1584
00:36:41,270 --> 00:36:41,280
exactly this idea applied in language
 

1585
00:36:41,280 --> 00:36:42,550
exactly this idea applied in language
settings. Yeah.

1586
00:36:42,550 --> 00:36:42,560
settings. Yeah.
 

1587
00:36:42,560 --> 00:36:46,150
settings. Yeah.
>> For mass autoenccoders, your losses over

1588
00:36:46,150 --> 00:36:46,160
>> For mass autoenccoders, your losses over
 

1589
00:36:46,160 --> 00:36:49,270
>> For mass autoenccoders, your losses over
the regions, right? Or is there where

1590
00:36:49,270 --> 00:36:49,280
the regions, right? Or is there where
 

1591
00:36:49,280 --> 00:36:50,790
the regions, right? Or is there where
they were computed over the entire

1592
00:36:50,790 --> 00:36:50,800
they were computed over the entire
 

1593
00:36:50,800 --> 00:36:51,589
they were computed over the entire
image.

1594
00:36:51,589 --> 00:36:51,599
image.
 

1595
00:36:51,599 --> 00:36:52,950
image.
>> Great question. So here you have a

1596
00:36:52,950 --> 00:36:52,960
>> Great question. So here you have a
 

1597
00:36:52,960 --> 00:36:54,790
>> Great question. So here you have a
choice of what you're trying to do,

1598
00:36:54,790 --> 00:36:54,800
choice of what you're trying to do,
 

1599
00:36:54,800 --> 00:36:57,270
choice of what you're trying to do,
right? So depending on the architecture,

1600
00:36:57,270 --> 00:36:57,280
right? So depending on the architecture,
 

1601
00:36:57,280 --> 00:37:00,790
right? So depending on the architecture,
you could say I want to have the mask

1602
00:37:00,790 --> 00:37:00,800
you could say I want to have the mask
 

1603
00:37:00,800 --> 00:37:02,310
you could say I want to have the mask
the reconstruction on everything, which

1604
00:37:02,310 --> 00:37:02,320
the reconstruction on everything, which
 

1605
00:37:02,320 --> 00:37:04,150
the reconstruction on everything, which
is what I've described here. There's

1606
00:37:04,150 --> 00:37:04,160
is what I've described here. There's
 

1607
00:37:04,160 --> 00:37:05,670
is what I've described here. There's
some cases where you can follow the

1608
00:37:05,670 --> 00:37:05,680
some cases where you can follow the
 

1609
00:37:05,680 --> 00:37:07,190
some cases where you can follow the
spirit of masked autoenccoding and just

1610
00:37:07,190 --> 00:37:07,200
spirit of masked autoenccoding and just
 

1611
00:37:07,200 --> 00:37:08,550
spirit of masked autoenccoding and just
say I just want to reconstruct the

1612
00:37:08,550 --> 00:37:08,560
say I just want to reconstruct the
 

1613
00:37:08,560 --> 00:37:11,030
say I just want to reconstruct the
masked parts.

1614
00:37:11,030 --> 00:37:11,040
masked parts.
 

1615
00:37:11,040 --> 00:37:17,990
masked parts.
>> Yeah.

1616
00:37:17,990 --> 00:37:18,000

 

1617
00:37:18,000 --> 00:37:19,430

>> Yes.

1618
00:37:19,430 --> 00:37:19,440
>> Yes.
 

1619
00:37:19,440 --> 00:37:24,310
>> Yes.
So

1620
00:37:24,310 --> 00:37:24,320

 

1621
00:37:24,320 --> 00:37:26,630

>> yeah, so again this is an important and

1622
00:37:26,630 --> 00:37:26,640
>> yeah, so again this is an important and
 

1623
00:37:26,640 --> 00:37:29,750
>> yeah, so again this is an important and
subtle point. When people started doing

1624
00:37:29,750 --> 00:37:29,760
subtle point. When people started doing
 

1625
00:37:29,760 --> 00:37:33,430
subtle point. When people started doing
uh autoenccoders, they thought you have

1626
00:37:33,430 --> 00:37:33,440
uh autoenccoders, they thought you have
 

1627
00:37:33,440 --> 00:37:37,190
uh autoenccoders, they thought you have
to have an actual bottleneck.

1628
00:37:37,190 --> 00:37:37,200
to have an actual bottleneck.
 

1629
00:37:37,200 --> 00:37:39,829
to have an actual bottleneck.
That's how people started.

1630
00:37:39,829 --> 00:37:39,839
That's how people started.
 

1631
00:37:39,839 --> 00:37:43,910
That's how people started.
Then people realized that wait, we have

1632
00:37:43,910 --> 00:37:43,920
Then people realized that wait, we have
 

1633
00:37:43,920 --> 00:37:45,270
Then people realized that wait, we have
multiple ways of expressing

1634
00:37:45,270 --> 00:37:45,280
multiple ways of expressing
 

1635
00:37:45,280 --> 00:37:47,589
multiple ways of expressing
regularities.

1636
00:37:47,589 --> 00:37:47,599
regularities.
 

1637
00:37:47,599 --> 00:37:50,790
regularities.
So sparse autoenccoders are the classic

1638
00:37:50,790 --> 00:37:50,800
So sparse autoenccoders are the classic
 

1639
00:37:50,800 --> 00:37:52,550
So sparse autoenccoders are the classic
example which says I don't have to make

1640
00:37:52,550 --> 00:37:52,560
example which says I don't have to make
 

1641
00:37:52,560 --> 00:37:55,510
example which says I don't have to make
the bottleneck small in dimension. It

1642
00:37:55,510 --> 00:37:55,520
the bottleneck small in dimension. It
 

1643
00:37:55,520 --> 00:37:57,430
the bottleneck small in dimension. It
can be large but I'll force sparsity to

1644
00:37:57,430 --> 00:37:57,440
can be large but I'll force sparsity to
 

1645
00:37:57,440 --> 00:37:58,630
can be large but I'll force sparsity to
make it small. You see this is like

1646
00:37:58,630 --> 00:37:58,640
make it small. You see this is like
 

1647
00:37:58,640 --> 00:38:00,310
make it small. You see this is like
edging out. You start off saying it has

1648
00:38:00,310 --> 00:38:00,320
edging out. You start off saying it has
 

1649
00:38:00,320 --> 00:38:02,950
edging out. You start off saying it has
to be small. You're like okay it could

1650
00:38:02,950 --> 00:38:02,960
to be small. You're like okay it could
 

1651
00:38:02,960 --> 00:38:08,550
to be small. You're like okay it could
be big but sparse. Okay. And then when

1652
00:38:08,550 --> 00:38:08,560
be big but sparse. Okay. And then when
 

1653
00:38:08,560 --> 00:38:10,550
be big but sparse. Okay. And then when
you go to denoising autoenccoders,

1654
00:38:10,550 --> 00:38:10,560
you go to denoising autoenccoders,
 

1655
00:38:10,560 --> 00:38:14,630
you go to denoising autoenccoders,
you're like, actually,

1656
00:38:14,630 --> 00:38:14,640

 

1657
00:38:14,640 --> 00:38:19,510

maybe it doesn't even have to be small.

1658
00:38:19,510 --> 00:38:19,520

 

1659
00:38:19,520 --> 00:38:24,150

Okay, so now here it could be, you're

1660
00:38:24,150 --> 00:38:24,160
Okay, so now here it could be, you're
 

1661
00:38:24,160 --> 00:38:27,510
Okay, so now here it could be, you're
right, a hypothetically it could be that

1662
00:38:27,510 --> 00:38:27,520
right, a hypothetically it could be that
 

1663
00:38:27,520 --> 00:38:30,470
right, a hypothetically it could be that
this thing just learns the identity and

1664
00:38:30,470 --> 00:38:30,480
this thing just learns the identity and
 

1665
00:38:30,480 --> 00:38:32,069
this thing just learns the identity and
this thing does all the work of

1666
00:38:32,069 --> 00:38:32,079
this thing does all the work of
 

1667
00:38:32,079 --> 00:38:34,230
this thing does all the work of
denoising.

1668
00:38:34,230 --> 00:38:34,240
denoising.
 

1669
00:38:34,240 --> 00:38:35,910
denoising.
That could happen, right? Right? That's

1670
00:38:35,910 --> 00:38:35,920
That could happen, right? Right? That's
 

1671
00:38:35,920 --> 00:38:38,710
That could happen, right? Right? That's
a possible valid solution. But you

1672
00:38:38,710 --> 00:38:38,720
a possible valid solution. But you
 

1673
00:38:38,720 --> 00:38:40,390
a possible valid solution. But you
expect during training like why would it

1674
00:38:40,390 --> 00:38:40,400
expect during training like why would it
 

1675
00:38:40,400 --> 00:38:44,550
expect during training like why would it
put all the work here,

1676
00:38:44,550 --> 00:38:44,560

 

1677
00:38:44,560 --> 00:38:45,990

right? Why would gradient descent do

1678
00:38:45,990 --> 00:38:46,000
right? Why would gradient descent do
 

1679
00:38:46,000 --> 00:38:48,550
right? Why would gradient descent do
that? Probably won't,

1680
00:38:48,550 --> 00:38:48,560
that? Probably won't,
 

1681
00:38:48,560 --> 00:38:51,670
that? Probably won't,
right? Probably split the work.

1682
00:38:51,670 --> 00:38:51,680
right? Probably split the work.
 

1683
00:38:51,680 --> 00:38:53,430
right? Probably split the work.
And if it splits the work of doing some

1684
00:38:53,430 --> 00:38:53,440
And if it splits the work of doing some
 

1685
00:38:53,440 --> 00:38:56,310
And if it splits the work of doing some
of the denoising in this part, then this

1686
00:38:56,310 --> 00:38:56,320
of the denoising in this part, then this
 

1687
00:38:56,320 --> 00:38:57,349
of the denoising in this part, then this
is still going to be a better

1688
00:38:57,349 --> 00:38:57,359
is still going to be a better
 

1689
00:38:57,359 --> 00:39:01,829
is still going to be a better
representation quote than the input.

1690
00:39:01,829 --> 00:39:01,839
representation quote than the input.
 

1691
00:39:01,839 --> 00:39:04,230
representation quote than the input.
Okay, that's like an intuition. But once

1692
00:39:04,230 --> 00:39:04,240
Okay, that's like an intuition. But once
 

1693
00:39:04,240 --> 00:39:07,270
Okay, that's like an intuition. But once
you take that intuition, right, you can

1694
00:39:07,270 --> 00:39:07,280
you take that intuition, right, you can
 

1695
00:39:07,280 --> 00:39:09,109
you take that intuition, right, you can
say, okay, the same same exact thing

1696
00:39:09,109 --> 00:39:09,119
say, okay, the same same exact thing
 

1697
00:39:09,119 --> 00:39:10,950
say, okay, the same same exact thing
applies here. You know, this does this

1698
00:39:10,950 --> 00:39:10,960
applies here. You know, this does this
 

1699
00:39:10,960 --> 00:39:13,750
applies here. You know, this does this
doesn't have to be smaller anymore. It

1700
00:39:13,750 --> 00:39:13,760
doesn't have to be smaller anymore. It
 

1701
00:39:13,760 --> 00:39:15,829
doesn't have to be smaller anymore. It
could be the same size or it could be

1702
00:39:15,829 --> 00:39:15,839
could be the same size or it could be
 

1703
00:39:15,839 --> 00:39:18,069
could be the same size or it could be
bigger.

1704
00:39:18,069 --> 00:39:18,079
bigger.
 

1705
00:39:18,079 --> 00:39:22,390
bigger.
Gradient descent is also a player.

1706
00:39:22,390 --> 00:39:22,400
Gradient descent is also a player.
 

1707
00:39:22,400 --> 00:39:25,589
Gradient descent is also a player.
So that's the kind of evolution of the

1708
00:39:25,589 --> 00:39:25,599
So that's the kind of evolution of the
 

1709
00:39:25,599 --> 00:39:27,349
So that's the kind of evolution of the
spirit of autoenccoding from the initial

1710
00:39:27,349 --> 00:39:27,359
spirit of autoenccoding from the initial
 

1711
00:39:27,359 --> 00:39:30,230
spirit of autoenccoding from the initial
it must be a bottleneck to now all

1712
00:39:30,230 --> 00:39:30,240
it must be a bottleneck to now all
 

1713
00:39:30,240 --> 00:39:33,030
it must be a bottleneck to now all
you're trying to do is sort of purify

1714
00:39:33,030 --> 00:39:33,040
you're trying to do is sort of purify
 

1715
00:39:33,040 --> 00:39:35,510
you're trying to do is sort of purify
clean up the representations so they

1716
00:39:35,510 --> 00:39:35,520
clean up the representations so they
 

1717
00:39:35,520 --> 00:39:38,790
clean up the representations so they
better capture what's important.

1718
00:39:38,790 --> 00:39:38,800
better capture what's important.
 

1719
00:39:38,800 --> 00:39:41,030
better capture what's important.
This is vague

1720
00:39:41,030 --> 00:39:41,040
This is vague
 

1721
00:39:41,040 --> 00:39:44,870
This is vague
okay but hopefully it but it's still the

1722
00:39:44,870 --> 00:39:44,880
okay but hopefully it but it's still the
 

1723
00:39:44,880 --> 00:39:47,190
okay but hopefully it but it's still the
same spirit as dimensional reduction in

1724
00:39:47,190 --> 00:39:47,200
same spirit as dimensional reduction in
 

1725
00:39:47,200 --> 00:39:48,790
same spirit as dimensional reduction in
that what makes it better might be

1726
00:39:48,790 --> 00:39:48,800
that what makes it better might be
 

1727
00:39:48,800 --> 00:39:50,470
that what makes it better might be
better for a downstream task. you just

1728
00:39:50,470 --> 00:39:50,480
better for a downstream task. you just
 

1729
00:39:50,480 --> 00:39:52,310
better for a downstream task. you just
take these encodings and you use them

1730
00:39:52,310 --> 00:39:52,320
take these encodings and you use them
 

1731
00:39:52,320 --> 00:39:55,349
take these encodings and you use them
for training another uh downstream task

1732
00:39:55,349 --> 00:39:55,359
for training another uh downstream task
 

1733
00:39:55,359 --> 00:39:56,790
for training another uh downstream task
the same way you use a dimensionality

1734
00:39:56,790 --> 00:39:56,800
the same way you use a dimensionality
 

1735
00:39:56,800 --> 00:39:59,910
the same way you use a dimensionality
reduction from PCA

1736
00:39:59,910 --> 00:39:59,920
reduction from PCA
 

1737
00:39:59,920 --> 00:40:01,589
reduction from PCA
and so the final proof of it being

1738
00:40:01,589 --> 00:40:01,599
and so the final proof of it being
 

1739
00:40:01,599 --> 00:40:03,270
and so the final proof of it being
better is it works better for a

1740
00:40:03,270 --> 00:40:03,280
better is it works better for a
 

1741
00:40:03,280 --> 00:40:06,790
better is it works better for a
downstream task

1742
00:40:06,790 --> 00:40:06,800

 

1743
00:40:06,800 --> 00:40:08,790

okay

1744
00:40:08,790 --> 00:40:08,800
okay
 

1745
00:40:08,800 --> 00:40:10,550
okay
so

1746
00:40:10,550 --> 00:40:10,560
so
 

1747
00:40:10,560 --> 00:40:14,230
so
um I want to kind of stop with like a

1748
00:40:14,230 --> 00:40:14,240
um I want to kind of stop with like a
 

1749
00:40:14,240 --> 00:40:15,670
um I want to kind of stop with like a
little tiny comment on one more thing

1750
00:40:15,670 --> 00:40:15,680
little tiny comment on one more thing
 

1751
00:40:15,680 --> 00:40:16,790
little tiny comment on one more thing
I'm not going to spend a lot of time on

1752
00:40:16,790 --> 00:40:16,800
I'm not going to spend a lot of time on
 

1753
00:40:16,800 --> 00:40:18,069
I'm not going to spend a lot of time on
this but I want to make sure you're

1754
00:40:18,069 --> 00:40:18,079
this but I want to make sure you're
 

1755
00:40:18,079 --> 00:40:20,870
this but I want to make sure you're
aware of it We started off by saying

1756
00:40:20,870 --> 00:40:20,880
aware of it We started off by saying
 

1757
00:40:20,880 --> 00:40:23,510
aware of it We started off by saying
there's two different approaches to

1758
00:40:23,510 --> 00:40:23,520
there's two different approaches to
 

1759
00:40:23,520 --> 00:40:26,230
there's two different approaches to
dimensional to uh unsupervised learning

1760
00:40:26,230 --> 00:40:26,240
dimensional to uh unsupervised learning
 

1761
00:40:26,240 --> 00:40:28,470
dimensional to uh unsupervised learning
in traditional ML. There's the

1762
00:40:28,470 --> 00:40:28,480
in traditional ML. There's the
 

1763
00:40:28,480 --> 00:40:29,990
in traditional ML. There's the
dimensionality reduction approach and

1764
00:40:29,990 --> 00:40:30,000
dimensionality reduction approach and
 

1765
00:40:30,000 --> 00:40:32,150
dimensionality reduction approach and
then there's the clustering approach.

1766
00:40:32,150 --> 00:40:32,160
then there's the clustering approach.
 

1767
00:40:32,160 --> 00:40:33,589
then there's the clustering approach.
And what I've just told you is that

1768
00:40:33,589 --> 00:40:33,599
And what I've just told you is that
 

1769
00:40:33,599 --> 00:40:35,990
And what I've just told you is that
dimensionality reduction in spirit

1770
00:40:35,990 --> 00:40:36,000
dimensionality reduction in spirit
 

1771
00:40:36,000 --> 00:40:37,990
dimensionality reduction in spirit
connects this autoenccoder style of

1772
00:40:37,990 --> 00:40:38,000
connects this autoenccoder style of
 

1773
00:40:38,000 --> 00:40:40,470
connects this autoenccoder style of
self-s supervision.

1774
00:40:40,470 --> 00:40:40,480
self-s supervision.
 

1775
00:40:40,480 --> 00:40:42,630
self-s supervision.
So you should just from your love of

1776
00:40:42,630 --> 00:40:42,640
So you should just from your love of
 

1777
00:40:42,640 --> 00:40:46,310
So you should just from your love of
symmetry, right? Say, is there a

1778
00:40:46,310 --> 00:40:46,320
symmetry, right? Say, is there a
 

1779
00:40:46,320 --> 00:40:50,150
symmetry, right? Say, is there a
counterpart of the clustering spirit?

1780
00:40:50,150 --> 00:40:50,160
counterpart of the clustering spirit?
 

1781
00:40:50,160 --> 00:40:51,430
counterpart of the clustering spirit?
Do you see that? It's just a way of

1782
00:40:51,430 --> 00:40:51,440
Do you see that? It's just a way of
 

1783
00:40:51,440 --> 00:40:53,670
Do you see that? It's just a way of
thinking, right? Can you make clustering

1784
00:40:53,670 --> 00:40:53,680
thinking, right? Can you make clustering
 

1785
00:40:53,680 --> 00:40:55,750
thinking, right? Can you make clustering
also feel like it's a kind of

1786
00:40:55,750 --> 00:40:55,760
also feel like it's a kind of
 

1787
00:40:55,760 --> 00:40:58,470
also feel like it's a kind of
self-supervision?

1788
00:40:58,470 --> 00:40:58,480
self-supervision?
 

1789
00:40:58,480 --> 00:41:02,069
self-supervision?
And the answer is you can. And it's

1790
00:41:02,069 --> 00:41:02,079
And the answer is you can. And it's
 

1791
00:41:02,079 --> 00:41:05,750
And the answer is you can. And it's
called contrastive self-supervision.

1792
00:41:05,750 --> 00:41:05,760
called contrastive self-supervision.
 

1793
00:41:05,760 --> 00:41:08,870
called contrastive self-supervision.
And so the core idea of contrastive

1794
00:41:08,870 --> 00:41:08,880
And so the core idea of contrastive
 

1795
00:41:08,880 --> 00:41:10,470
And so the core idea of contrastive
self-supervision

1796
00:41:10,470 --> 00:41:10,480
self-supervision
 

1797
00:41:10,480 --> 00:41:15,349
self-supervision
says any example in your data and its

1798
00:41:15,349 --> 00:41:15,359
says any example in your data and its
 

1799
00:41:15,359 --> 00:41:17,510
says any example in your data and its
own augmentations.

1800
00:41:17,510 --> 00:41:17,520
own augmentations.
 

1801
00:41:17,520 --> 00:41:19,670
own augmentations.
Okay. So you take an example an image

1802
00:41:19,670 --> 00:41:19,680
Okay. So you take an example an image
 

1803
00:41:19,680 --> 00:41:23,109
Okay. So you take an example an image
and do a data augmentation on it.

1804
00:41:23,109 --> 00:41:23,119
and do a data augmentation on it.
 

1805
00:41:23,119 --> 00:41:25,510
and do a data augmentation on it.
Whatever cluster the original belongs to

1806
00:41:25,510 --> 00:41:25,520
Whatever cluster the original belongs to
 

1807
00:41:25,520 --> 00:41:27,190
Whatever cluster the original belongs to
the augmentation should probably belong

1808
00:41:27,190 --> 00:41:27,200
the augmentation should probably belong
 

1809
00:41:27,200 --> 00:41:29,670
the augmentation should probably belong
to the same cluster.

1810
00:41:29,670 --> 00:41:29,680
to the same cluster.
 

1811
00:41:29,680 --> 00:41:31,430
to the same cluster.
Does everyone see that as a spirit? The

1812
00:41:31,430 --> 00:41:31,440
Does everyone see that as a spirit? The
 

1813
00:41:31,440 --> 00:41:33,030
Does everyone see that as a spirit? The
augmentation is not supposed to change

1814
00:41:33,030 --> 00:41:33,040
augmentation is not supposed to change
 

1815
00:41:33,040 --> 00:41:36,550
augmentation is not supposed to change
its character a lot.

1816
00:41:36,550 --> 00:41:36,560
its character a lot.
 

1817
00:41:36,560 --> 00:41:37,829
its character a lot.
So you should probably belong to the

1818
00:41:37,829 --> 00:41:37,839
So you should probably belong to the
 

1819
00:41:37,839 --> 00:41:40,390
So you should probably belong to the
same cluster. Does everyone see that?

1820
00:41:40,390 --> 00:41:40,400
same cluster. Does everyone see that?
 

1821
00:41:40,400 --> 00:41:42,870
same cluster. Does everyone see that?
It's okay.

1822
00:41:42,870 --> 00:41:42,880
It's okay.
 

1823
00:41:42,880 --> 00:41:45,109
It's okay.
That's the idea.

1824
00:41:45,109 --> 00:41:45,119
That's the idea.
 

1825
00:41:45,119 --> 00:41:47,829
That's the idea.
And similarly,

1826
00:41:47,829 --> 00:41:47,839
And similarly,
 

1827
00:41:47,839 --> 00:41:50,470
And similarly,
fundamentally different examples in your

1828
00:41:50,470 --> 00:41:50,480
fundamentally different examples in your
 

1829
00:41:50,480 --> 00:41:52,630
fundamentally different examples in your
training data probably belong to

1830
00:41:52,630 --> 00:41:52,640
training data probably belong to
 

1831
00:41:52,640 --> 00:41:55,030
training data probably belong to
different clusters. So the spirit here

1832
00:41:55,030 --> 00:41:55,040
different clusters. So the spirit here
 

1833
00:41:55,040 --> 00:41:57,510
different clusters. So the spirit here
is your data is quite rich. There's a

1834
00:41:57,510 --> 00:41:57,520
is your data is quite rich. There's a
 

1835
00:41:57,520 --> 00:42:00,950
is your data is quite rich. There's a
thousand different kinds of objects.

1836
00:42:00,950 --> 00:42:00,960
thousand different kinds of objects.
 

1837
00:42:00,960 --> 00:42:04,309
thousand different kinds of objects.
So you pick an image at random, its

1838
00:42:04,309 --> 00:42:04,319
So you pick an image at random, its
 

1839
00:42:04,319 --> 00:42:06,150
So you pick an image at random, its
augmentation is in the same cluster as

1840
00:42:06,150 --> 00:42:06,160
augmentation is in the same cluster as
 

1841
00:42:06,160 --> 00:42:09,030
augmentation is in the same cluster as
this image. If you pick another image at

1842
00:42:09,030 --> 00:42:09,040
this image. If you pick another image at
 

1843
00:42:09,040 --> 00:42:11,510
this image. If you pick another image at
random, it's not going to be in the same

1844
00:42:11,510 --> 00:42:11,520
random, it's not going to be in the same
 

1845
00:42:11,520 --> 00:42:13,829
random, it's not going to be in the same
cluster.

1846
00:42:13,829 --> 00:42:13,839
cluster.
 

1847
00:42:13,839 --> 00:42:18,630
cluster.
Everyone see that as a kind of guess.

1848
00:42:18,630 --> 00:42:18,640
Everyone see that as a kind of guess.
 

1849
00:42:18,640 --> 00:42:21,109
Everyone see that as a kind of guess.
So can you turn make a learning

1850
00:42:21,109 --> 00:42:21,119
So can you turn make a learning
 

1851
00:42:21,119 --> 00:42:24,710
So can you turn make a learning
algorithm based on this? And the answer

1852
00:42:24,710 --> 00:42:24,720
algorithm based on this? And the answer
 

1853
00:42:24,720 --> 00:42:30,710
algorithm based on this? And the answer
is sure you can. Okay.

1854
00:42:30,710 --> 00:42:30,720

 

1855
00:42:30,720 --> 00:42:32,870

So I have some papers here that you can

1856
00:42:32,870 --> 00:42:32,880
So I have some papers here that you can
 

1857
00:42:32,880 --> 00:42:37,109
So I have some papers here that you can
read the references to. Um

1858
00:42:37,109 --> 00:42:37,119
read the references to. Um
 

1859
00:42:37,119 --> 00:42:39,510
read the references to. Um
you take a you take a data point and you

1860
00:42:39,510 --> 00:42:39,520
you take a you take a data point and you
 

1861
00:42:39,520 --> 00:42:42,069
you take a you take a data point and you
take another randomly chosen data point.

1862
00:42:42,069 --> 00:42:42,079
take another randomly chosen data point.
 

1863
00:42:42,079 --> 00:42:43,670
take another randomly chosen data point.
They probably belong to different

1864
00:42:43,670 --> 00:42:43,680
They probably belong to different
 

1865
00:42:43,680 --> 00:42:46,390
They probably belong to different
clusters. So you have an encoder for

1866
00:42:46,390 --> 00:42:46,400
clusters. So you have an encoder for
 

1867
00:42:46,400 --> 00:42:49,109
clusters. So you have an encoder for
them that results in some embedding.

1868
00:42:49,109 --> 00:42:49,119
them that results in some embedding.
 

1869
00:42:49,119 --> 00:42:52,309
them that results in some embedding.
These two belong to different clusters.

1870
00:42:52,309 --> 00:42:52,319
These two belong to different clusters.
 

1871
00:42:52,319 --> 00:42:53,990
These two belong to different clusters.
What does that mean from a clustering

1872
00:42:53,990 --> 00:42:54,000
What does that mean from a clustering
 

1873
00:42:54,000 --> 00:42:55,109
What does that mean from a clustering
algorithm point of view? It means

1874
00:42:55,109 --> 00:42:55,119
algorithm point of view? It means
 

1875
00:42:55,119 --> 00:42:57,109
algorithm point of view? It means
they're far away from each other because

1876
00:42:57,109 --> 00:42:57,119
they're far away from each other because
 

1877
00:42:57,119 --> 00:42:58,950
they're far away from each other because
clustering algorithms like K means being

1878
00:42:58,950 --> 00:42:58,960
clustering algorithms like K means being
 

1879
00:42:58,960 --> 00:43:01,910
clustering algorithms like K means being
things that are close together.

1880
00:43:01,910 --> 00:43:01,920
things that are close together.
 

1881
00:43:01,920 --> 00:43:04,470
things that are close together.
So you say you enforce make these be far

1882
00:43:04,470 --> 00:43:04,480
So you say you enforce make these be far
 

1883
00:43:04,480 --> 00:43:07,829
So you say you enforce make these be far
apart. You reward distance.

1884
00:43:07,829 --> 00:43:07,839
apart. You reward distance.
 

1885
00:43:07,839 --> 00:43:11,589
apart. You reward distance.
Whereas an augmentation of this you say

1886
00:43:11,589 --> 00:43:11,599
Whereas an augmentation of this you say
 

1887
00:43:11,599 --> 00:43:14,390
Whereas an augmentation of this you say
belongs to the same cluster.

1888
00:43:14,390 --> 00:43:14,400
belongs to the same cluster.
 

1889
00:43:14,400 --> 00:43:16,950
belongs to the same cluster.
So you reward closeness

1890
00:43:16,950 --> 00:43:16,960
So you reward closeness
 

1891
00:43:16,960 --> 00:43:19,270
So you reward closeness
penalize distance

1892
00:43:19,270 --> 00:43:19,280
penalize distance
 

1893
00:43:19,280 --> 00:43:22,069
penalize distance
and you just train. Now to be careful to

1894
00:43:22,069 --> 00:43:22,079
and you just train. Now to be careful to
 

1895
00:43:22,079 --> 00:43:24,069
and you just train. Now to be careful to
choose a distance, right? So this this

1896
00:43:24,069 --> 00:43:24,079
choose a distance, right? So this this
 

1897
00:43:24,079 --> 00:43:26,790
choose a distance, right? So this this
works but this is called contrastive

1898
00:43:26,790 --> 00:43:26,800
works but this is called contrastive
 

1899
00:43:26,800 --> 00:43:29,990
works but this is called contrastive
self-s supervision. It's not a there's

1900
00:43:29,990 --> 00:43:30,000
self-s supervision. It's not a there's
 

1901
00:43:30,000 --> 00:43:32,470
self-s supervision. It's not a there's
no decoder here.

1902
00:43:32,470 --> 00:43:32,480
no decoder here.
 

1903
00:43:32,480 --> 00:43:35,349
no decoder here.
There's only encoders

1904
00:43:35,349 --> 00:43:35,359
There's only encoders
 

1905
00:43:35,359 --> 00:43:40,630
There's only encoders
that are trying to learn the regularity.

1906
00:43:40,630 --> 00:43:40,640

 

1907
00:43:40,640 --> 00:43:43,589

So fundamentally this requires the

1908
00:43:43,589 --> 00:43:43,599
So fundamentally this requires the
 

1909
00:43:43,599 --> 00:43:45,510
So fundamentally this requires the
augmentations.

1910
00:43:45,510 --> 00:43:45,520
augmentations.
 

1911
00:43:45,520 --> 00:43:47,349
augmentations.
Okay. Contrast self-servision requires

1912
00:43:47,349 --> 00:43:47,359
Okay. Contrast self-servision requires
 

1913
00:43:47,359 --> 00:43:51,829
Okay. Contrast self-servision requires
augmentations.

1914
00:43:51,829 --> 00:43:51,839

 

1915
00:43:51,839 --> 00:43:55,910

Okay. So just

1916
00:43:55,910 --> 00:43:55,920
Okay. So just
 

1917
00:43:55,920 --> 00:43:57,510
Okay. So just
because deep learning is interesting and

1918
00:43:57,510 --> 00:43:57,520
because deep learning is interesting and
 

1919
00:43:57,520 --> 00:44:00,710
because deep learning is interesting and
weird um the fun thing that I'll leave

1920
00:44:00,710 --> 00:44:00,720
weird um the fun thing that I'll leave
 

1921
00:44:00,720 --> 00:44:03,430
weird um the fun thing that I'll leave
to you to read about if you want to is

1922
00:44:03,430 --> 00:44:03,440
to you to read about if you want to is
 

1923
00:44:03,440 --> 00:44:05,750
to you to read about if you want to is
to say can you do contrastive self-s

1924
00:44:05,750 --> 00:44:05,760
to say can you do contrastive self-s
 

1925
00:44:05,760 --> 00:44:09,190
to say can you do contrastive self-s
supervision without the contrast.

1926
00:44:09,190 --> 00:44:09,200
supervision without the contrast.
 

1927
00:44:09,200 --> 00:44:11,910
supervision without the contrast.
Okay, what this is saying is remember I

1928
00:44:11,910 --> 00:44:11,920
Okay, what this is saying is remember I
 

1929
00:44:11,920 --> 00:44:13,990
Okay, what this is saying is remember I
said you randomly pick another image and

1930
00:44:13,990 --> 00:44:14,000
said you randomly pick another image and
 

1931
00:44:14,000 --> 00:44:15,829
said you randomly pick another image and
it's probably in a different cluster.

1932
00:44:15,829 --> 00:44:15,839
it's probably in a different cluster.
 

1933
00:44:15,839 --> 00:44:17,670
it's probably in a different cluster.
People found that in practice, if it was

1934
00:44:17,670 --> 00:44:17,680
People found that in practice, if it was
 

1935
00:44:17,680 --> 00:44:19,349
People found that in practice, if it was
actually in the same cluster, bad things

1936
00:44:19,349 --> 00:44:19,359
actually in the same cluster, bad things
 

1937
00:44:19,359 --> 00:44:20,630
actually in the same cluster, bad things
might happen a little bit during

1938
00:44:20,630 --> 00:44:20,640
might happen a little bit during
 

1939
00:44:20,640 --> 00:44:21,910
might happen a little bit during
training because you're trying to push

1940
00:44:21,910 --> 00:44:21,920
training because you're trying to push
 

1941
00:44:21,920 --> 00:44:23,750
training because you're trying to push
apart things that should be together and

1942
00:44:23,750 --> 00:44:23,760
apart things that should be together and
 

1943
00:44:23,760 --> 00:44:25,510
apart things that should be together and
that can sometimes cause trouble. So the

1944
00:44:25,510 --> 00:44:25,520
that can sometimes cause trouble. So the
 

1945
00:44:25,520 --> 00:44:26,630
that can sometimes cause trouble. So the
question is, can you get away from

1946
00:44:26,630 --> 00:44:26,640
question is, can you get away from
 

1947
00:44:26,640 --> 00:44:28,950
question is, can you get away from
having negative examples at all? And

1948
00:44:28,950 --> 00:44:28,960
having negative examples at all? And
 

1949
00:44:28,960 --> 00:44:32,390
having negative examples at all? And
there are tricks that uh let you let

1950
00:44:32,390 --> 00:44:32,400
there are tricks that uh let you let
 

1951
00:44:32,400 --> 00:44:38,550
there are tricks that uh let you let
that work. Yeah,

1952
00:44:38,550 --> 00:44:38,560

 

1953
00:44:38,560 --> 00:44:41,109

>> data augmentation means do uh it's

1954
00:44:41,109 --> 00:44:41,119
>> data augmentation means do uh it's
 

1955
00:44:41,119 --> 00:44:43,190
>> data augmentation means do uh it's
problem specific, right? So an

1956
00:44:43,190 --> 00:44:43,200
problem specific, right? So an
 

1957
00:44:43,200 --> 00:44:45,349
problem specific, right? So an
augmentation for image could be like

1958
00:44:45,349 --> 00:44:45,359
augmentation for image could be like
 

1959
00:44:45,359 --> 00:44:46,790
augmentation for image could be like
adding noise, changing the colors,

1960
00:44:46,790 --> 00:44:46,800
adding noise, changing the colors,
 

1961
00:44:46,800 --> 00:44:48,230
adding noise, changing the colors,
contrasting it, rotating a little bit,

1962
00:44:48,230 --> 00:44:48,240
contrasting it, rotating a little bit,
 

1963
00:44:48,240 --> 00:44:50,069
contrasting it, rotating a little bit,
translating a little bit, shearing it,

1964
00:44:50,069 --> 00:44:50,079
translating a little bit, shearing it,
 

1965
00:44:50,079 --> 00:44:51,670
translating a little bit, shearing it,
you know, cropping out little sections,

1966
00:44:51,670 --> 00:44:51,680
you know, cropping out little sections,
 

1967
00:44:51,680 --> 00:44:53,109
you know, cropping out little sections,
stuff like this,

1968
00:44:53,109 --> 00:44:53,119
stuff like this,
 

1969
00:44:53,119 --> 00:44:55,430
stuff like this,
>> right? All of that stuff that you expect

1970
00:44:55,430 --> 00:44:55,440
>> right? All of that stuff that you expect
 

1971
00:44:55,440 --> 00:44:57,109
>> right? All of that stuff that you expect
should be not changing the basic

1972
00:44:57,109 --> 00:44:57,119
should be not changing the basic
 

1973
00:44:57,119 --> 00:45:00,630
should be not changing the basic
character of the image.

1974
00:45:00,630 --> 00:45:00,640
character of the image.
 

1975
00:45:00,640 --> 00:45:03,109
character of the image.
Okay.

1976
00:45:03,109 --> 00:45:03,119
Okay.
 

1977
00:45:03,119 --> 00:45:05,670
Okay.
Okay. So I will stop here and hand it

1978
00:45:05,670 --> 00:45:05,680
Okay. So I will stop here and hand it
 

1979
00:45:05,680 --> 00:45:09,349
Okay. So I will stop here and hand it
over uh to the and this is the end of

1980
00:45:09,349 --> 00:45:09,359
over uh to the and this is the end of
 

1981
00:45:09,359 --> 00:45:10,950
over uh to the and this is the end of
self-supervision by itself. And now

1982
00:45:10,950 --> 00:45:10,960
self-supervision by itself. And now
 

1983
00:45:10,960 --> 00:45:13,510
self-supervision by itself. And now
we're going to go back to the question

1984
00:45:13,510 --> 00:45:13,520
we're going to go back to the question
 

1985
00:45:13,520 --> 00:45:15,349
we're going to go back to the question
that was raised earlier of you have

1986
00:45:15,349 --> 00:45:15,359
that was raised earlier of you have
 

1987
00:45:15,359 --> 00:45:17,109
that was raised earlier of you have
these state space models, you have this

1988
00:45:17,109 --> 00:45:17,119
these state space models, you have this
 

1989
00:45:17,119 --> 00:45:19,349
these state space models, you have this
problem with nonlinearity. What can you

1990
00:45:19,349 --> 00:45:19,359
problem with nonlinearity. What can you
 

1991
00:45:19,359 --> 00:45:58,630
problem with nonlinearity. What can you
do

1992
00:45:58,630 --> 00:45:58,640

 

1993
00:45:58,640 --> 00:46:01,430

Okay, good. So, I have about half an

1994
00:46:01,430 --> 00:46:01,440
Okay, good. So, I have about half an
 

1995
00:46:01,440 --> 00:46:07,270
Okay, good. So, I have about half an
hour.

1996
00:46:07,270 --> 00:46:07,280

 

1997
00:46:07,280 --> 00:46:09,270

Okay.

1998
00:46:09,270 --> 00:46:09,280
Okay.
 

1999
00:46:09,280 --> 00:46:11,030
Okay.
So

2000
00:46:11,030 --> 00:46:11,040
So
 

2001
00:46:11,040 --> 00:46:13,910
So
coming back to now you we've talked

2002
00:46:13,910 --> 00:46:13,920
coming back to now you we've talked
 

2003
00:46:13,920 --> 00:46:16,950
coming back to now you we've talked
about RNN's and what I'm going to try to

2004
00:46:16,950 --> 00:46:16,960
about RNN's and what I'm going to try to
 

2005
00:46:16,960 --> 00:46:19,510
about RNN's and what I'm going to try to
set up in this lecture and the ne next

2006
00:46:19,510 --> 00:46:19,520
set up in this lecture and the ne next
 

2007
00:46:19,520 --> 00:46:22,390
set up in this lecture and the ne next
lecture is essentially the modern

2008
00:46:22,390 --> 00:46:22,400
lecture is essentially the modern
 

2009
00:46:22,400 --> 00:46:25,349
lecture is essentially the modern
counterpart to RNN's and talk about how

2010
00:46:25,349 --> 00:46:25,359
counterpart to RNN's and talk about how
 

2011
00:46:25,359 --> 00:46:28,470
counterpart to RNN's and talk about how
we get around the key bottleneck that

2012
00:46:28,470 --> 00:46:28,480
we get around the key bottleneck that
 

2013
00:46:28,480 --> 00:46:31,430
we get around the key bottleneck that
RNN's have presented to us which is the

2014
00:46:31,430 --> 00:46:31,440
RNN's have presented to us which is the
 

2015
00:46:31,440 --> 00:46:32,950
RNN's have presented to us which is the
fact that when we have these

2016
00:46:32,950 --> 00:46:32,960
fact that when we have these
 

2017
00:46:32,960 --> 00:46:35,910
fact that when we have these
nonlinearities in RNN's they become

2018
00:46:35,910 --> 00:46:35,920
nonlinearities in RNN's they become
 

2019
00:46:35,920 --> 00:46:38,470
nonlinearities in RNN's they become
difficult to train right everyone

2020
00:46:38,470 --> 00:46:38,480
difficult to train right everyone
 

2021
00:46:38,480 --> 00:46:41,349
difficult to train right everyone
remember that we're we're with like what

2022
00:46:41,349 --> 00:46:41,359
remember that we're we're with like what
 

2023
00:46:41,359 --> 00:46:45,030
remember that we're we're with like what
our agenda is is somewhat clear. So what

2024
00:46:45,030 --> 00:46:45,040
our agenda is is somewhat clear. So what
 

2025
00:46:45,040 --> 00:46:46,550
our agenda is is somewhat clear. So what
is the problem with these traditional

2026
00:46:46,550 --> 00:46:46,560
is the problem with these traditional
 

2027
00:46:46,560 --> 00:46:49,589
is the problem with these traditional
RNNs? Well, basically what happened is

2028
00:46:49,589 --> 00:46:49,599
RNNs? Well, basically what happened is
 

2029
00:46:49,599 --> 00:46:51,510
RNNs? Well, basically what happened is
that when you're doing back like you're

2030
00:46:51,510 --> 00:46:51,520
that when you're doing back like you're
 

2031
00:46:51,520 --> 00:46:52,790
that when you're doing back like you're
unrolling this thing and you have this

2032
00:46:52,790 --> 00:46:52,800
unrolling this thing and you have this
 

2033
00:46:52,800 --> 00:46:55,190
unrolling this thing and you have this
nonlinearity showing up every time in

2034
00:46:55,190 --> 00:46:55,200
nonlinearity showing up every time in
 

2035
00:46:55,200 --> 00:46:57,190
nonlinearity showing up every time in
your computation graph and so you have

2036
00:46:57,190 --> 00:46:57,200
your computation graph and so you have
 

2037
00:46:57,200 --> 00:46:59,589
your computation graph and so you have
all these sequential paths that you have

2038
00:46:59,589 --> 00:46:59,599
all these sequential paths that you have
 

2039
00:46:59,599 --> 00:47:01,430
all these sequential paths that you have
to do your forward and backward pass

2040
00:47:01,430 --> 00:47:01,440
to do your forward and backward pass
 

2041
00:47:01,440 --> 00:47:03,990
to do your forward and backward pass
through and this made things very

2042
00:47:03,990 --> 00:47:04,000
through and this made things very
 

2043
00:47:04,000 --> 00:47:07,589
through and this made things very
difficult to train.

2044
00:47:07,589 --> 00:47:07,599
difficult to train.
 

2045
00:47:07,599 --> 00:47:09,670
difficult to train.
What is the key idea? We see that okay,

2046
00:47:09,670 --> 00:47:09,680
What is the key idea? We see that okay,
 

2047
00:47:09,680 --> 00:47:12,630
What is the key idea? We see that okay,
we don't like the nonlinearity because

2048
00:47:12,630 --> 00:47:12,640
we don't like the nonlinearity because
 

2049
00:47:12,640 --> 00:47:14,550
we don't like the nonlinearity because
that is creating all of these paths. We

2050
00:47:14,550 --> 00:47:14,560
that is creating all of these paths. We
 

2051
00:47:14,560 --> 00:47:17,190
that is creating all of these paths. We
cannot parallelize this, right? What we

2052
00:47:17,190 --> 00:47:17,200
cannot parallelize this, right? What we
 

2053
00:47:17,200 --> 00:47:18,390
cannot parallelize this, right? What we
want to be able to do is we want to be

2054
00:47:18,390 --> 00:47:18,400
want to be able to do is we want to be
 

2055
00:47:18,400 --> 00:47:20,790
want to be able to do is we want to be
able to do something that will allow us

2056
00:47:20,790 --> 00:47:20,800
able to do something that will allow us
 

2057
00:47:20,800 --> 00:47:23,349
able to do something that will allow us
to parallelize.

2058
00:47:23,349 --> 00:47:23,359
to parallelize.
 

2059
00:47:23,359 --> 00:47:26,950
to parallelize.
The kind of brilliant but

2060
00:47:26,950 --> 00:47:26,960
The kind of brilliant but
 

2061
00:47:26,960 --> 00:47:28,790
The kind of brilliant but
uh surprising idea is that well, you

2062
00:47:28,790 --> 00:47:28,800
uh surprising idea is that well, you
 

2063
00:47:28,800 --> 00:47:30,870
uh surprising idea is that well, you
don't like the nonlinearity.

2064
00:47:30,870 --> 00:47:30,880
don't like the nonlinearity.
 

2065
00:47:30,880 --> 00:47:33,670
don't like the nonlinearity.
What state space models did was said,

2066
00:47:33,670 --> 00:47:33,680
What state space models did was said,
 

2067
00:47:33,680 --> 00:47:36,870
What state space models did was said,
let's just get rid of it, right? We like

2068
00:47:36,870 --> 00:47:36,880
let's just get rid of it, right? We like
 

2069
00:47:36,880 --> 00:47:39,030
let's just get rid of it, right? We like
linear things. Let's just make things

2070
00:47:39,030 --> 00:47:39,040
linear things. Let's just make things
 

2071
00:47:39,040 --> 00:47:43,109
linear things. Let's just make things
linear. That's the key highlevel idea

2072
00:47:43,109 --> 00:47:43,119
linear. That's the key highlevel idea
 

2073
00:47:43,119 --> 00:47:45,829
linear. That's the key highlevel idea
that we are going to explore. Of course,

2074
00:47:45,829 --> 00:47:45,839
that we are going to explore. Of course,
 

2075
00:47:45,839 --> 00:47:48,309
that we are going to explore. Of course,
this idea is, you know, in some sense

2076
00:47:48,309 --> 00:47:48,319
this idea is, you know, in some sense
 

2077
00:47:48,319 --> 00:47:52,069
this idea is, you know, in some sense
simple, but to actually get it to work

2078
00:47:52,069 --> 00:47:52,079
simple, but to actually get it to work
 

2079
00:47:52,079 --> 00:47:54,069
simple, but to actually get it to work
involves quite a bit of complexity and

2080
00:47:54,069 --> 00:47:54,079
involves quite a bit of complexity and
 

2081
00:47:54,079 --> 00:47:56,470
involves quite a bit of complexity and
that's what I'm going to try and

2082
00:47:56,470 --> 00:47:56,480
that's what I'm going to try and
 

2083
00:47:56,480 --> 00:47:58,950
that's what I'm going to try and
disentangle and talk through in the rest

2084
00:47:58,950 --> 00:47:58,960
disentangle and talk through in the rest
 

2085
00:47:58,960 --> 00:48:00,790
disentangle and talk through in the rest
of the lecture and then uh tomorrow's

2086
00:48:00,790 --> 00:48:00,800
of the lecture and then uh tomorrow's
 

2087
00:48:00,800 --> 00:48:02,390
of the lecture and then uh tomorrow's
lecture.

2088
00:48:02,390 --> 00:48:02,400
lecture.
 

2089
00:48:02,400 --> 00:48:06,309
lecture.
Okay. So this is our picture of an RNN

2090
00:48:06,309 --> 00:48:06,319
Okay. So this is our picture of an RNN
 

2091
00:48:06,319 --> 00:48:09,030
Okay. So this is our picture of an RNN
and here we have these horizontal

2092
00:48:09,030 --> 00:48:09,040
and here we have these horizontal
 

2093
00:48:09,040 --> 00:48:10,630
and here we have these horizontal
nonlinearities right in each of these

2094
00:48:10,630 --> 00:48:10,640
nonlinearities right in each of these
 

2095
00:48:10,640 --> 00:48:12,470
nonlinearities right in each of these
blocks there's stuff happening but one

2096
00:48:12,470 --> 00:48:12,480
blocks there's stuff happening but one
 

2097
00:48:12,480 --> 00:48:14,630
blocks there's stuff happening but one
of the key stuff things that's happening

2098
00:48:14,630 --> 00:48:14,640
of the key stuff things that's happening
 

2099
00:48:14,640 --> 00:48:17,190
of the key stuff things that's happening
is that there is this uh nonlinearity in

2100
00:48:17,190 --> 00:48:17,200
is that there is this uh nonlinearity in
 

2101
00:48:17,200 --> 00:48:20,790
is that there is this uh nonlinearity in
each of these blocks okay

2102
00:48:20,790 --> 00:48:20,800
each of these blocks okay
 

2103
00:48:20,800 --> 00:48:23,510
each of these blocks okay
so what these so uh state space models

2104
00:48:23,510 --> 00:48:23,520
so what these so uh state space models
 

2105
00:48:23,520 --> 00:48:26,790
so what these so uh state space models
said was okay in this traditional

2106
00:48:26,790 --> 00:48:26,800
said was okay in this traditional
 

2107
00:48:26,800 --> 00:48:29,349
said was okay in this traditional
uh RNN we have something like this you

2108
00:48:29,349 --> 00:48:29,359
uh RNN we have something like this you
 

2109
00:48:29,359 --> 00:48:31,990
uh RNN we have something like this you
have a hidden state

2110
00:48:31,990 --> 00:48:32,000
have a hidden state
 

2111
00:48:32,000 --> 00:48:35,190
have a hidden state
ht +1 one and it is some nonlinear

2112
00:48:35,190 --> 00:48:35,200
ht +1 one and it is some nonlinear
 

2113
00:48:35,200 --> 00:48:37,349
ht +1 one and it is some nonlinear
function of maybe your weights times

2114
00:48:37,349 --> 00:48:37,359
function of maybe your weights times
 

2115
00:48:37,359 --> 00:48:40,309
function of maybe your weights times
your previous state maybe you have some

2116
00:48:40,309 --> 00:48:40,319
your previous state maybe you have some
 

2117
00:48:40,319 --> 00:48:42,950
your previous state maybe you have some
dependence on input so on and so forth

2118
00:48:42,950 --> 00:48:42,960
dependence on input so on and so forth
 

2119
00:48:42,960 --> 00:48:45,430
dependence on input so on and so forth
there's a bias term what we're going to

2120
00:48:45,430 --> 00:48:45,440
there's a bias term what we're going to
 

2121
00:48:45,440 --> 00:48:47,030
there's a bias term what we're going to
think about is let's just get rid of

2122
00:48:47,030 --> 00:48:47,040
think about is let's just get rid of
 

2123
00:48:47,040 --> 00:48:49,109
think about is let's just get rid of
this entirely

2124
00:48:49,109 --> 00:48:49,119
this entirely
 

2125
00:48:49,119 --> 00:48:53,270
this entirely
and let's think of a model that is of

2126
00:48:53,270 --> 00:48:53,280
and let's think of a model that is of
 

2127
00:48:53,280 --> 00:48:57,349
and let's think of a model that is of
this form okay

2128
00:48:57,349 --> 00:48:57,359
this form okay
 

2129
00:48:57,359 --> 00:49:00,630
this form okay
and so for those of you who have taken a

2130
00:49:00,630 --> 00:49:00,640
and so for those of you who have taken a
 

2131
00:49:00,640 --> 00:49:02,630
and so for those of you who have taken a
control theory or any kind kind of

2132
00:49:02,630 --> 00:49:02,640
control theory or any kind kind of
 

2133
00:49:02,640 --> 00:49:05,349
control theory or any kind kind of
systems class, any linear systems class,

2134
00:49:05,349 --> 00:49:05,359
systems class, any linear systems class,
 

2135
00:49:05,359 --> 00:49:08,230
systems class, any linear systems class,
you've seen this kind of stuff over and

2136
00:49:08,230 --> 00:49:08,240
you've seen this kind of stuff over and
 

2137
00:49:08,240 --> 00:49:11,109
you've seen this kind of stuff over and
over and over again, right? Ax plus BU,

2138
00:49:11,109 --> 00:49:11,119
over and over again, right? Ax plus BU,
 

2139
00:49:11,119 --> 00:49:13,030
over and over again, right? Ax plus BU,
if you if you've done it in control,

2140
00:49:13,030 --> 00:49:13,040
if you if you've done it in control,
 

2141
00:49:13,040 --> 00:49:14,950
if you if you've done it in control,
you're used to seeing this this is X and

2142
00:49:14,950 --> 00:49:14,960
you're used to seeing this this is X and
 

2143
00:49:14,960 --> 00:49:16,790
you're used to seeing this this is X and
you're so used to seeing this is you,

2144
00:49:16,790 --> 00:49:16,800
you're so used to seeing this is you,
 

2145
00:49:16,800 --> 00:49:21,349
you're so used to seeing this is you,
right? Um that's and and so here this

2146
00:49:21,349 --> 00:49:21,359
right? Um that's and and so here this
 

2147
00:49:21,359 --> 00:49:24,069
right? Um that's and and so here this
thing is called the state because that

2148
00:49:24,069 --> 00:49:24,079
thing is called the state because that
 

2149
00:49:24,079 --> 00:49:26,390
thing is called the state because that
is what is capturing all of your time

2150
00:49:26,390 --> 00:49:26,400
is what is capturing all of your time
 

2151
00:49:26,400 --> 00:49:28,630
is what is capturing all of your time
dependence all of your history and every

2152
00:49:28,630 --> 00:49:28,640
dependence all of your history and every
 

2153
00:49:28,640 --> 00:49:30,630
dependence all of your history and every
time that is what is being updated that

2154
00:49:30,630 --> 00:49:30,640
time that is what is being updated that
 

2155
00:49:30,640 --> 00:49:32,230
time that is what is being updated that
is where your that is where your memory

2156
00:49:32,230 --> 00:49:32,240
is where your that is where your memory
 

2157
00:49:32,240 --> 00:49:35,750
is where your that is where your memory
is. So in talking about these models I'm

2158
00:49:35,750 --> 00:49:35,760
is. So in talking about these models I'm
 

2159
00:49:35,760 --> 00:49:37,670
is. So in talking about these models I'm
basically going to be following a series

2160
00:49:37,670 --> 00:49:37,680
basically going to be following a series
 

2161
00:49:37,680 --> 00:49:41,030
basically going to be following a series
of papers that have come out in the past

2162
00:49:41,030 --> 00:49:41,040
of papers that have come out in the past
 

2163
00:49:41,040 --> 00:49:43,109
of papers that have come out in the past
couple of years. None of this material

2164
00:49:43,109 --> 00:49:43,119
couple of years. None of this material
 

2165
00:49:43,119 --> 00:49:45,910
couple of years. None of this material
is really in the in the prince textbook.

2166
00:49:45,910 --> 00:49:45,920
is really in the in the prince textbook.
 

2167
00:49:45,920 --> 00:49:49,270
is really in the in the prince textbook.
So take lots of notes.

2168
00:49:49,270 --> 00:49:49,280
So take lots of notes.
 

2169
00:49:49,280 --> 00:49:53,430
So take lots of notes.
Um and I will do my best to communicate

2170
00:49:53,430 --> 00:49:53,440
Um and I will do my best to communicate
 

2171
00:49:53,440 --> 00:49:57,030
Um and I will do my best to communicate
it nicely and cleanly. Um the material

2172
00:49:57,030 --> 00:49:57,040
it nicely and cleanly. Um the material
 

2173
00:49:57,040 --> 00:49:59,109
it nicely and cleanly. Um the material
is being drawn from a series of papers.

2174
00:49:59,109 --> 00:49:59,119
is being drawn from a series of papers.
 

2175
00:49:59,119 --> 00:50:01,589
is being drawn from a series of papers.
A large number of them are coming out of

2176
00:50:01,589 --> 00:50:01,599
A large number of them are coming out of
 

2177
00:50:01,599 --> 00:50:04,470
A large number of them are coming out of
uh Chris Ray's lab at Stanford as well

2178
00:50:04,470 --> 00:50:04,480
uh Chris Ray's lab at Stanford as well
 

2179
00:50:04,480 --> 00:50:07,670
uh Chris Ray's lab at Stanford as well
as the Mamba work which is coming out of

2180
00:50:07,670 --> 00:50:07,680
as the Mamba work which is coming out of
 

2181
00:50:07,680 --> 00:50:11,990
as the Mamba work which is coming out of
I think Princeton or CMU. Um and I think

2182
00:50:11,990 --> 00:50:12,000
I think Princeton or CMU. Um and I think
 

2183
00:50:12,000 --> 00:50:14,950
I think Princeton or CMU. Um and I think
that the that the the authors of those

2184
00:50:14,950 --> 00:50:14,960
that the that the the authors of those
 

2185
00:50:14,960 --> 00:50:18,630
that the that the the authors of those
used to be at st at at Stanford right so

2186
00:50:18,630 --> 00:50:18,640
used to be at st at at Stanford right so
 

2187
00:50:18,640 --> 00:50:20,950
used to be at st at at Stanford right so
there's basically this one uh group that

2188
00:50:20,950 --> 00:50:20,960
there's basically this one uh group that
 

2189
00:50:20,960 --> 00:50:22,470
there's basically this one uh group that
has been doing a lot of work and then

2190
00:50:22,470 --> 00:50:22,480
has been doing a lot of work and then
 

2191
00:50:22,480 --> 00:50:25,990
has been doing a lot of work and then
now recently there is a uh new work out

2192
00:50:25,990 --> 00:50:26,000
now recently there is a uh new work out
 

2193
00:50:26,000 --> 00:50:29,270
now recently there is a uh new work out
of MIT called Deltanets that is kind of

2194
00:50:29,270 --> 00:50:29,280
of MIT called Deltanets that is kind of
 

2195
00:50:29,280 --> 00:50:31,589
of MIT called Deltanets that is kind of
further building this state space uh

2196
00:50:31,589 --> 00:50:31,599
further building this state space uh
 

2197
00:50:31,599 --> 00:50:34,950
further building this state space uh
perspective out. So why do we care about

2198
00:50:34,950 --> 00:50:34,960
perspective out. So why do we care about
 

2199
00:50:34,960 --> 00:50:36,150
perspective out. So why do we care about
understanding the state space

2200
00:50:36,150 --> 00:50:36,160
understanding the state space
 

2201
00:50:36,160 --> 00:50:37,510
understanding the state space
perspective? Maybe I'll motivate that

2202
00:50:37,510 --> 00:50:37,520
perspective? Maybe I'll motivate that
 

2203
00:50:37,520 --> 00:50:42,710
perspective? Maybe I'll motivate that
just a minute before I even go into um

2204
00:50:42,710 --> 00:50:42,720
just a minute before I even go into um
 

2205
00:50:42,720 --> 00:50:45,190
just a minute before I even go into um
yeah maybe let me show you this picture

2206
00:50:45,190 --> 00:50:45,200
yeah maybe let me show you this picture
 

2207
00:50:45,200 --> 00:50:46,950
yeah maybe let me show you this picture
uh before I go into talking more about

2208
00:50:46,950 --> 00:50:46,960
uh before I go into talking more about
 

2209
00:50:46,960 --> 00:50:51,670
uh before I go into talking more about
it. So this is uh the architecture for

2210
00:50:51,670 --> 00:50:51,680
it. So this is uh the architecture for
 

2211
00:50:51,680 --> 00:50:54,630
it. So this is uh the architecture for
the latest Quen model. So the leading

2212
00:50:54,630 --> 00:50:54,640
the latest Quen model. So the leading
 

2213
00:50:54,640 --> 00:50:56,870
the latest Quen model. So the leading
essentially open- source model and I'm

2214
00:50:56,870 --> 00:50:56,880
essentially open- source model and I'm
 

2215
00:50:56,880 --> 00:50:58,870
essentially open- source model and I'm
not going to there's a lot more stuff

2216
00:50:58,870 --> 00:50:58,880
not going to there's a lot more stuff
 

2217
00:50:58,880 --> 00:51:00,870
not going to there's a lot more stuff
here. We're not going to go into all of

2218
00:51:00,870 --> 00:51:00,880
here. We're not going to go into all of
 

2219
00:51:00,880 --> 00:51:03,109
here. We're not going to go into all of
this. But what I want to draw your

2220
00:51:03,109 --> 00:51:03,119
this. But what I want to draw your
 

2221
00:51:03,119 --> 00:51:07,910
this. But what I want to draw your
attention to here is

2222
00:51:07,910 --> 00:51:07,920
attention to here is
 

2223
00:51:07,920 --> 00:51:09,510
attention to here is
this

2224
00:51:09,510 --> 00:51:09,520
this
 

2225
00:51:09,520 --> 00:51:13,030
this
delta net. Okay,

2226
00:51:13,030 --> 00:51:13,040
delta net. Okay,
 

2227
00:51:13,040 --> 00:51:16,470
delta net. Okay,
this delta net is basically a so there

2228
00:51:16,470 --> 00:51:16,480
this delta net is basically a so there
 

2229
00:51:16,480 --> 00:51:18,950
this delta net is basically a so there
was this S4 state space model. Then was

2230
00:51:18,950 --> 00:51:18,960
was this S4 state space model. Then was
 

2231
00:51:18,960 --> 00:51:21,990
was this S4 state space model. Then was
there was S4 diagonal then that led to

2232
00:51:21,990 --> 00:51:22,000
there was S4 diagonal then that led to
 

2233
00:51:22,000 --> 00:51:25,510
there was S4 diagonal then that led to
Mamba and an evolution of then there was

2234
00:51:25,510 --> 00:51:25,520
Mamba and an evolution of then there was
 

2235
00:51:25,520 --> 00:51:28,309
Mamba and an evolution of then there was
Mamba 2 and then building on that there

2236
00:51:28,309 --> 00:51:28,319
Mamba 2 and then building on that there
 

2237
00:51:28,319 --> 00:51:31,270
Mamba 2 and then building on that there
was this Delta which is currently

2238
00:51:31,270 --> 00:51:31,280
was this Delta which is currently
 

2239
00:51:31,280 --> 00:51:32,870
was this Delta which is currently
considered one of the leading state

2240
00:51:32,870 --> 00:51:32,880
considered one of the leading state
 

2241
00:51:32,880 --> 00:51:34,630
considered one of the leading state
space models.

2242
00:51:34,630 --> 00:51:34,640
space models.
 

2243
00:51:34,640 --> 00:51:37,030
space models.
This is now incorporated

2244
00:51:37,030 --> 00:51:37,040
This is now incorporated
 

2245
00:51:37,040 --> 00:51:40,309
This is now incorporated
into this you know leading Quen model.

2246
00:51:40,309 --> 00:51:40,319
into this you know leading Quen model.
 

2247
00:51:40,319 --> 00:51:43,990
into this you know leading Quen model.
Okay. So it used to be that transformers

2248
00:51:43,990 --> 00:51:44,000
Okay. So it used to be that transformers
 

2249
00:51:44,000 --> 00:51:46,150
Okay. So it used to be that transformers
were you know like people thought that

2250
00:51:46,150 --> 00:51:46,160
were you know like people thought that
 

2251
00:51:46,160 --> 00:51:48,630
were you know like people thought that
okay it was going to be all attention

2252
00:51:48,630 --> 00:51:48,640
okay it was going to be all attention
 

2253
00:51:48,640 --> 00:51:50,710
okay it was going to be all attention
but it turns out that the many

2254
00:51:50,710 --> 00:51:50,720
but it turns out that the many
 

2255
00:51:50,720 --> 00:51:52,870
but it turns out that the many
advantages of state space models and the

2256
00:51:52,870 --> 00:51:52,880
advantages of state space models and the
 

2257
00:51:52,880 --> 00:51:56,230
advantages of state space models and the
fact that at inference time uh these can

2258
00:51:56,230 --> 00:51:56,240
fact that at inference time uh these can
 

2259
00:51:56,240 --> 00:51:59,589
fact that at inference time uh these can
be done quite uh computationally

2260
00:51:59,589 --> 00:51:59,599
be done quite uh computationally
 

2261
00:51:59,599 --> 00:52:02,069
be done quite uh computationally
efficiently makes it very attractive to

2262
00:52:02,069 --> 00:52:02,079
efficiently makes it very attractive to
 

2263
00:52:02,079 --> 00:52:05,190
efficiently makes it very attractive to
have aspects of your model or parts of

2264
00:52:05,190 --> 00:52:05,200
have aspects of your model or parts of
 

2265
00:52:05,200 --> 00:52:07,670
have aspects of your model or parts of
your model incorporate state space type

2266
00:52:07,670 --> 00:52:07,680
your model incorporate state space type
 

2267
00:52:07,680 --> 00:52:09,829
your model incorporate state space type
architectures. So I'm showing this just

2268
00:52:09,829 --> 00:52:09,839
architectures. So I'm showing this just
 

2269
00:52:09,839 --> 00:52:12,069
architectures. So I'm showing this just
as an example to say like we're not

2270
00:52:12,069 --> 00:52:12,079
as an example to say like we're not
 

2271
00:52:12,079 --> 00:52:14,549
as an example to say like we're not
teaching you some esoterica uh thing

2272
00:52:14,549 --> 00:52:14,559
teaching you some esoterica uh thing
 

2273
00:52:14,559 --> 00:52:16,230
teaching you some esoterica uh thing
just because I happen to like control

2274
00:52:16,230 --> 00:52:16,240
just because I happen to like control
 

2275
00:52:16,240 --> 00:52:19,109
just because I happen to like control
theory but it actually matters. Um

2276
00:52:19,109 --> 00:52:19,119
theory but it actually matters. Um
 

2277
00:52:19,119 --> 00:52:21,750
theory but it actually matters. Um
similarly here is a picture of the the

2278
00:52:21,750 --> 00:52:21,760
similarly here is a picture of the the
 

2279
00:52:21,760 --> 00:52:24,950
similarly here is a picture of the the
granite architecture from IBM and again

2280
00:52:24,950 --> 00:52:24,960
granite architecture from IBM and again
 

2281
00:52:24,960 --> 00:52:29,270
granite architecture from IBM and again
you see here some of these um

2282
00:52:29,270 --> 00:52:29,280
you see here some of these um
 

2283
00:52:29,280 --> 00:52:30,870
you see here some of these um
mamba blocks. So you see it's a hybrid

2284
00:52:30,870 --> 00:52:30,880
mamba blocks. So you see it's a hybrid
 

2285
00:52:30,880 --> 00:52:32,150
mamba blocks. So you see it's a hybrid
architecture, right? They have attention

2286
00:52:32,150 --> 00:52:32,160
architecture, right? They have attention
 

2287
00:52:32,160 --> 00:52:35,510
architecture, right? They have attention
blocks but they also have uh the state

2288
00:52:35,510 --> 00:52:35,520
blocks but they also have uh the state
 

2289
00:52:35,520 --> 00:52:37,910
blocks but they also have uh the state
space blocks and they're being used for

2290
00:52:37,910 --> 00:52:37,920
space blocks and they're being used for
 

2291
00:52:37,920 --> 00:52:40,630
space blocks and they're being used for
their differential strengths. So there's

2292
00:52:40,630 --> 00:52:40,640
their differential strengths. So there's
 

2293
00:52:40,640 --> 00:52:42,870
their differential strengths. So there's
there's important reasons to basically

2294
00:52:42,870 --> 00:52:42,880
there's important reasons to basically
 

2295
00:52:42,880 --> 00:52:44,549
there's important reasons to basically
understand this. We will not I'm not

2296
00:52:44,549 --> 00:52:44,559
understand this. We will not I'm not
 

2297
00:52:44,559 --> 00:52:46,390
understand this. We will not I'm not
going to answer all the questions about

2298
00:52:46,390 --> 00:52:46,400
going to answer all the questions about
 

2299
00:52:46,400 --> 00:52:48,309
going to answer all the questions about
all of these things. We will you know by

2300
00:52:48,309 --> 00:52:48,319
all of these things. We will you know by
 

2301
00:52:48,319 --> 00:52:49,589
all of these things. We will you know by
the end of the class we'll be able to

2302
00:52:49,589 --> 00:52:49,599
the end of the class we'll be able to
 

2303
00:52:49,599 --> 00:52:51,030
the end of the class we'll be able to
understand all of the parts of these

2304
00:52:51,030 --> 00:52:51,040
understand all of the parts of these
 

2305
00:52:51,040 --> 00:52:55,829
understand all of the parts of these
pictures.

2306
00:52:55,829 --> 00:52:55,839

 

2307
00:52:55,839 --> 00:52:59,190

Okay. So with that let me now come to

2308
00:52:59,190 --> 00:52:59,200
Okay. So with that let me now come to
 

2309
00:52:59,200 --> 00:53:08,309
Okay. So with that let me now come to
what I wanted to talk about. Okay.

2310
00:53:08,309 --> 00:53:08,319

 

2311
00:53:08,319 --> 00:53:11,430

So what kind of things basically

2312
00:53:11,430 --> 00:53:11,440
So what kind of things basically
 

2313
00:53:11,440 --> 00:53:13,510
So what kind of things basically
the thing the kind of thing that we like

2314
00:53:13,510 --> 00:53:13,520
the thing the kind of thing that we like
 

2315
00:53:13,520 --> 00:53:15,910
the thing the kind of thing that we like
doing and that is nice and efficient for

2316
00:53:15,910 --> 00:53:15,920
doing and that is nice and efficient for
 

2317
00:53:15,920 --> 00:53:17,190
doing and that is nice and efficient for
training and that is nicely

2318
00:53:17,190 --> 00:53:17,200
training and that is nicely
 

2319
00:53:17,200 --> 00:53:18,790
training and that is nicely
parallelizable.

2320
00:53:18,790 --> 00:53:18,800
parallelizable.
 

2321
00:53:18,800 --> 00:53:20,549
parallelizable.
There's one operation that we know how

2322
00:53:20,549 --> 00:53:20,559
There's one operation that we know how
 

2323
00:53:20,559 --> 00:53:23,910
There's one operation that we know how
to do. And what is that operation

2324
00:53:23,910 --> 00:53:23,920
to do. And what is that operation
 

2325
00:53:23,920 --> 00:53:27,349
to do. And what is that operation
that we've like looked at so far that is

2326
00:53:27,349 --> 00:53:27,359
that we've like looked at so far that is
 

2327
00:53:27,359 --> 00:53:29,750
that we've like looked at so far that is
nice for training?

2328
00:53:29,750 --> 00:53:29,760
nice for training?
 

2329
00:53:29,760 --> 00:53:31,430
nice for training?
Matrix multiplication. Yeah, matrix

2330
00:53:31,430 --> 00:53:31,440
Matrix multiplication. Yeah, matrix
 

2331
00:53:31,440 --> 00:53:33,829
Matrix multiplication. Yeah, matrix
multiplication is nice. Specifically,

2332
00:53:33,829 --> 00:53:33,839
multiplication is nice. Specifically,
 

2333
00:53:33,839 --> 00:53:36,230
multiplication is nice. Specifically,
convolutions are particularly nice,

2334
00:53:36,230 --> 00:53:36,240
convolutions are particularly nice,
 

2335
00:53:36,240 --> 00:53:38,870
convolutions are particularly nice,
right? Convolutional convolutional

2336
00:53:38,870 --> 00:53:38,880
right? Convolutional convolutional
 

2337
00:53:38,880 --> 00:53:40,870
right? Convolutional convolutional
neural nets we know how to train. And

2338
00:53:40,870 --> 00:53:40,880
neural nets we know how to train. And
 

2339
00:53:40,880 --> 00:53:42,230
neural nets we know how to train. And
the nice thing about convolutions is

2340
00:53:42,230 --> 00:53:42,240
the nice thing about convolutions is
 

2341
00:53:42,240 --> 00:53:45,030
the nice thing about convolutions is
they're they're nicely parallelizable.

2342
00:53:45,030 --> 00:53:45,040
they're they're nicely parallelizable.
 

2343
00:53:45,040 --> 00:53:47,910
they're they're nicely parallelizable.
Okay. So, wouldn't it be great if we

2344
00:53:47,910 --> 00:53:47,920
Okay. So, wouldn't it be great if we
 

2345
00:53:47,920 --> 00:53:50,390
Okay. So, wouldn't it be great if we
could use the fact that now we have just

2346
00:53:50,390 --> 00:53:50,400
could use the fact that now we have just
 

2347
00:53:50,400 --> 00:53:53,990
could use the fact that now we have just
reduced this to a linear system in the

2348
00:53:53,990 --> 00:53:54,000
reduced this to a linear system in the
 

2349
00:53:54,000 --> 00:53:57,349
reduced this to a linear system in the
sense to be able to

2350
00:53:57,349 --> 00:53:57,359
sense to be able to
 

2351
00:53:57,359 --> 00:54:00,630
sense to be able to
use convolutions. Okay. And if we can do

2352
00:54:00,630 --> 00:54:00,640
use convolutions. Okay. And if we can do
 

2353
00:54:00,640 --> 00:54:02,950
use convolutions. Okay. And if we can do
that then maybe we will be able to

2354
00:54:02,950 --> 00:54:02,960
that then maybe we will be able to
 

2355
00:54:02,960 --> 00:54:05,510
that then maybe we will be able to
parallelize our training nicely. So,

2356
00:54:05,510 --> 00:54:05,520
parallelize our training nicely. So,
 

2357
00:54:05,520 --> 00:54:07,270
parallelize our training nicely. So,
let's think somehow we have we have

2358
00:54:07,270 --> 00:54:07,280
let's think somehow we have we have
 

2359
00:54:07,280 --> 00:54:09,030
let's think somehow we have we have
learned our system. We've learned our

2360
00:54:09,030 --> 00:54:09,040
learned our system. We've learned our
 

2361
00:54:09,040 --> 00:54:11,030
learned our system. We've learned our
our model and we have these learned

2362
00:54:11,030 --> 00:54:11,040
our model and we have these learned
 

2363
00:54:11,040 --> 00:54:15,190
our model and we have these learned
weights A, B, C, um, and D.

2364
00:54:15,190 --> 00:54:15,200
weights A, B, C, um, and D.
 

2365
00:54:15,200 --> 00:54:20,870
weights A, B, C, um, and D.
And let's say we have this

2366
00:54:20,870 --> 00:54:20,880

 

2367
00:54:20,880 --> 00:54:24,790

uh this particular system with with

2368
00:54:24,790 --> 00:54:24,800
uh this particular system with with
 

2369
00:54:24,800 --> 00:54:26,950
uh this particular system with with
fixed and learned weights. Okay, this is

2370
00:54:26,950 --> 00:54:26,960
fixed and learned weights. Okay, this is
 

2371
00:54:26,960 --> 00:54:30,390
fixed and learned weights. Okay, this is
now an LTI system. So you now know that

2372
00:54:30,390 --> 00:54:30,400
now an LTI system. So you now know that
 

2373
00:54:30,400 --> 00:54:33,270
now an LTI system. So you now know that
I can think of this basically by un

2374
00:54:33,270 --> 00:54:33,280
I can think of this basically by un
 

2375
00:54:33,280 --> 00:54:35,510
I can think of this basically by un
unrolling it, right? So if I look at H

2376
00:54:35,510 --> 00:54:35,520
unrolling it, right? So if I look at H
 

2377
00:54:35,520 --> 00:54:38,549
unrolling it, right? So if I look at H
knot, that's just B * X knot.

2378
00:54:38,549 --> 00:54:38,559
knot, that's just B * X knot.
 

2379
00:54:38,559 --> 00:54:42,150
knot, that's just B * X knot.
Then I look at H1 and that's AB X plus B

2380
00:54:42,150 --> 00:54:42,160
Then I look at H1 and that's AB X plus B
 

2381
00:54:42,160 --> 00:54:46,549
Then I look at H1 and that's AB X plus B
X1. H2 I have a^2 bx knot plus so on and

2382
00:54:46,549 --> 00:54:46,559
X1. H2 I have a^2 bx knot plus so on and
 

2383
00:54:46,559 --> 00:54:48,870
X1. H2 I have a^2 bx knot plus so on and
so forth. I can just unroll this

2384
00:54:48,870 --> 00:54:48,880
so forth. I can just unroll this
 

2385
00:54:48,880 --> 00:54:52,069
so forth. I can just unroll this
recurrence and get this these equations

2386
00:54:52,069 --> 00:54:52,079
recurrence and get this these equations
 

2387
00:54:52,079 --> 00:54:55,910
recurrence and get this these equations
out. Make sense to everyone?

2388
00:54:55,910 --> 00:54:55,920
out. Make sense to everyone?
 

2389
00:54:55,920 --> 00:54:59,829
out. Make sense to everyone?
Any questions about this?

2390
00:54:59,829 --> 00:54:59,839

 

2391
00:54:59,839 --> 00:55:02,630

No. Yeah. Okay.

2392
00:55:02,630 --> 00:55:02,640
No. Yeah. Okay.
 

2393
00:55:02,640 --> 00:55:04,710
No. Yeah. Okay.
So, I can basically write my hidden

2394
00:55:04,710 --> 00:55:04,720
So, I can basically write my hidden
 

2395
00:55:04,720 --> 00:55:08,950
So, I can basically write my hidden
state H just as a function of my

2396
00:55:08,950 --> 00:55:08,960
state H just as a function of my
 

2397
00:55:08,960 --> 00:55:10,950
state H just as a function of my
different inputs, right? I'm removing

2398
00:55:10,950 --> 00:55:10,960
different inputs, right? I'm removing
 

2399
00:55:10,960 --> 00:55:16,630
different inputs, right? I'm removing
the dependence on the different hes.

2400
00:55:16,630 --> 00:55:16,640

 

2401
00:55:16,640 --> 00:55:18,790

Everyone see that?

2402
00:55:18,790 --> 00:55:18,800
Everyone see that?
 

2403
00:55:18,800 --> 00:55:22,230
Everyone see that?
So now I can write my output y.

2404
00:55:22,230 --> 00:55:22,240
So now I can write my output y.
 

2405
00:55:22,240 --> 00:55:24,230
So now I can write my output y.
I just have to pull in this c matrix

2406
00:55:24,230 --> 00:55:24,240
I just have to pull in this c matrix
 

2407
00:55:24,240 --> 00:55:28,790
I just have to pull in this c matrix
here, right? Y is essentially c * h k

2408
00:55:28,790 --> 00:55:28,800
here, right? Y is essentially c * h k
 

2409
00:55:28,800 --> 00:55:31,510
here, right? Y is essentially c * h k
plus d * xt.

2410
00:55:31,510 --> 00:55:31,520
plus d * xt.
 

2411
00:55:31,520 --> 00:55:34,630
plus d * xt.
And so I have my output is just c a k *

2412
00:55:34,630 --> 00:55:34,640
And so I have my output is just c a k *
 

2413
00:55:34,640 --> 00:55:39,750
And so I have my output is just c a k *
b * x plus c a k minus 1 b * x1. so on

2414
00:55:39,750 --> 00:55:39,760
b * x plus c a k minus 1 b * x1. so on
 

2415
00:55:39,760 --> 00:55:41,670
b * x plus c a k minus 1 b * x1. so on
and so forth.

2416
00:55:41,670 --> 00:55:41,680
and so forth.
 

2417
00:55:41,680 --> 00:55:44,309
and so forth.
And the nice thing about this is now

2418
00:55:44,309 --> 00:55:44,319
And the nice thing about this is now
 

2419
00:55:44,319 --> 00:55:47,829
And the nice thing about this is now
this only depends on my previous inputs.

2420
00:55:47,829 --> 00:55:47,839
this only depends on my previous inputs.
 

2421
00:55:47,839 --> 00:55:51,109
this only depends on my previous inputs.
It doesn't depend at all on my hidden

2422
00:55:51,109 --> 00:55:51,119
It doesn't depend at all on my hidden
 

2423
00:55:51,119 --> 00:55:52,870
It doesn't depend at all on my hidden
states.

2424
00:55:52,870 --> 00:55:52,880
states.
 

2425
00:55:52,880 --> 00:55:56,870
states.
So to compute my output now, what do I

2426
00:55:56,870 --> 00:55:56,880
So to compute my output now, what do I
 

2427
00:55:56,880 --> 00:55:59,109
So to compute my output now, what do I
need to do?

2428
00:55:59,109 --> 00:55:59,119
need to do?
 

2429
00:55:59,119 --> 00:56:00,630
need to do?
I can do all of these different

2430
00:56:00,630 --> 00:56:00,640
I can do all of these different
 

2431
00:56:00,640 --> 00:56:03,270
I can do all of these different
operations in parallel, right? I don't

2432
00:56:03,270 --> 00:56:03,280
operations in parallel, right? I don't
 

2433
00:56:03,280 --> 00:56:06,069
operations in parallel, right? I don't
need to wait on the computation. I don't

2434
00:56:06,069 --> 00:56:06,079
need to wait on the computation. I don't
 

2435
00:56:06,079 --> 00:56:09,190
need to wait on the computation. I don't
need to wait to compute ht to then

2436
00:56:09,190 --> 00:56:09,200
need to wait to compute ht to then
 

2437
00:56:09,200 --> 00:56:11,990
need to wait to compute ht to then
compute ht plus one. I just have all of

2438
00:56:11,990 --> 00:56:12,000
compute ht plus one. I just have all of
 

2439
00:56:12,000 --> 00:56:15,109
compute ht plus one. I just have all of
my inputs. And because I know what my a,

2440
00:56:15,109 --> 00:56:15,119
my inputs. And because I know what my a,
 

2441
00:56:15,119 --> 00:56:18,390
my inputs. And because I know what my a,
b, and c are, I can just

2442
00:56:18,390 --> 00:56:18,400
b, and c are, I can just
 

2443
00:56:18,400 --> 00:56:20,950
b, and c are, I can just
compute the next hidden state. Does that

2444
00:56:20,950 --> 00:56:20,960
compute the next hidden state. Does that
 

2445
00:56:20,960 --> 00:56:23,030
compute the next hidden state. Does that
make sense to everyone? Yes. No

2446
00:56:23,030 --> 00:56:23,040
make sense to everyone? Yes. No
 

2447
00:56:23,040 --> 00:56:26,950
make sense to everyone? Yes. No
questions. I'll pause here for a minute.

2448
00:56:26,950 --> 00:56:26,960
questions. I'll pause here for a minute.
 

2449
00:56:26,960 --> 00:56:28,390
questions. I'll pause here for a minute.
Everyone with me? Thumbs up, thumbs

2450
00:56:28,390 --> 00:56:28,400
Everyone with me? Thumbs up, thumbs
 

2451
00:56:28,400 --> 00:56:30,150
Everyone with me? Thumbs up, thumbs
down.

2452
00:56:30,150 --> 00:56:30,160
down.
 

2453
00:56:30,160 --> 00:56:33,589
down.
Okay, good.

2454
00:56:33,589 --> 00:56:33,599
Okay, good.
 

2455
00:56:33,599 --> 00:56:35,589
Okay, good.
So, this is just a convolution. And this

2456
00:56:35,589 --> 00:56:35,599
So, this is just a convolution. And this
 

2457
00:56:35,599 --> 00:56:37,349
So, this is just a convolution. And this
is great, right? So this is basically

2458
00:56:37,349 --> 00:56:37,359
is great, right? So this is basically
 

2459
00:56:37,359 --> 00:56:42,309
is great, right? So this is basically
giving us a way to parallelize our

2460
00:56:42,309 --> 00:56:42,319
giving us a way to parallelize our
 

2461
00:56:42,319 --> 00:56:45,349
giving us a way to parallelize our
computation, right? So at this point

2462
00:56:45,349 --> 00:56:45,359
computation, right? So at this point
 

2463
00:56:45,359 --> 00:56:49,190
computation, right? So at this point
maybe some of you are like

2464
00:56:49,190 --> 00:56:49,200
maybe some of you are like
 

2465
00:56:49,200 --> 00:56:51,750
maybe some of you are like
a little bit suspicious or not yet.

2466
00:56:51,750 --> 00:56:51,760
a little bit suspicious or not yet.
 

2467
00:56:51,760 --> 00:56:53,270
a little bit suspicious or not yet.
You're still you're just very trusting

2468
00:56:53,270 --> 00:56:53,280
You're still you're just very trusting
 

2469
00:56:53,280 --> 00:57:06,150
You're still you're just very trusting
people. Yes. Question.

2470
00:57:06,150 --> 00:57:06,160

 

2471
00:57:06,160 --> 00:57:07,430

Exactly. Okay.

2472
00:57:07,430 --> 00:57:07,440
Exactly. Okay.
 

2473
00:57:07,440 --> 00:57:08,549
Exactly. Okay.
>> This is exactly the question I was

2474
00:57:08,549 --> 00:57:08,559
>> This is exactly the question I was
 

2475
00:57:08,559 --> 00:57:09,829
>> This is exactly the question I was
hoping someone would ask. So, thank you.

2476
00:57:09,829 --> 00:57:09,839
hoping someone would ask. So, thank you.
 

2477
00:57:09,839 --> 00:57:17,109
hoping someone would ask. So, thank you.
Okay. Do you have a followup or you want

2478
00:57:17,109 --> 00:57:17,119

 

2479
00:57:17,119 --> 00:57:19,510

>> So, um, not quite. So, okay. So, I

2480
00:57:19,510 --> 00:57:19,520
>> So, um, not quite. So, okay. So, I
 

2481
00:57:19,520 --> 00:57:21,670
>> So, um, not quite. So, okay. So, I
showed you these architectures

2482
00:57:21,670 --> 00:57:21,680
showed you these architectures
 

2483
00:57:21,680 --> 00:57:25,109
showed you these architectures
and these architectures here indeed

2484
00:57:25,109 --> 00:57:25,119
and these architectures here indeed
 

2485
00:57:25,119 --> 00:57:26,549
and these architectures here indeed
mix different kinds of things. Like

2486
00:57:26,549 --> 00:57:26,559
mix different kinds of things. Like
 

2487
00:57:26,559 --> 00:57:27,829
mix different kinds of things. Like
there's an attention layer here and

2488
00:57:27,829 --> 00:57:27,839
there's an attention layer here and
 

2489
00:57:27,839 --> 00:57:29,910
there's an attention layer here and
there's nonlinearities there.

2490
00:57:29,910 --> 00:57:29,920
there's nonlinearities there.
 

2491
00:57:29,920 --> 00:57:34,069
there's nonlinearities there.
But what you will uh see is actually for

2492
00:57:34,069 --> 00:57:34,079
But what you will uh see is actually for
 

2493
00:57:34,079 --> 00:57:36,870
But what you will uh see is actually for
example here

2494
00:57:36,870 --> 00:57:36,880
example here
 

2495
00:57:36,880 --> 00:57:39,190
example here
uh do I have a picture of this here

2496
00:57:39,190 --> 00:57:39,200
uh do I have a picture of this here
 

2497
00:57:39,200 --> 00:57:42,390
uh do I have a picture of this here
somewhere?

2498
00:57:42,390 --> 00:57:42,400

 

2499
00:57:42,400 --> 00:57:48,230

Where did it go?

2500
00:57:48,230 --> 00:57:48,240

 

2501
00:57:48,240 --> 00:57:52,069

This is an example of the the the

2502
00:57:52,069 --> 00:57:52,079
This is an example of the the the
 

2503
00:57:52,079 --> 00:57:54,630
This is an example of the the the
mamba architecture which I'm probably

2504
00:57:54,630 --> 00:57:54,640
mamba architecture which I'm probably
 

2505
00:57:54,640 --> 00:57:55,990
mamba architecture which I'm probably
not going to get enough time to go into

2506
00:57:55,990 --> 00:57:56,000
not going to get enough time to go into
 

2507
00:57:56,000 --> 00:57:58,230
not going to get enough time to go into
in detail. But the key thing is that

2508
00:57:58,230 --> 00:57:58,240
in detail. But the key thing is that
 

2509
00:57:58,240 --> 00:57:59,910
in detail. But the key thing is that
what we're going to do is we're going to

2510
00:57:59,910 --> 00:57:59,920
what we're going to do is we're going to
 

2511
00:57:59,920 --> 00:58:02,710
what we're going to do is we're going to
maintain nonlinearities on essentially

2512
00:58:02,710 --> 00:58:02,720
maintain nonlinearities on essentially
 

2513
00:58:02,720 --> 00:58:06,230
maintain nonlinearities on essentially
what is the vertical path.

2514
00:58:06,230 --> 00:58:06,240
what is the vertical path.
 

2515
00:58:06,240 --> 00:58:08,710
what is the vertical path.
The horizontal path is time. And if you

2516
00:58:08,710 --> 00:58:08,720
The horizontal path is time. And if you
 

2517
00:58:08,720 --> 00:58:11,990
The horizontal path is time. And if you
look at if you remember our RNN issue

2518
00:58:11,990 --> 00:58:12,000
look at if you remember our RNN issue
 

2519
00:58:12,000 --> 00:58:13,750
look at if you remember our RNN issue
on this horizontal path we had

2520
00:58:13,750 --> 00:58:13,760
on this horizontal path we had
 

2521
00:58:13,760 --> 00:58:16,789
on this horizontal path we had
nonlinearities and those were causing

2522
00:58:16,789 --> 00:58:16,799
nonlinearities and those were causing
 

2523
00:58:16,799 --> 00:58:19,430
nonlinearities and those were causing
problems for us in our back prop and

2524
00:58:19,430 --> 00:58:19,440
problems for us in our back prop and
 

2525
00:58:19,440 --> 00:58:22,309
problems for us in our back prop and
computation graph. But if we just have

2526
00:58:22,309 --> 00:58:22,319
computation graph. But if we just have
 

2527
00:58:22,319 --> 00:58:23,990
computation graph. But if we just have
these nonlinearities in the vertical

2528
00:58:23,990 --> 00:58:24,000
these nonlinearities in the vertical
 

2529
00:58:24,000 --> 00:58:25,990
these nonlinearities in the vertical
path,

2530
00:58:25,990 --> 00:58:26,000
path,
 

2531
00:58:26,000 --> 00:58:28,870
path,
those allow us to still parallelize

2532
00:58:28,870 --> 00:58:28,880
those allow us to still parallelize
 

2533
00:58:28,880 --> 00:58:31,270
those allow us to still parallelize
because we can just basically put an MLP

2534
00:58:31,270 --> 00:58:31,280
because we can just basically put an MLP
 

2535
00:58:31,280 --> 00:58:34,470
because we can just basically put an MLP
block after our solid state block and

2536
00:58:34,470 --> 00:58:34,480
block after our solid state block and
 

2537
00:58:34,480 --> 00:58:36,870
block after our solid state block and
that can do all kinds of nonlinear

2538
00:58:36,870 --> 00:58:36,880
that can do all kinds of nonlinear
 

2539
00:58:36,880 --> 00:58:40,470
that can do all kinds of nonlinear
things and recover our expressive power.

2540
00:58:40,470 --> 00:58:40,480
things and recover our expressive power.
 

2541
00:58:40,480 --> 00:58:43,510
things and recover our expressive power.
Okay, so we're going to have this but

2542
00:58:43,510 --> 00:58:43,520
Okay, so we're going to have this but
 

2543
00:58:43,520 --> 00:58:45,829
Okay, so we're going to have this but
we're going to capture the history and

2544
00:58:45,829 --> 00:58:45,839
we're going to capture the history and
 

2545
00:58:45,839 --> 00:58:48,950
we're going to capture the history and
the time dependence of the sequences

2546
00:58:48,950 --> 00:58:48,960
the time dependence of the sequences
 

2547
00:58:48,960 --> 00:58:52,950
the time dependence of the sequences
in this linear part.

2548
00:58:52,950 --> 00:58:52,960
in this linear part.
 

2549
00:58:52,960 --> 00:58:55,750
in this linear part.
And one of the key insights that came uh

2550
00:58:55,750 --> 00:58:55,760
And one of the key insights that came uh
 

2551
00:58:55,760 --> 00:58:57,510
And one of the key insights that came uh
this I'm not going to talk about this

2552
00:58:57,510 --> 00:58:57,520
this I'm not going to talk about this
 

2553
00:58:57,520 --> 00:58:59,430
this I'm not going to talk about this
today but there is there was this paper

2554
00:58:59,430 --> 00:58:59,440
today but there is there was this paper
 

2555
00:58:59,440 --> 00:59:01,910
today but there is there was this paper
called u hippo or hungry hungry hippo

2556
00:59:01,910 --> 00:59:01,920
called u hippo or hungry hungry hippo
 

2557
00:59:01,920 --> 00:59:05,510
called u hippo or hungry hungry hippo
which talked about a representation

2558
00:59:05,510 --> 00:59:05,520
which talked about a representation
 

2559
00:59:05,520 --> 00:59:10,150
which talked about a representation
or how you can basically uh do polomial

2560
00:59:10,150 --> 00:59:10,160
or how you can basically uh do polomial
 

2561
00:59:10,160 --> 00:59:11,829
or how you can basically uh do polomial
approximation

2562
00:59:11,829 --> 00:59:11,839
approximation
 

2563
00:59:11,839 --> 00:59:16,309
approximation
um that will help you c and and how you

2564
00:59:16,309 --> 00:59:16,319
um that will help you c and and how you
 

2565
00:59:16,319 --> 00:59:18,390
um that will help you c and and how you
can use basically uh differential

2566
00:59:18,390 --> 00:59:18,400
can use basically uh differential
 

2567
00:59:18,400 --> 00:59:20,150
can use basically uh differential
equations and discretized versions of

2568
00:59:20,150 --> 00:59:20,160
equations and discretized versions of
 

2569
00:59:20,160 --> 00:59:21,910
equations and discretized versions of
differential equations to represent many

2570
00:59:21,910 --> 00:59:21,920
differential equations to represent many
 

2571
00:59:21,920 --> 00:59:23,270
differential equations to represent many
different functions And basically saying

2572
00:59:23,270 --> 00:59:23,280
different functions And basically saying
 

2573
00:59:23,280 --> 00:59:26,950
different functions And basically saying
that actually linear functions can have

2574
00:59:26,950 --> 00:59:26,960
that actually linear functions can have
 

2575
00:59:26,960 --> 00:59:29,589
that actually linear functions can have
a lot of expressive power. And one other

2576
00:59:29,589 --> 00:59:29,599
a lot of expressive power. And one other
 

2577
00:59:29,599 --> 00:59:31,030
a lot of expressive power. And one other
way to think about is that well you know

2578
00:59:31,030 --> 00:59:31,040
way to think about is that well you know
 

2579
00:59:31,040 --> 00:59:33,349
way to think about is that well you know
like yes we we're doing neural networks

2580
00:59:33,349 --> 00:59:33,359
like yes we we're doing neural networks
 

2581
00:59:33,359 --> 00:59:34,789
like yes we we're doing neural networks
now and we're doing a lot of nonlinear

2582
00:59:34,789 --> 00:59:34,799
now and we're doing a lot of nonlinear
 

2583
00:59:34,799 --> 00:59:36,309
now and we're doing a lot of nonlinear
things but we have been doing linear

2584
00:59:36,309 --> 00:59:36,319
things but we have been doing linear
 

2585
00:59:36,319 --> 00:59:38,230
things but we have been doing linear
stuff for a long time and you can

2586
00:59:38,230 --> 00:59:38,240
stuff for a long time and you can
 

2587
00:59:38,240 --> 00:59:40,950
stuff for a long time and you can
actually capture a lot of stuff with

2588
00:59:40,950 --> 00:59:40,960
actually capture a lot of stuff with
 

2589
00:59:40,960 --> 00:59:42,870
actually capture a lot of stuff with
linear functions as well. So there's you

2590
00:59:42,870 --> 00:59:42,880
linear functions as well. So there's you
 

2591
00:59:42,880 --> 00:59:44,470
linear functions as well. So there's you
know you can think of it two ways but

2592
00:59:44,470 --> 00:59:44,480
know you can think of it two ways but
 

2593
00:59:44,480 --> 00:59:48,549
know you can think of it two ways but
this hippo paper um also brought about

2594
00:59:48,549 --> 00:59:48,559
this hippo paper um also brought about
 

2595
00:59:48,559 --> 00:59:50,309
this hippo paper um also brought about
this realization that actually looking

2596
00:59:50,309 --> 00:59:50,319
this realization that actually looking
 

2597
00:59:50,319 --> 00:59:54,950
this realization that actually looking
at a particular linear perspective can

2598
00:59:54,950 --> 00:59:54,960
at a particular linear perspective can
 

2599
00:59:54,960 --> 00:59:57,190
at a particular linear perspective can
uh can bring about a lot of expressive

2600
00:59:57,190 --> 00:59:57,200
uh can bring about a lot of expressive
 

2601
00:59:57,200 --> 00:59:58,789
uh can bring about a lot of expressive
power as well but here we're going to be

2602
00:59:58,789 --> 00:59:58,799
power as well but here we're going to be
 

2603
00:59:58,799 --> 01:00:01,750
power as well but here we're going to be
combining this with an explicit MLP in

2604
01:00:01,750 --> 01:00:01,760
combining this with an explicit MLP in
 

2605
01:00:01,760 --> 01:00:04,470
combining this with an explicit MLP in
the vertical direction. Does that answer

2606
01:00:04,470 --> 01:00:04,480
the vertical direction. Does that answer
 

2607
01:00:04,480 --> 01:00:05,910
the vertical direction. Does that answer
the question? But this is exactly what I

2608
01:00:05,910 --> 01:00:05,920
the question? But this is exactly what I
 

2609
01:00:05,920 --> 01:00:06,950
the question? But this is exactly what I
was thinking that you're probably

2610
01:00:06,950 --> 01:00:06,960
was thinking that you're probably
 

2611
01:00:06,960 --> 01:00:09,109
was thinking that you're probably
thinking. So I'm glad you uh vocalized

2612
01:00:09,109 --> 01:00:09,119
thinking. So I'm glad you uh vocalized
 

2613
01:00:09,119 --> 01:00:12,309
thinking. So I'm glad you uh vocalized
this this question. Okay. So, we have

2614
01:00:12,309 --> 01:00:12,319
this this question. Okay. So, we have
 

2615
01:00:12,319 --> 01:00:14,630
this this question. Okay. So, we have
this. So, we're we're focusing on this

2616
01:00:14,630 --> 01:00:14,640
this. So, we're we're focusing on this
 

2617
01:00:14,640 --> 01:00:16,710
this. So, we're we're focusing on this
linear thing and we're we're hoping that

2618
01:00:16,710 --> 01:00:16,720
linear thing and we're we're hoping that
 

2619
01:00:16,720 --> 01:00:18,789
linear thing and we're we're hoping that
it's going to give us uh give us what we

2620
01:00:18,789 --> 01:00:18,799
it's going to give us uh give us what we
 

2621
01:00:18,799 --> 01:00:22,950
it's going to give us uh give us what we
want. Any other questions here?

2622
01:00:22,950 --> 01:00:22,960

 

2623
01:00:22,960 --> 01:00:26,630

Okay, good.

2624
01:00:26,630 --> 01:00:26,640

 

2625
01:00:26,640 --> 01:00:32,870

So, let's um think about this. So, now

2626
01:00:32,870 --> 01:00:32,880

 

2627
01:00:32,880 --> 01:00:39,430

at position Yes, question.

2628
01:00:39,430 --> 01:00:39,440

 

2629
01:00:39,440 --> 01:00:42,390

still get paral.

2630
01:00:42,390 --> 01:00:42,400
still get paral.
 

2631
01:00:42,400 --> 01:00:44,470
still get paral.
>> No. So there they there will still be an

2632
01:00:44,470 --> 01:00:44,480
>> No. So there they there will still be an
 

2633
01:00:44,480 --> 01:00:47,670
>> No. So there they there will still be an
independence. Yes. In the sense that you

2634
01:00:47,670 --> 01:00:47,680
independence. Yes. In the sense that you
 

2635
01:00:47,680 --> 01:00:48,950
independence. Yes. In the sense that you
will you will you will train it the same

2636
01:00:48,950 --> 01:00:48,960
will you will you will train it the same
 

2637
01:00:48,960 --> 01:00:51,910
will you will you will train it the same
way you would train in an MLP.

2638
01:00:51,910 --> 01:00:51,920
way you would train in an MLP.
 

2639
01:00:51,920 --> 01:01:00,150
way you would train in an MLP.
>> Yes.

2640
01:01:00,150 --> 01:01:00,160

 

2641
01:01:00,160 --> 01:01:01,589

>> Whatever nonlinearity

2642
01:01:01,589 --> 01:01:01,599
>> Whatever nonlinearity
 

2643
01:01:01,599 --> 01:01:03,670
>> Whatever nonlinearity
>> function whatever

2644
01:01:03,670 --> 01:01:03,680
>> function whatever
 

2645
01:01:03,680 --> 01:01:08,549
>> function whatever
was acting as

2646
01:01:08,549 --> 01:01:08,559

 

2647
01:01:08,559 --> 01:01:09,990

or

2648
01:01:09,990 --> 01:01:10,000
or
 

2649
01:01:10,000 --> 01:01:11,349
or
>> okay that's that's an excellent

2650
01:01:11,349 --> 01:01:11,359
>> okay that's that's an excellent
 

2651
01:01:11,359 --> 01:01:14,549
>> okay that's that's an excellent
question. Um so in RNN's yes we choose

2652
01:01:14,549 --> 01:01:14,559
question. Um so in RNN's yes we choose
 

2653
01:01:14,559 --> 01:01:16,870
question. Um so in RNN's yes we choose
to we choose to have an a sigmoid to to

2654
01:01:16,870 --> 01:01:16,880
to we choose to have an a sigmoid to to
 

2655
01:01:16,880 --> 01:01:19,990
to we choose to have an a sigmoid to to
avoid this blowup problem. This blowup

2656
01:01:19,990 --> 01:01:20,000
avoid this blowup problem. This blowup
 

2657
01:01:20,000 --> 01:01:22,789
avoid this blowup problem. This blowup
issue is an issue that we we will come

2658
01:01:22,789 --> 01:01:22,799
issue is an issue that we we will come
 

2659
01:01:22,799 --> 01:01:24,390
issue is an issue that we we will come
to I will probably not talk about it

2660
01:01:24,390 --> 01:01:24,400
to I will probably not talk about it
 

2661
01:01:24,400 --> 01:01:25,990
to I will probably not talk about it
today but we will talk about it

2662
01:01:25,990 --> 01:01:26,000
today but we will talk about it
 

2663
01:01:26,000 --> 01:01:29,750
today but we will talk about it
tomorrow. Um and we will handle this by

2664
01:01:29,750 --> 01:01:29,760
tomorrow. Um and we will handle this by
 

2665
01:01:29,760 --> 01:01:33,829
tomorrow. Um and we will handle this by
thinking about the en values of the

2666
01:01:33,829 --> 01:01:33,839
thinking about the en values of the
 

2667
01:01:33,839 --> 01:01:35,349
thinking about the en values of the
linear systems that we're thinking

2668
01:01:35,349 --> 01:01:35,359
linear systems that we're thinking
 

2669
01:01:35,359 --> 01:01:38,390
linear systems that we're thinking
about. And so one way of what the what

2670
01:01:38,390 --> 01:01:38,400
about. And so one way of what the what
 

2671
01:01:38,400 --> 01:01:40,309
about. And so one way of what the what
in RNN's the sigmoid did was it just

2672
01:01:40,309 --> 01:01:40,319
in RNN's the sigmoid did was it just
 

2673
01:01:40,319 --> 01:01:42,069
in RNN's the sigmoid did was it just
made it squashed all the values and made

2674
01:01:42,069 --> 01:01:42,079
made it squashed all the values and made
 

2675
01:01:42,079 --> 01:01:44,950
made it squashed all the values and made
them small. But in linear systems we

2676
01:01:44,950 --> 01:01:44,960
them small. But in linear systems we
 

2677
01:01:44,960 --> 01:01:46,549
them small. But in linear systems we
know what causes blowups and we know

2678
01:01:46,549 --> 01:01:46,559
know what causes blowups and we know
 

2679
01:01:46,559 --> 01:01:48,390
know what causes blowups and we know
that IEN values are the things that

2680
01:01:48,390 --> 01:01:48,400
that IEN values are the things that
 

2681
01:01:48,400 --> 01:01:49,829
that IEN values are the things that
cause blowups. And we understand

2682
01:01:49,829 --> 01:01:49,839
cause blowups. And we understand
 

2683
01:01:49,839 --> 01:01:53,270
cause blowups. And we understand
critical damping and uh

2684
01:01:53,270 --> 01:01:53,280
critical damping and uh
 

2685
01:01:53,280 --> 01:01:55,270
critical damping and uh
exponential stability. And so we're

2686
01:01:55,270 --> 01:01:55,280
exponential stability. And so we're
 

2687
01:01:55,280 --> 01:01:59,349
exponential stability. And so we're
going to use those ideas to initialize

2688
01:01:59,349 --> 01:01:59,359
going to use those ideas to initialize
 

2689
01:01:59,359 --> 01:02:02,069
going to use those ideas to initialize
appropriately and make sure that we can

2690
01:02:02,069 --> 01:02:02,079
appropriately and make sure that we can
 

2691
01:02:02,079 --> 01:02:03,670
appropriately and make sure that we can
still get the kind of long range

2692
01:02:03,670 --> 01:02:03,680
still get the kind of long range
 

2693
01:02:03,680 --> 01:02:05,829
still get the kind of long range
dependency we want.

2694
01:02:05,829 --> 01:02:05,839
dependency we want.
 

2695
01:02:05,839 --> 01:02:07,910
dependency we want.
but make sure our systems don't explode.

2696
01:02:07,910 --> 01:02:07,920
but make sure our systems don't explode.
 

2697
01:02:07,920 --> 01:02:10,230
but make sure our systems don't explode.
But this is this is again still the

2698
01:02:10,230 --> 01:02:10,240
But this is this is again still the
 

2699
01:02:10,240 --> 01:02:12,710
But this is this is again still the
tricky part or a tricky part of state

2700
01:02:12,710 --> 01:02:12,720
tricky part or a tricky part of state
 

2701
01:02:12,720 --> 01:02:14,950
tricky part or a tricky part of state
space models.

2702
01:02:14,950 --> 01:02:14,960
space models.
 

2703
01:02:14,960 --> 01:02:33,750
space models.
Yes.

2704
01:02:33,750 --> 01:02:33,760

 

2705
01:02:33,760 --> 01:02:35,349

you so you could write you could write

2706
01:02:35,349 --> 01:02:35,359
you so you could write you could write
 

2707
01:02:35,359 --> 01:02:37,510
you so you could write you could write
an unrolled version of this but what I

2708
01:02:37,510 --> 01:02:37,520
an unrolled version of this but what I
 

2709
01:02:37,520 --> 01:02:39,190
an unrolled version of this but what I
need to do is I need to compute the

2710
01:02:39,190 --> 01:02:39,200
need to do is I need to compute the
 

2711
01:02:39,200 --> 01:02:41,030
need to do is I need to compute the
nonlinearity before I can compute the

2712
01:02:41,030 --> 01:02:41,040
nonlinearity before I can compute the
 

2713
01:02:41,040 --> 01:02:43,430
nonlinearity before I can compute the
next hidden state

2714
01:02:43,430 --> 01:02:43,440
next hidden state
 

2715
01:02:43,440 --> 01:02:45,910
next hidden state
so I need to operate the here I can do

2716
01:02:45,910 --> 01:02:45,920
so I need to operate the here I can do
 

2717
01:02:45,920 --> 01:02:50,150
so I need to operate the here I can do
all of these in one go I don't

2718
01:02:50,150 --> 01:02:50,160
all of these in one go I don't
 

2719
01:02:50,160 --> 01:02:52,549
all of these in one go I don't
like this term depends on this term and

2720
01:02:52,549 --> 01:02:52,559
like this term depends on this term and
 

2721
01:02:52,559 --> 01:02:54,069
like this term depends on this term and
this term depends on this term if I

2722
01:02:54,069 --> 01:02:54,079
this term depends on this term if I
 

2723
01:02:54,079 --> 01:02:55,829
this term depends on this term if I
unroll it with the nonlinear ity but

2724
01:02:55,829 --> 01:02:55,839
unroll it with the nonlinear ity but
 

2725
01:02:55,839 --> 01:02:58,069
unroll it with the nonlinear ity but
without the nonlinearity I can just go

2726
01:02:58,069 --> 01:02:58,079
without the nonlinearity I can just go
 

2727
01:02:58,079 --> 01:03:01,109
without the nonlinearity I can just go
and get it all as one convolution or one

2728
01:03:01,109 --> 01:03:01,119
and get it all as one convolution or one
 

2729
01:03:01,119 --> 01:03:04,950
and get it all as one convolution or one
matrix multiply

2730
01:03:04,950 --> 01:03:04,960

 

2731
01:03:04,960 --> 01:03:07,030

>> yes exactly parallelization that's the

2732
01:03:07,030 --> 01:03:07,040
>> yes exactly parallelization that's the
 

2733
01:03:07,040 --> 01:03:08,390
>> yes exactly parallelization that's the
key thing the thing is that you can

2734
01:03:08,390 --> 01:03:08,400
key thing the thing is that you can
 

2735
01:03:08,400 --> 01:03:12,789
key thing the thing is that you can
parallelize this

2736
01:03:12,789 --> 01:03:12,799

 

2737
01:03:12,799 --> 01:03:16,230

okay so this is the really nice thing

2738
01:03:16,230 --> 01:03:16,240
okay so this is the really nice thing
 

2739
01:03:16,240 --> 01:03:18,870
okay so this is the really nice thing
this is the like key or one key thing

2740
01:03:18,870 --> 01:03:18,880
this is the like key or one key thing
 

2741
01:03:18,880 --> 01:03:21,430
this is the like key or one key thing
about state space models

2742
01:03:21,430 --> 01:03:21,440
about state space models
 

2743
01:03:21,440 --> 01:03:23,190
about state space models
so the other thing that we want to

2744
01:03:23,190 --> 01:03:23,200
so the other thing that we want to
 

2745
01:03:23,200 --> 01:03:26,309
so the other thing that we want to
really uh bring out is that okay you

2746
01:03:26,309 --> 01:03:26,319
really uh bring out is that okay you
 

2747
01:03:26,319 --> 01:03:28,630
really uh bring out is that okay you
know but this is still a lot of lot of

2748
01:03:28,630 --> 01:03:28,640
know but this is still a lot of lot of
 

2749
01:03:28,640 --> 01:03:30,309
know but this is still a lot of lot of
compute right to compute these

2750
01:03:30,309 --> 01:03:30,319
compute right to compute these
 

2751
01:03:30,319 --> 01:03:32,710
compute right to compute these
especially if you're having long context

2752
01:03:32,710 --> 01:03:32,720
especially if you're having long context
 

2753
01:03:32,720 --> 01:03:35,510
especially if you're having long context
and your t is getting larger and larger

2754
01:03:35,510 --> 01:03:35,520
and your t is getting larger and larger
 

2755
01:03:35,520 --> 01:03:39,109
and your t is getting larger and larger
then you know to compute position t I

2756
01:03:39,109 --> 01:03:39,119
then you know to compute position t I
 

2757
01:03:39,119 --> 01:03:40,789
then you know to compute position t I
still have you know I have I have my

2758
01:03:40,789 --> 01:03:40,799
still have you know I have I have my
 

2759
01:03:40,799 --> 01:03:43,270
still have you know I have I have my
history I have t history now behind me

2760
01:03:43,270 --> 01:03:43,280
history I have t history now behind me
 

2761
01:03:43,280 --> 01:03:46,230
history I have t history now behind me
and the longer my history is

2762
01:03:46,230 --> 01:03:46,240
and the longer my history is
 

2763
01:03:46,240 --> 01:03:48,470
and the longer my history is
the bigger this power is right so the

2764
01:03:48,470 --> 01:03:48,480
the bigger this power is right so the
 

2765
01:03:48,480 --> 01:03:50,710
the bigger this power is right so the
more the the longer my convolutions

2766
01:03:50,710 --> 01:03:50,720
more the the longer my convolutions
 

2767
01:03:50,720 --> 01:03:53,670
more the the longer my convolutions
because this is essentially an infinite

2768
01:03:53,670 --> 01:03:53,680
because this is essentially an infinite
 

2769
01:03:53,680 --> 01:03:55,829
because this is essentially an infinite
impulse response that I that I have,

2770
01:03:55,829 --> 01:03:55,839
impulse response that I that I have,
 

2771
01:03:55,839 --> 01:03:59,190
impulse response that I that I have,
right? And so the the way that I'm going

2772
01:03:59,190 --> 01:03:59,200
right? And so the the way that I'm going
 

2773
01:03:59,200 --> 01:04:00,950
right? And so the the way that I'm going
to handle this is that I have a sequence

2774
01:04:00,950 --> 01:04:00,960
to handle this is that I have a sequence
 

2775
01:04:00,960 --> 01:04:03,109
to handle this is that I have a sequence
and it's all going to just I I'll load

2776
01:04:03,109 --> 01:04:03,119
and it's all going to just I I'll load
 

2777
01:04:03,119 --> 01:04:05,349
and it's all going to just I I'll load
the sequence that can fit into my memory

2778
01:04:05,349 --> 01:04:05,359
the sequence that can fit into my memory
 

2779
01:04:05,359 --> 01:04:07,750
the sequence that can fit into my memory
and then I will do the convolution that

2780
01:04:07,750 --> 01:04:07,760
and then I will do the convolution that
 

2781
01:04:07,760 --> 01:04:11,430
and then I will do the convolution that
I can do. Okay? So the bigger t gets,

2782
01:04:11,430 --> 01:04:11,440
I can do. Okay? So the bigger t gets,
 

2783
01:04:11,440 --> 01:04:13,270
I can do. Okay? So the bigger t gets,
the more multiplies I'm going to have to

2784
01:04:13,270 --> 01:04:13,280
the more multiplies I'm going to have to
 

2785
01:04:13,280 --> 01:04:15,750
the more multiplies I'm going to have to
do.

2786
01:04:15,750 --> 01:04:15,760
do.
 

2787
01:04:15,760 --> 01:04:17,670
do.
So

2788
01:04:17,670 --> 01:04:17,680
So
 

2789
01:04:17,680 --> 01:04:21,589
So
if this if at position t I have you know

2790
01:04:21,589 --> 01:04:21,599
if this if at position t I have you know
 

2791
01:04:21,599 --> 01:04:24,069
if this if at position t I have you know
let's say I have a maximum sequence

2792
01:04:24,069 --> 01:04:24,079
let's say I have a maximum sequence
 

2793
01:04:24,079 --> 01:04:27,510
let's say I have a maximum sequence
length of capital t okay and I have let

2794
01:04:27,510 --> 01:04:27,520
length of capital t okay and I have let
 

2795
01:04:27,520 --> 01:04:31,750
length of capital t okay and I have let
me write this out maybe

2796
01:04:31,750 --> 01:04:31,760

 

2797
01:04:31,760 --> 01:04:36,870

so I have um here

2798
01:04:36,870 --> 01:04:36,880
so I have um here
 

2799
01:04:36,880 --> 01:04:43,510
so I have um here
uh zero maybe not zero

2800
01:04:43,510 --> 01:04:43,520

 

2801
01:04:43,520 --> 01:04:49,270

I have one to t.

2802
01:04:49,270 --> 01:04:49,280
I have one to t.
 

2803
01:04:49,280 --> 01:04:51,510
I have one to t.
Okay, maybe t is the maximum context

2804
01:04:51,510 --> 01:04:51,520
Okay, maybe t is the maximum context
 

2805
01:04:51,520 --> 01:04:52,950
Okay, maybe t is the maximum context
length that I can handle. This is the

2806
01:04:52,950 --> 01:04:52,960
length that I can handle. This is the
 

2807
01:04:52,960 --> 01:04:54,549
length that I can handle. This is the
maximum number of things that I will

2808
01:04:54,549 --> 01:04:54,559
maximum number of things that I will
 

2809
01:04:54,559 --> 01:04:57,910
maximum number of things that I will
have

2810
01:04:57,910 --> 01:04:57,920

 

2811
01:04:57,920 --> 01:05:00,309

to compute

2812
01:05:00,309 --> 01:05:00,319
to compute
 

2813
01:05:00,319 --> 01:05:03,910
to compute
every position t.

2814
01:05:03,910 --> 01:05:03,920
every position t.
 

2815
01:05:03,920 --> 01:05:07,029
every position t.
I basically need order t compute, right?

2816
01:05:07,029 --> 01:05:07,039
I basically need order t compute, right?
 

2817
01:05:07,039 --> 01:05:12,390
I basically need order t compute, right?
Because there are t terms here, right?

2818
01:05:12,390 --> 01:05:12,400
Because there are t terms here, right?
 

2819
01:05:12,400 --> 01:05:15,990
Because there are t terms here, right?
So how much compute do I need

2820
01:05:15,990 --> 01:05:16,000
So how much compute do I need
 

2821
01:05:16,000 --> 01:05:23,270
So how much compute do I need
all the way up to capital T?

2822
01:05:23,270 --> 01:05:23,280

 

2823
01:05:23,280 --> 01:05:25,829

Yeah, go ahead. Or

2824
01:05:25,829 --> 01:05:25,839
Yeah, go ahead. Or
 

2825
01:05:25,839 --> 01:05:27,670
Yeah, go ahead. Or
t^ square over two essentially, right?

2826
01:05:27,670 --> 01:05:27,680
t^ square over two essentially, right?
 

2827
01:05:27,680 --> 01:05:30,230
t^ square over two essentially, right?
Um but I need order t^2 compute. And the

2828
01:05:30,230 --> 01:05:30,240
Um but I need order t^2 compute. And the
 

2829
01:05:30,240 --> 01:05:32,470
Um but I need order t^2 compute. And the
basic the the way to see that is if I

2830
01:05:32,470 --> 01:05:32,480
basic the the way to see that is if I
 

2831
01:05:32,480 --> 01:05:34,470
basic the the way to see that is if I
need one compute, two compute, three

2832
01:05:34,470 --> 01:05:34,480
need one compute, two compute, three
 

2833
01:05:34,480 --> 01:05:35,990
need one compute, two compute, three
compute, t compute, I have to add this

2834
01:05:35,990 --> 01:05:36,000
compute, t compute, I have to add this
 

2835
01:05:36,000 --> 01:05:39,750
compute, t compute, I have to add this
all up. And essentially the compute that

2836
01:05:39,750 --> 01:05:39,760
all up. And essentially the compute that
 

2837
01:05:39,760 --> 01:05:43,270
all up. And essentially the compute that
I need is a total of t^2 compute. Okay.

2838
01:05:43,270 --> 01:05:43,280
I need is a total of t^2 compute. Okay.
 

2839
01:05:43,280 --> 01:05:45,829
I need is a total of t^2 compute. Okay.
So as my context grows this is getting

2840
01:05:45,829 --> 01:05:45,839
So as my context grows this is getting
 

2841
01:05:45,839 --> 01:05:50,150
So as my context grows this is getting
larger and larger. This is not great.

2842
01:05:50,150 --> 01:05:50,160
larger and larger. This is not great.
 

2843
01:05:50,160 --> 01:05:52,069
larger and larger. This is not great.
The question is now and one of the

2844
01:05:52,069 --> 01:05:52,079
The question is now and one of the
 

2845
01:05:52,079 --> 01:05:54,710
The question is now and one of the
really nice things about these models is

2846
01:05:54,710 --> 01:05:54,720
really nice things about these models is
 

2847
01:05:54,720 --> 01:05:57,349
really nice things about these models is
can we do something better than this

2848
01:05:57,349 --> 01:05:57,359
can we do something better than this
 

2849
01:05:57,359 --> 01:06:01,270
can we do something better than this
order t^2? And this is the second key

2850
01:06:01,270 --> 01:06:01,280
order t^2? And this is the second key
 

2851
01:06:01,280 --> 01:06:04,549
order t^2? And this is the second key
insight or power that state space models

2852
01:06:04,549 --> 01:06:04,559
insight or power that state space models
 

2853
01:06:04,559 --> 01:06:07,430
insight or power that state space models
leverage. So I'm going to give you a

2854
01:06:07,430 --> 01:06:07,440
leverage. So I'm going to give you a
 

2855
01:06:07,440 --> 01:06:09,029
leverage. So I'm going to give you a
minute to think about this and think

2856
01:06:09,029 --> 01:06:09,039
minute to think about this and think
 

2857
01:06:09,039 --> 01:06:11,750
minute to think about this and think
about well what could we do to go and

2858
01:06:11,750 --> 01:06:11,760
about well what could we do to go and
 

2859
01:06:11,760 --> 01:06:14,230
about well what could we do to go and
improve beyond beyond this order t^ squ

2860
01:06:14,230 --> 01:06:14,240
improve beyond beyond this order t^ squ
 

2861
01:06:14,240 --> 01:06:16,069
improve beyond beyond this order t^ squ
compute the nice thing is what we have

2862
01:06:16,069 --> 01:06:16,079
compute the nice thing is what we have
 

2863
01:06:16,079 --> 01:06:19,109
compute the nice thing is what we have
is we can do this parallelly but tsquare

2864
01:06:19,109 --> 01:06:19,119
is we can do this parallelly but tsquare
 

2865
01:06:19,119 --> 01:06:22,470
is we can do this parallelly but tsquare
is still a lot what can we do to do

2866
01:06:22,470 --> 01:06:22,480
is still a lot what can we do to do
 

2867
01:06:22,480 --> 01:06:24,390
is still a lot what can we do to do
better so you know take a minute think

2868
01:06:24,390 --> 01:06:24,400
better so you know take a minute think
 

2869
01:06:24,400 --> 01:06:26,230
better so you know take a minute think
talk to your neighbors ask questions so

2870
01:06:26,230 --> 01:06:26,240
talk to your neighbors ask questions so
 

2871
01:06:26,240 --> 01:06:47,349
talk to your neighbors ask questions so
on and so forth I'll set a

2872
01:06:47,349 --> 01:06:47,359

 

2873
01:06:47,359 --> 01:08:20,950

All right.

2874
01:08:20,950 --> 01:08:20,960

 

2875
01:08:20,960 --> 01:08:36,950

Yes,

2876
01:08:36,950 --> 01:08:36,960

 

2877
01:08:36,960 --> 01:08:40,149

So that's my timer. Okay. So, anyone

2878
01:08:40,149 --> 01:08:40,159
So that's my timer. Okay. So, anyone
 

2879
01:08:40,159 --> 01:08:43,669
So that's my timer. Okay. So, anyone
have any ideas or suggestions on how

2880
01:08:43,669 --> 01:08:43,679
have any ideas or suggestions on how
 

2881
01:08:43,679 --> 01:08:46,470
have any ideas or suggestions on how
we could go do better than order T

2882
01:08:46,470 --> 01:08:46,480
we could go do better than order T
 

2883
01:08:46,480 --> 01:08:49,189
we could go do better than order T
square?

2884
01:08:49,189 --> 01:08:49,199
square?
 

2885
01:08:49,199 --> 01:08:51,990
square?
>> Yeah.

2886
01:08:51,990 --> 01:08:52,000
>> Yeah.
 

2887
01:08:52,000 --> 01:08:52,950
>> Yeah.
For

2888
01:08:52,950 --> 01:08:52,960
For
 

2889
01:08:52,960 --> 01:09:03,269
For
examp

2890
01:09:03,269 --> 01:09:03,279

 

2891
01:09:03,279 --> 01:09:05,349

you've only if you've saved T already

2892
01:09:05,349 --> 01:09:05,359
you've only if you've saved T already
 

2893
01:09:05,359 --> 01:09:16,709
you've only if you've saved T already
you could only

2894
01:09:16,709 --> 01:09:16,719

 

2895
01:09:16,719 --> 01:09:18,709

>> so you can save some of these powers of

2896
01:09:18,709 --> 01:09:18,719
>> so you can save some of these powers of
 

2897
01:09:18,719 --> 01:09:21,510
>> so you can save some of these powers of
A and basically improve how fast you can

2898
01:09:21,510 --> 01:09:21,520
A and basically improve how fast you can
 

2899
01:09:21,520 --> 01:09:23,030
A and basically improve how fast you can
compute that you can you can do a little

2900
01:09:23,030 --> 01:09:23,040
compute that you can you can do a little
 

2901
01:09:23,040 --> 01:09:24,470
compute that you can you can do a little
bit of improvement and we'll talk a

2902
01:09:24,470 --> 01:09:24,480
bit of improvement and we'll talk a
 

2903
01:09:24,480 --> 01:09:25,749
bit of improvement and we'll talk a
little bit about that, but that's not

2904
01:09:25,749 --> 01:09:25,759
little bit about that, but that's not
 

2905
01:09:25,759 --> 01:09:27,669
little bit about that, but that's not
going to get you a the big kind of

2906
01:09:27,669 --> 01:09:27,679
going to get you a the big kind of
 

2907
01:09:27,679 --> 01:09:29,189
going to get you a the big kind of
improvement that we're we're looking

2908
01:09:29,189 --> 01:09:29,199
improvement that we're we're looking
 

2909
01:09:29,199 --> 01:09:36,309
improvement that we're we're looking
for.

2910
01:09:36,309 --> 01:09:36,319

 

2911
01:09:36,319 --> 01:09:45,829

>> Anyone else or Yeah.

2912
01:09:45,829 --> 01:09:45,839

 

2913
01:09:45,839 --> 01:09:53,749

Get all these sizing

2914
01:09:53,749 --> 01:09:53,759

 

2915
01:09:53,759 --> 01:10:12,870

across the different

2916
01:10:12,870 --> 01:10:12,880

 

2917
01:10:12,880 --> 01:10:16,149

>> You could try things like this but um I

2918
01:10:16,149 --> 01:10:16,159
>> You could try things like this but um I
 

2919
01:10:16,159 --> 01:10:18,229
>> You could try things like this but um I
want to try and take a a different

2920
01:10:18,229 --> 01:10:18,239
want to try and take a a different
 

2921
01:10:18,239 --> 01:10:20,229
want to try and take a a different
different perspective and so maybe this

2922
01:10:20,229 --> 01:10:20,239
different perspective and so maybe this
 

2923
01:10:20,239 --> 01:10:24,470
different perspective and so maybe this
is um so when I was in undergrad uh

2924
01:10:24,470 --> 01:10:24,480
is um so when I was in undergrad uh
 

2925
01:10:24,480 --> 01:10:26,390
is um so when I was in undergrad uh
everyone had to take a signal processing

2926
01:10:26,390 --> 01:10:26,400
everyone had to take a signal processing
 

2927
01:10:26,400 --> 01:10:28,229
everyone had to take a signal processing
class like we all took signal processing

2928
01:10:28,229 --> 01:10:28,239
class like we all took signal processing
 

2929
01:10:28,239 --> 01:10:32,310
class like we all took signal processing
it was part of our lower division and we

2930
01:10:32,310 --> 01:10:32,320
it was part of our lower division and we
 

2931
01:10:32,320 --> 01:10:34,709
it was part of our lower division and we
you know this was but these days you

2932
01:10:34,709 --> 01:10:34,719
you know this was but these days you
 

2933
01:10:34,719 --> 01:10:37,910
you know this was but these days you
guys you guys don't

2934
01:10:37,910 --> 01:10:37,920
guys you guys don't
 

2935
01:10:37,920 --> 01:10:40,870
guys you guys don't
and so when you think convolution what

2936
01:10:40,870 --> 01:10:40,880
and so when you think convolution what
 

2937
01:10:40,880 --> 01:10:43,590
and so when you think convolution what
is the so in in signal processing you

2938
01:10:43,590 --> 01:10:43,600
is the so in in signal processing you
 

2939
01:10:43,600 --> 01:10:44,390
is the so in in signal processing you
think

2940
01:10:44,390 --> 01:10:44,400
think
 

2941
01:10:44,400 --> 01:10:46,229
think
uh convolutions

2942
01:10:46,229 --> 01:10:46,239
uh convolutions
 

2943
01:10:46,239 --> 01:10:50,149
uh convolutions
in time domain are

2944
01:10:50,149 --> 01:10:50,159
in time domain are
 

2945
01:10:50,159 --> 01:10:51,990
in time domain are
what what's the what's the corresponding

2946
01:10:51,990 --> 01:10:52,000
what what's the what's the corresponding
 

2947
01:10:52,000 --> 01:10:53,910
what what's the what's the corresponding
there's time domain and there's

2948
01:10:53,910 --> 01:10:53,920
there's time domain and there's
 

2949
01:10:53,920 --> 01:10:56,310
there's time domain and there's
>> frequency domain and convolutions in

2950
01:10:56,310 --> 01:10:56,320
>> frequency domain and convolutions in
 

2951
01:10:56,320 --> 01:10:58,390
>> frequency domain and convolutions in
time are

2952
01:10:58,390 --> 01:10:58,400
time are
 

2953
01:10:58,400 --> 01:11:01,590
time are
>> multiplications in frequency right and

2954
01:11:01,590 --> 01:11:01,600
>> multiplications in frequency right and
 

2955
01:11:01,600 --> 01:11:05,030
>> multiplications in frequency right and
to be able to get this duality

2956
01:11:05,030 --> 01:11:05,040
to be able to get this duality
 

2957
01:11:05,040 --> 01:11:07,830
to be able to get this duality
what is the transform that you use

2958
01:11:07,830 --> 01:11:07,840
what is the transform that you use
 

2959
01:11:07,840 --> 01:11:11,189
what is the transform that you use
>> the fier transform right or the dftt so

2960
01:11:11,189 --> 01:11:11,199
>> the fier transform right or the dftt so
 

2961
01:11:11,199 --> 01:11:12,790
>> the fier transform right or the dftt so
what is this algorithm that everyone

2962
01:11:12,790 --> 01:11:12,800
what is this algorithm that everyone
 

2963
01:11:12,800 --> 01:11:15,030
what is this algorithm that everyone
who's taken 70 has probably heard of

2964
01:11:15,030 --> 01:11:15,040
who's taken 70 has probably heard of
 

2965
01:11:15,040 --> 01:11:15,830
who's taken 70 has probably heard of
>> FFT.

2966
01:11:15,830 --> 01:11:15,840
>> FFT.
 

2967
01:11:15,840 --> 01:11:18,470
>> FFT.
>> The FFT, right? The fast fer transform.

2968
01:11:18,470 --> 01:11:18,480
>> The FFT, right? The fast fer transform.
 

2969
01:11:18,480 --> 01:11:20,630
>> The FFT, right? The fast fer transform.
So what the fast fer transform says is

2970
01:11:20,630 --> 01:11:20,640
So what the fast fer transform says is
 

2971
01:11:20,640 --> 01:11:23,510
So what the fast fer transform says is
that oh I can actually use dynamic

2972
01:11:23,510 --> 01:11:23,520
that oh I can actually use dynamic
 

2973
01:11:23,520 --> 01:11:25,189
that oh I can actually use dynamic
programming or a divide and conquer

2974
01:11:25,189 --> 01:11:25,199
programming or a divide and conquer
 

2975
01:11:25,199 --> 01:11:29,110
programming or a divide and conquer
style approach to instead of having an

2976
01:11:29,110 --> 01:11:29,120
style approach to instead of having an
 

2977
01:11:29,120 --> 01:11:31,830
style approach to instead of having an
ordered t^2 or n squ computation to

2978
01:11:31,830 --> 01:11:31,840
ordered t^2 or n squ computation to
 

2979
01:11:31,840 --> 01:11:33,830
ordered t^2 or n squ computation to
compute the fier transform of a length n

2980
01:11:33,830 --> 01:11:33,840
compute the fier transform of a length n
 

2981
01:11:33,840 --> 01:11:36,470
compute the fier transform of a length n
sequence how fast can I do it from you

2982
01:11:36,470 --> 01:11:36,480
sequence how fast can I do it from you
 

2983
01:11:36,480 --> 01:11:40,229
sequence how fast can I do it from you
can do it in n login. Right? So if we

2984
01:11:40,229 --> 01:11:40,239
can do it in n login. Right? So if we
 

2985
01:11:40,239 --> 01:11:42,630
can do it in n login. Right? So if we
want to try and improve this well the

2986
01:11:42,630 --> 01:11:42,640
want to try and improve this well the
 

2987
01:11:42,640 --> 01:11:46,070
want to try and improve this well the
answer is yes

2988
01:11:46,070 --> 01:11:46,080
answer is yes
 

2989
01:11:46,080 --> 01:11:51,350
answer is yes
and we can use the fast

2990
01:11:51,350 --> 01:11:51,360

 

2991
01:11:51,360 --> 01:11:55,270

fia transform

2992
01:11:55,270 --> 01:11:55,280

 

2993
01:11:55,280 --> 01:11:56,790

okay

2994
01:11:56,790 --> 01:11:56,800
okay
 

2995
01:11:56,800 --> 01:12:00,709
okay
and I want to go from order t^2 to

2996
01:12:00,709 --> 01:12:00,719
and I want to go from order t^2 to
 

2997
01:12:00,719 --> 01:12:02,470
and I want to go from order t^2 to
instead or maybe I shouldn't write this

2998
01:12:02,470 --> 01:12:02,480
instead or maybe I shouldn't write this
 

2999
01:12:02,480 --> 01:12:09,110
instead or maybe I shouldn't write this
here I should just say

3000
01:12:09,110 --> 01:12:09,120

 

3001
01:12:09,120 --> 01:12:13,510

should just say order t

3002
01:12:13,510 --> 01:12:13,520
should just say order t
 

3003
01:12:13,520 --> 01:12:16,390
should just say order t
log t right and so this I'm basically

3004
01:12:16,390 --> 01:12:16,400
log t right and so this I'm basically
 

3005
01:12:16,400 --> 01:12:23,590
log t right and so this I'm basically
going to do a dynamic programming

3006
01:12:23,590 --> 01:12:23,600

 

3007
01:12:23,600 --> 01:12:25,990

style algorithm and the key thing that

3008
01:12:25,990 --> 01:12:26,000
style algorithm and the key thing that
 

3009
01:12:26,000 --> 01:12:27,669
style algorithm and the key thing that
one has to notice so how will we do this

3010
01:12:27,669 --> 01:12:27,679
one has to notice so how will we do this
 

3011
01:12:27,679 --> 01:12:29,669
one has to notice so how will we do this
we have to do these convolutions well

3012
01:12:29,669 --> 01:12:29,679
we have to do these convolutions well
 

3013
01:12:29,679 --> 01:12:30,870
we have to do these convolutions well
what we're going to do is we're going to

3014
01:12:30,870 --> 01:12:30,880
what we're going to do is we're going to
 

3015
01:12:30,880 --> 01:12:33,430
what we're going to do is we're going to
do an fft of your filter you're going to

3016
01:12:33,430 --> 01:12:33,440
do an fft of your filter you're going to
 

3017
01:12:33,440 --> 01:12:35,750
do an fft of your filter you're going to
do an fft of your sequence you're going

3018
01:12:35,750 --> 01:12:35,760
do an fft of your sequence you're going
 

3019
01:12:35,760 --> 01:12:36,950
do an fft of your sequence you're going
multiply and then you're going to do an

3020
01:12:36,950 --> 01:12:36,960
multiply and then you're going to do an
 

3021
01:12:36,960 --> 01:12:39,030
multiply and then you're going to do an
inverse FFT

3022
01:12:39,030 --> 01:12:39,040
inverse FFT
 

3023
01:12:39,040 --> 01:12:40,950
inverse FFT
and you're going to get out essentially

3024
01:12:40,950 --> 01:12:40,960
and you're going to get out essentially
 

3025
01:12:40,960 --> 01:12:43,990
and you're going to get out essentially
in time the time domain convolution is

3026
01:12:43,990 --> 01:12:44,000
in time the time domain convolution is
 

3027
01:12:44,000 --> 01:12:47,590
in time the time domain convolution is
going to come out right so everyone any

3028
01:12:47,590 --> 01:12:47,600
going to come out right so everyone any
 

3029
01:12:47,600 --> 01:12:49,590
going to come out right so everyone any
questions about

3030
01:12:49,590 --> 01:12:49,600
questions about
 

3031
01:12:49,600 --> 01:12:51,510
questions about
how one would do this again let me just

3032
01:12:51,510 --> 01:12:51,520
how one would do this again let me just
 

3033
01:12:51,520 --> 01:12:54,950
how one would do this again let me just
say that slowly I have my filter my

3034
01:12:54,950 --> 01:12:54,960
say that slowly I have my filter my
 

3035
01:12:54,960 --> 01:12:58,790
say that slowly I have my filter my
filter is essentially

3036
01:12:58,790 --> 01:12:58,800

 

3037
01:12:58,800 --> 01:13:01,189

these matrices

3038
01:13:01,189 --> 01:13:01,199
these matrices
 

3039
01:13:01,199 --> 01:13:04,870
these matrices
okay my filter is these matrices

3040
01:13:04,870 --> 01:13:04,880
okay my filter is these matrices
 

3041
01:13:04,880 --> 01:13:10,709
okay my filter is these matrices
and My signal is my inputs x1 x2 x k

3042
01:13:10,709 --> 01:13:10,719
and My signal is my inputs x1 x2 x k
 

3043
01:13:10,719 --> 01:13:12,630
and My signal is my inputs x1 x2 x k
and then what I'm going to do is I'm

3044
01:13:12,630 --> 01:13:12,640
and then what I'm going to do is I'm
 

3045
01:13:12,640 --> 01:13:14,149
and then what I'm going to do is I'm
going to take both of these I'm going to

3046
01:13:14,149 --> 01:13:14,159
going to take both of these I'm going to
 

3047
01:13:14,159 --> 01:13:16,790
going to take both of these I'm going to
transfer them to fiery domain which is n

3048
01:13:16,790 --> 01:13:16,800
transfer them to fiery domain which is n
 

3049
01:13:16,800 --> 01:13:19,189
transfer them to fiery domain which is n
login do a multiply

3050
01:13:19,189 --> 01:13:19,199
login do a multiply
 

3051
01:13:19,199 --> 01:13:21,669
login do a multiply
and then do the transform back again so

3052
01:13:21,669 --> 01:13:21,679
and then do the transform back again so
 

3053
01:13:21,679 --> 01:13:24,390
and then do the transform back again so
I can do this basically in n or t log t

3054
01:13:24,390 --> 01:13:24,400
I can do this basically in n or t log t
 

3055
01:13:24,400 --> 01:13:27,270
I can do this basically in n or t log t
time okay

3056
01:13:27,270 --> 01:13:27,280
time okay
 

3057
01:13:27,280 --> 01:13:30,070
time okay
now there's another okay so when you did

3058
01:13:30,070 --> 01:13:30,080
now there's another okay so when you did
 

3059
01:13:30,080 --> 01:13:33,189
now there's another okay so when you did
fft what were you used to having all of

3060
01:13:33,189 --> 01:13:33,199
fft what were you used to having all of
 

3061
01:13:33,199 --> 01:13:35,990
fft what were you used to having all of
your elements of your sequence be like

3062
01:13:35,990 --> 01:13:36,000
your elements of your sequence be like
 

3063
01:13:36,000 --> 01:13:38,070
your elements of your sequence be like
when I think of a signal I typically

3064
01:13:38,070 --> 01:13:38,080
when I think of a signal I typically
 

3065
01:13:38,080 --> 01:13:41,030
when I think of a signal I typically
think of a signal with entries where

3066
01:13:41,030 --> 01:13:41,040
think of a signal with entries where
 

3067
01:13:41,040 --> 01:13:44,470
think of a signal with entries where
where every where every entry of my

3068
01:13:44,470 --> 01:13:44,480
where every where every entry of my
 

3069
01:13:44,480 --> 01:13:47,030
where every where every entry of my
signal essentially is or every value of

3070
01:13:47,030 --> 01:13:47,040
signal essentially is or every value of
 

3071
01:13:47,040 --> 01:13:49,590
signal essentially is or every value of
my signal is a scalar right like I have

3072
01:13:49,590 --> 01:13:49,600
my signal is a scalar right like I have
 

3073
01:13:49,600 --> 01:13:52,790
my signal is a scalar right like I have
something like when I think of a signal

3074
01:13:52,790 --> 01:13:52,800
something like when I think of a signal
 

3075
01:13:52,800 --> 01:13:55,430
something like when I think of a signal
I think of something like if I'm

3076
01:13:55,430 --> 01:13:55,440
I think of something like if I'm
 

3077
01:13:55,440 --> 01:13:57,030
I think of something like if I'm
thinking discrete time I'm thinking of

3078
01:13:57,030 --> 01:13:57,040
thinking discrete time I'm thinking of
 

3079
01:13:57,040 --> 01:13:58,870
thinking discrete time I'm thinking of
something like this or I'm thinking of

3080
01:13:58,870 --> 01:13:58,880
something like this or I'm thinking of
 

3081
01:13:58,880 --> 01:14:01,510
something like this or I'm thinking of
in continuous time

3082
01:14:01,510 --> 01:14:01,520
in continuous time
 

3083
01:14:01,520 --> 01:14:05,430
in continuous time
I'm thinking of something that's

3084
01:14:05,430 --> 01:14:05,440
I'm thinking of something that's
 

3085
01:14:05,440 --> 01:14:07,750
I'm thinking of something that's
you know it's a it's a scalar I can't

3086
01:14:07,750 --> 01:14:07,760
you know it's a it's a scalar I can't
 

3087
01:14:07,760 --> 01:14:10,149
you know it's a it's a scalar I can't
but what do we have here what is every

3088
01:14:10,149 --> 01:14:10,159
but what do we have here what is every
 

3089
01:14:10,159 --> 01:14:13,590
but what do we have here what is every
entry that I have

3090
01:14:13,590 --> 01:14:13,600
entry that I have
 

3091
01:14:13,600 --> 01:14:16,550
entry that I have
each of these things this is now my I'm

3092
01:14:16,550 --> 01:14:16,560
each of these things this is now my I'm
 

3093
01:14:16,560 --> 01:14:18,709
each of these things this is now my I'm
saying my signal my first entry of my

3094
01:14:18,709 --> 01:14:18,719
saying my signal my first entry of my
 

3095
01:14:18,719 --> 01:14:21,189
saying my signal my first entry of my
signal is x knot the second entry of my

3096
01:14:21,189 --> 01:14:21,199
signal is x knot the second entry of my
 

3097
01:14:21,199 --> 01:14:23,350
signal is x knot the second entry of my
signal is x1 the third entry of my

3098
01:14:23,350 --> 01:14:23,360
signal is x1 the third entry of my
 

3099
01:14:23,360 --> 01:14:26,310
signal is x1 the third entry of my
signal is x2 but these are all actually

3100
01:14:26,310 --> 01:14:26,320
signal is x2 but these are all actually
 

3101
01:14:26,320 --> 01:14:30,709
signal is x2 but these are all actually
vectors right so I want to use the fft

3102
01:14:30,709 --> 01:14:30,719
vectors right so I want to use the fft
 

3103
01:14:30,719 --> 01:14:33,830
vectors right so I want to use the fft
but is it obvious how to use the FFT I

3104
01:14:33,830 --> 01:14:33,840
but is it obvious how to use the FFT I
 

3105
01:14:33,840 --> 01:14:36,229
but is it obvious how to use the FFT I
just kind of said that we can use it but

3106
01:14:36,229 --> 01:14:36,239
just kind of said that we can use it but
 

3107
01:14:36,239 --> 01:14:38,630
just kind of said that we can use it but
we have we have a little bit of a issue

3108
01:14:38,630 --> 01:14:38,640
we have we have a little bit of a issue
 

3109
01:14:38,640 --> 01:14:41,990
we have we have a little bit of a issue
here right that you know when we do the

3110
01:14:41,990 --> 01:14:42,000
here right that you know when we do the
 

3111
01:14:42,000 --> 01:14:43,990
here right that you know when we do the
FFT we're used to doing it on scalers

3112
01:14:43,990 --> 01:14:44,000
FFT we're used to doing it on scalers
 

3113
01:14:44,000 --> 01:14:46,390
FFT we're used to doing it on scalers
does everyone see the issue but here we

3114
01:14:46,390 --> 01:14:46,400
does everyone see the issue but here we
 

3115
01:14:46,400 --> 01:14:49,189
does everyone see the issue but here we
have matrices and vectors instead of uh

3116
01:14:49,189 --> 01:14:49,199
have matrices and vectors instead of uh
 

3117
01:14:49,199 --> 01:14:53,110
have matrices and vectors instead of uh
scalers multiplying scalers

3118
01:14:53,110 --> 01:14:53,120
scalers multiplying scalers
 

3119
01:14:53,120 --> 01:15:04,470
scalers multiplying scalers
everyone with me yes

3120
01:15:04,470 --> 01:15:04,480

 

3121
01:15:04,480 --> 01:15:06,470

I don't think it would just work like

3122
01:15:06,470 --> 01:15:06,480
I don't think it would just work like
 

3123
01:15:06,480 --> 01:15:07,750
I don't think it would just work like
that. I mean, essentially, we're going

3124
01:15:07,750 --> 01:15:07,760
that. I mean, essentially, we're going
 

3125
01:15:07,760 --> 01:15:09,750
that. I mean, essentially, we're going
to break it down component by component.

3126
01:15:09,750 --> 01:15:09,760
to break it down component by component.
 

3127
01:15:09,760 --> 01:15:11,830
to break it down component by component.
The key idea, I mean, at some level,

3128
01:15:11,830 --> 01:15:11,840
The key idea, I mean, at some level,
 

3129
01:15:11,840 --> 01:15:14,950
The key idea, I mean, at some level,
it's all linearity and it's all just

3130
01:15:14,950 --> 01:15:14,960
it's all linearity and it's all just
 

3131
01:15:14,960 --> 01:15:18,229
it's all linearity and it's all just
change of basis, right? And so, uh, you

3132
01:15:18,229 --> 01:15:18,239
change of basis, right? And so, uh, you
 

3133
01:15:18,239 --> 01:15:20,630
change of basis, right? And so, uh, you
can think of it in maybe there's a way

3134
01:15:20,630 --> 01:15:20,640
can think of it in maybe there's a way
 

3135
01:15:20,640 --> 01:15:23,270
can think of it in maybe there's a way
of thinking about it that way. The way

3136
01:15:23,270 --> 01:15:23,280
of thinking about it that way. The way
 

3137
01:15:23,280 --> 01:15:24,550
of thinking about it that way. The way
I'm going to talk about thinking about

3138
01:15:24,550 --> 01:15:24,560
I'm going to talk about thinking about
 

3139
01:15:24,560 --> 01:15:26,229
I'm going to talk about thinking about
it is basically breaking it down

3140
01:15:26,229 --> 01:15:26,239
it is basically breaking it down
 

3141
01:15:26,239 --> 01:15:28,630
it is basically breaking it down
component by component uh to to

3142
01:15:28,630 --> 01:15:28,640
component by component uh to to
 

3143
01:15:28,640 --> 01:15:31,189
component by component uh to to
carefully account for uh each of these.

3144
01:15:31,189 --> 01:15:31,199
carefully account for uh each of these.
 

3145
01:15:31,199 --> 01:15:32,470
carefully account for uh each of these.
So we're going to take these vectors and

3146
01:15:32,470 --> 01:15:32,480
So we're going to take these vectors and
 

3147
01:15:32,480 --> 01:15:34,870
So we're going to take these vectors and
break them down into a se into a set of

3148
01:15:34,870 --> 01:15:34,880
break them down into a se into a set of
 

3149
01:15:34,880 --> 01:15:37,830
break them down into a se into a set of
sequences to be able to to to be able to

3150
01:15:37,830 --> 01:15:37,840
sequences to be able to to to be able to
 

3151
01:15:37,840 --> 01:15:40,550
sequences to be able to to to be able to
do this. And this was the one of the key

3152
01:15:40,550 --> 01:15:40,560
do this. And this was the one of the key
 

3153
01:15:40,560 --> 01:15:43,750
do this. And this was the one of the key
things that doing this,

3154
01:15:43,750 --> 01:15:43,760
things that doing this,
 

3155
01:15:43,760 --> 01:15:45,830
things that doing this,
you know, being able to use the FFT

3156
01:15:45,830 --> 01:15:45,840
you know, being able to use the FFT
 

3157
01:15:45,840 --> 01:15:48,310
you know, being able to use the FFT
trick on these vector valued sequences

3158
01:15:48,310 --> 01:15:48,320
trick on these vector valued sequences
 

3159
01:15:48,320 --> 01:15:50,070
trick on these vector valued sequences
was one of the key contributions and

3160
01:15:50,070 --> 01:15:50,080
was one of the key contributions and
 

3161
01:15:50,080 --> 01:15:54,709
was one of the key contributions and
innovations of the first set of um state

3162
01:15:54,709 --> 01:15:54,719
innovations of the first set of um state
 

3163
01:15:54,719 --> 01:15:57,830
innovations of the first set of um state
space model papers.

3164
01:15:57,830 --> 01:15:57,840
space model papers.
 

3165
01:15:57,840 --> 01:16:00,790
space model papers.
Okay. So before we get to that, I'm not

3166
01:16:00,790 --> 01:16:00,800
Okay. So before we get to that, I'm not
 

3167
01:16:00,800 --> 01:16:02,550
Okay. So before we get to that, I'm not
sure I have enough time to fully get

3168
01:16:02,550 --> 01:16:02,560
sure I have enough time to fully get
 

3169
01:16:02,560 --> 01:16:04,149
sure I have enough time to fully get
through that. So I will go through that

3170
01:16:04,149 --> 01:16:04,159
through that. So I will go through that
 

3171
01:16:04,159 --> 01:16:07,350
through that. So I will go through that
next time. But I'm going to um talk

3172
01:16:07,350 --> 01:16:07,360
next time. But I'm going to um talk
 

3173
01:16:07,360 --> 01:16:10,070
next time. But I'm going to um talk
about one other little thing which is

3174
01:16:10,070 --> 01:16:10,080
about one other little thing which is
 

3175
01:16:10,080 --> 01:16:13,030
about one other little thing which is
that let's say we can somehow get this t

3176
01:16:13,030 --> 01:16:13,040
that let's say we can somehow get this t
 

3177
01:16:13,040 --> 01:16:14,709
that let's say we can somehow get this t
log t. Okay, we still have this vector

3178
01:16:14,709 --> 01:16:14,719
log t. Okay, we still have this vector
 

3179
01:16:14,719 --> 01:16:17,990
log t. Okay, we still have this vector
issue but you'll grant me that probably

3180
01:16:17,990 --> 01:16:18,000
issue but you'll grant me that probably
 

3181
01:16:18,000 --> 01:16:21,669
issue but you'll grant me that probably
we can do some careful accounting.

3182
01:16:21,669 --> 01:16:21,679
we can do some careful accounting.
 

3183
01:16:21,679 --> 01:16:24,149
we can do some careful accounting.
Everything is nice and linear and you'll

3184
01:16:24,149 --> 01:16:24,159
Everything is nice and linear and you'll
 

3185
01:16:24,159 --> 01:16:25,510
Everything is nice and linear and you'll
trust me that I'll teach you how to do

3186
01:16:25,510 --> 01:16:25,520
trust me that I'll teach you how to do
 

3187
01:16:25,520 --> 01:16:29,910
trust me that I'll teach you how to do
it next time. Okay, but

3188
01:16:29,910 --> 01:16:29,920
it next time. Okay, but
 

3189
01:16:29,920 --> 01:16:31,910
it next time. Okay, but
let's talk about one other issue since I

3190
01:16:31,910 --> 01:16:31,920
let's talk about one other issue since I
 

3191
01:16:31,920 --> 01:16:36,630
let's talk about one other issue since I
don't have that much time left.

3192
01:16:36,630 --> 01:16:36,640

 

3193
01:16:36,640 --> 01:16:39,990

which is we also have these

3194
01:16:39,990 --> 01:16:40,000
which is we also have these
 

3195
01:16:40,000 --> 01:16:43,350
which is we also have these
things here, right? These c a to the k *

3196
01:16:43,350 --> 01:16:43,360
things here, right? These c a to the k *
 

3197
01:16:43,360 --> 01:16:50,310
things here, right? These c a to the k *
b. Maybe I should just copy this. Uh

3198
01:16:50,310 --> 01:16:50,320

 

3199
01:16:50,320 --> 01:17:13,830

oh, wrong thing. I want this.

3200
01:17:13,830 --> 01:17:13,840

 

3201
01:17:13,840 --> 01:17:19,110

Did not work out the way I wanted to.

3202
01:17:19,110 --> 01:17:19,120

 

3203
01:17:19,120 --> 01:17:34,630

Okay, never mind. Um,

3204
01:17:34,630 --> 01:17:34,640

 

3205
01:17:34,640 --> 01:17:37,510

you remember that equation, right?

3206
01:17:37,510 --> 01:17:37,520
you remember that equation, right?
 

3207
01:17:37,520 --> 01:17:40,310
you remember that equation, right?
Okay.

3208
01:17:40,310 --> 01:17:40,320
Okay.
 

3209
01:17:40,320 --> 01:17:43,030
Okay.
So, what about this term

3210
01:17:43,030 --> 01:17:43,040
So, what about this term
 

3211
01:17:43,040 --> 01:17:44,709
So, what about this term
computing? This is also like these are a

3212
01:17:44,709 --> 01:17:44,719
computing? This is also like these are a
 

3213
01:17:44,719 --> 01:17:47,350
computing? This is also like these are a
lot of matrices to multiply, right? And

3214
01:17:47,350 --> 01:17:47,360
lot of matrices to multiply, right? And
 

3215
01:17:47,360 --> 01:17:49,750
lot of matrices to multiply, right? And
one of the things here is that what we

3216
01:17:49,750 --> 01:17:49,760
one of the things here is that what we
 

3217
01:17:49,760 --> 01:17:52,470
one of the things here is that what we
want to do is we want to be able to have

3218
01:17:52,470 --> 01:17:52,480
want to do is we want to be able to have
 

3219
01:17:52,480 --> 01:17:54,709
want to do is we want to be able to have
a lot of hidden state, right? We want to

3220
01:17:54,709 --> 01:17:54,719
a lot of hidden state, right? We want to
 

3221
01:17:54,719 --> 01:17:58,070
a lot of hidden state, right? We want to
be able to capture all of the past into

3222
01:17:58,070 --> 01:17:58,080
be able to capture all of the past into
 

3223
01:17:58,080 --> 01:17:59,910
be able to capture all of the past into
this H.

3224
01:17:59,910 --> 01:17:59,920
this H.
 

3225
01:17:59,920 --> 01:18:02,790
this H.
And so to do that, if we want to capture

3226
01:18:02,790 --> 01:18:02,800
And so to do that, if we want to capture
 

3227
01:18:02,800 --> 01:18:05,590
And so to do that, if we want to capture
more and more history and context, we

3228
01:18:05,590 --> 01:18:05,600
more and more history and context, we
 

3229
01:18:05,600 --> 01:18:07,990
more and more history and context, we
want to make H big.

3230
01:18:07,990 --> 01:18:08,000
want to make H big.
 

3231
01:18:08,000 --> 01:18:10,229
want to make H big.
The larger H is, the more stuff it can

3232
01:18:10,229 --> 01:18:10,239
The larger H is, the more stuff it can
 

3233
01:18:10,239 --> 01:18:12,870
The larger H is, the more stuff it can
it can can it can store. So that means

3234
01:18:12,870 --> 01:18:12,880
it can can it can store. So that means
 

3235
01:18:12,880 --> 01:18:15,430
it can can it can store. So that means
that these this a matrix and these is

3236
01:18:15,430 --> 01:18:15,440
that these this a matrix and these is
 

3237
01:18:15,440 --> 01:18:18,310
that these this a matrix and these is
going to be quite big right so this is

3238
01:18:18,310 --> 01:18:18,320
going to be quite big right so this is
 

3239
01:18:18,320 --> 01:18:21,350
going to be quite big right so this is
quite a bit of uh this is not a small

3240
01:18:21,350 --> 01:18:21,360
quite a bit of uh this is not a small
 

3241
01:18:21,360 --> 01:18:23,910
quite a bit of uh this is not a small
matrix multiply to handle so yes there's

3242
01:18:23,910 --> 01:18:23,920
matrix multiply to handle so yes there's
 

3243
01:18:23,920 --> 01:18:25,510
matrix multiply to handle so yes there's
a dependence on the length of the

3244
01:18:25,510 --> 01:18:25,520
a dependence on the length of the
 

3245
01:18:25,520 --> 01:18:28,149
a dependence on the length of the
context but also there's the per context

3246
01:18:28,149 --> 01:18:28,159
context but also there's the per context
 

3247
01:18:28,159 --> 01:18:29,590
context but also there's the per context
compute that you also have to think

3248
01:18:29,590 --> 01:18:29,600
compute that you also have to think
 

3249
01:18:29,600 --> 01:18:33,510
compute that you also have to think
about okay

3250
01:18:33,510 --> 01:18:33,520

 

3251
01:18:33,520 --> 01:18:35,669

so this a to the k again you can think

3252
01:18:35,669 --> 01:18:35,679
so this a to the k again you can think
 

3253
01:18:35,679 --> 01:18:37,669
so this a to the k again you can think
of computing a to the k in this you know

3254
01:18:37,669 --> 01:18:37,679
of computing a to the k in this you know
 

3255
01:18:37,679 --> 01:18:40,229
of computing a to the k in this you know
in some in a in a memoization or caching

3256
01:18:40,229 --> 01:18:40,239
in some in a in a memoization or caching
 

3257
01:18:40,239 --> 01:18:42,310
in some in a in a memoization or caching
way where I can think of Well, I can

3258
01:18:42,310 --> 01:18:42,320
way where I can think of Well, I can
 

3259
01:18:42,320 --> 01:18:44,870
way where I can think of Well, I can
keep doubling it. I don't have to I

3260
01:18:44,870 --> 01:18:44,880
keep doubling it. I don't have to I
 

3261
01:18:44,880 --> 01:18:47,030
keep doubling it. I don't have to I
don't have to multiply a k times, but I

3262
01:18:47,030 --> 01:18:47,040
don't have to multiply a k times, but I
 

3263
01:18:47,040 --> 01:18:48,630
don't have to multiply a k times, but I
can kind of do a squaring trick to maybe

3264
01:18:48,630 --> 01:18:48,640
can kind of do a squaring trick to maybe
 

3265
01:18:48,640 --> 01:18:51,510
can kind of do a squaring trick to maybe
reduce that to a log uh level of

3266
01:18:51,510 --> 01:18:51,520
reduce that to a log uh level of
 

3267
01:18:51,520 --> 01:18:53,350
reduce that to a log uh level of
computation.

3268
01:18:53,350 --> 01:18:53,360
computation.
 

3269
01:18:53,360 --> 01:18:56,790
computation.
But even then, a to the k is going to

3270
01:18:56,790 --> 01:18:56,800
But even then, a to the k is going to
 

3271
01:18:56,800 --> 01:18:59,510
But even then, a to the k is going to
add steps to your computation graph,

3272
01:18:59,510 --> 01:18:59,520
add steps to your computation graph,
 

3273
01:18:59,520 --> 01:19:01,590
add steps to your computation graph,
right? Because I have to that that this

3274
01:19:01,590 --> 01:19:01,600
right? Because I have to that that this
 

3275
01:19:01,600 --> 01:19:03,430
right? Because I have to that that this
is a sequential operation. Even if I do

3276
01:19:03,430 --> 01:19:03,440
is a sequential operation. Even if I do
 

3277
01:19:03,440 --> 01:19:06,870
is a sequential operation. Even if I do
it in log number of steps, log k number

3278
01:19:06,870 --> 01:19:06,880
it in log number of steps, log k number
 

3279
01:19:06,880 --> 01:19:09,830
it in log number of steps, log k number
of steps, I'm still going to have to

3280
01:19:09,830 --> 01:19:09,840
of steps, I'm still going to have to
 

3281
01:19:09,840 --> 01:19:11,669
of steps, I'm still going to have to
first square it and then square it again

3282
01:19:11,669 --> 01:19:11,679
first square it and then square it again
 

3283
01:19:11,679 --> 01:19:13,110
first square it and then square it again
and then square it again. I cannot

3284
01:19:13,110 --> 01:19:13,120
and then square it again. I cannot
 

3285
01:19:13,120 --> 01:19:14,870
and then square it again. I cannot
parallelize this, right? My computation

3286
01:19:14,870 --> 01:19:14,880
parallelize this, right? My computation
 

3287
01:19:14,880 --> 01:19:19,030
parallelize this, right? My computation
graph uh path becomes longer.

3288
01:19:19,030 --> 01:19:19,040
graph uh path becomes longer.
 

3289
01:19:19,040 --> 01:19:23,990
graph uh path becomes longer.
So is there a way that we can speed this

3290
01:19:23,990 --> 01:19:24,000
So is there a way that we can speed this
 

3291
01:19:24,000 --> 01:19:27,189
So is there a way that we can speed this
part of the computation off?

3292
01:19:27,189 --> 01:19:27,199
part of the computation off?
 

3293
01:19:27,199 --> 01:19:33,750
part of the computation off?
>> Yes.

3294
01:19:33,750 --> 01:19:33,760

 

3295
01:19:33,760 --> 01:19:35,510

Yeah, that's exactly what we are going

3296
01:19:35,510 --> 01:19:35,520
Yeah, that's exactly what we are going
 

3297
01:19:35,520 --> 01:19:37,510
Yeah, that's exactly what we are going
to do is we're going to say that well

3298
01:19:37,510 --> 01:19:37,520
to do is we're going to say that well
 

3299
01:19:37,520 --> 01:19:41,189
to do is we're going to say that well
what is the nicest matrix that if you

3300
01:19:41,189 --> 01:19:41,199
what is the nicest matrix that if you
 

3301
01:19:41,199 --> 01:19:43,189
what is the nicest matrix that if you
wanted to take powers of what would be

3302
01:19:43,189 --> 01:19:43,199
wanted to take powers of what would be
 

3303
01:19:43,199 --> 01:19:45,350
wanted to take powers of what would be
your choice you would choose a diagonal

3304
01:19:45,350 --> 01:19:45,360
your choice you would choose a diagonal
 

3305
01:19:45,360 --> 01:19:49,430
your choice you would choose a diagonal
matrix right and so it turns out that we

3306
01:19:49,430 --> 01:19:49,440
matrix right and so it turns out that we
 

3307
01:19:49,440 --> 01:19:50,630
matrix right and so it turns out that we
can actually just we're just going to

3308
01:19:50,630 --> 01:19:50,640
can actually just we're just going to
 

3309
01:19:50,640 --> 01:19:52,550
can actually just we're just going to
say let a be diagonal we're going to

3310
01:19:52,550 --> 01:19:52,560
say let a be diagonal we're going to
 

3311
01:19:52,560 --> 01:19:55,510
say let a be diagonal we're going to
restrict a to being diagonal

3312
01:19:55,510 --> 01:19:55,520
restrict a to being diagonal
 

3313
01:19:55,520 --> 01:19:57,590
restrict a to being diagonal
now does this come at a cost or right

3314
01:19:57,590 --> 01:19:57,600
now does this come at a cost or right
 

3315
01:19:57,600 --> 01:19:59,750
now does this come at a cost or right
because now we're restricting the kind

3316
01:19:59,750 --> 01:19:59,760
because now we're restricting the kind
 

3317
01:19:59,760 --> 01:20:02,550
because now we're restricting the kind
of interactions that your uh state space

3318
01:20:02,550 --> 01:20:02,560
of interactions that your uh state space
 

3319
01:20:02,560 --> 01:20:04,550
of interactions that your uh state space
model can capture. There's only certain

3320
01:20:04,550 --> 01:20:04,560
model can capture. There's only certain
 

3321
01:20:04,560 --> 01:20:06,870
model can capture. There's only certain
things that can that can capture. Well,

3322
01:20:06,870 --> 01:20:06,880
things that can that can capture. Well,
 

3323
01:20:06,880 --> 01:20:10,310
things that can that can capture. Well,
it turns out that most matrices or many

3324
01:20:10,310 --> 01:20:10,320
it turns out that most matrices or many
 

3325
01:20:10,320 --> 01:20:14,229
it turns out that most matrices or many
matrices are diagonalizable, right? So

3326
01:20:14,229 --> 01:20:14,239
matrices are diagonalizable, right? So
 

3327
01:20:14,239 --> 01:20:15,830
matrices are diagonalizable, right? So
up to a change of basis, you're

3328
01:20:15,830 --> 01:20:15,840
up to a change of basis, you're
 

3329
01:20:15,840 --> 01:20:18,950
up to a change of basis, you're
capturing a very large family of

3330
01:20:18,950 --> 01:20:18,960
capturing a very large family of
 

3331
01:20:18,960 --> 01:20:21,510
capturing a very large family of
structures using a diagonalizable

3332
01:20:21,510 --> 01:20:21,520
structures using a diagonalizable
 

3333
01:20:21,520 --> 01:20:23,590
structures using a diagonalizable
matrix. Which are the matrices that are

3334
01:20:23,590 --> 01:20:23,600
matrix. Which are the matrices that are
 

3335
01:20:23,600 --> 01:20:25,430
matrix. Which are the matrices that are
not diagonalizable?

3336
01:20:25,430 --> 01:20:25,440
not diagonalizable?
 

3337
01:20:25,440 --> 01:20:26,870
not diagonalizable?
Well, those are the ones that have

3338
01:20:26,870 --> 01:20:26,880
Well, those are the ones that have
 

3339
01:20:26,880 --> 01:20:29,830
Well, those are the ones that have
basically a a Jordan block structure,

3340
01:20:29,830 --> 01:20:29,840
basically a a Jordan block structure,
 

3341
01:20:29,840 --> 01:20:31,669
basically a a Jordan block structure,
right? Or a non-trivial Jordan block

3342
01:20:31,669 --> 01:20:31,679
right? Or a non-trivial Jordan block
 

3343
01:20:31,679 --> 01:20:34,070
right? Or a non-trivial Jordan block
structure for the people have seen

3344
01:20:34,070 --> 01:20:34,080
structure for the people have seen
 

3345
01:20:34,080 --> 01:20:36,709
structure for the people have seen
Jordan blocks. Yes. Okay. So, basically

3346
01:20:36,709 --> 01:20:36,719
Jordan blocks. Yes. Okay. So, basically
 

3347
01:20:36,719 --> 01:20:38,070
Jordan blocks. Yes. Okay. So, basically
that means that if you have these

3348
01:20:38,070 --> 01:20:38,080
that means that if you have these
 

3349
01:20:38,080 --> 01:20:39,910
that means that if you have these
repeated values, then you're going to

3350
01:20:39,910 --> 01:20:39,920
repeated values, then you're going to
 

3351
01:20:39,920 --> 01:20:41,669
repeated values, then you're going to
have issues with uh with

3352
01:20:41,669 --> 01:20:41,679
have issues with uh with
 

3353
01:20:41,679 --> 01:20:45,030
have issues with uh with
diagonalization.

3354
01:20:45,030 --> 01:20:45,040

 

3355
01:20:45,040 --> 01:20:47,189

That's true. What we're going to say is

3356
01:20:47,189 --> 01:20:47,199
That's true. What we're going to say is
 

3357
01:20:47,199 --> 01:20:49,270
That's true. What we're going to say is
we're just going to let those go and

3358
01:20:49,270 --> 01:20:49,280
we're just going to let those go and
 

3359
01:20:49,280 --> 01:20:50,390
we're just going to let those go and
we're going to be able to try and

3360
01:20:50,390 --> 01:20:50,400
we're going to be able to try and
 

3361
01:20:50,400 --> 01:20:51,830
we're going to be able to try and
capture we're going to capture as much

3362
01:20:51,830 --> 01:20:51,840
capture we're going to capture as much
 

3363
01:20:51,840 --> 01:20:54,070
capture we're going to capture as much
as we can in the very large set of

3364
01:20:54,070 --> 01:20:54,080
as we can in the very large set of
 

3365
01:20:54,080 --> 01:20:55,669
as we can in the very large set of
things that can be captured by

3366
01:20:55,669 --> 01:20:55,679
things that can be captured by
 

3367
01:20:55,679 --> 01:20:57,110
things that can be captured by
diagonalizable matrices. And because

3368
01:20:57,110 --> 01:20:57,120
diagonalizable matrices. And because
 

3369
01:20:57,120 --> 01:20:58,390
diagonalizable matrices. And because
we're learning these parameters, we

3370
01:20:58,390 --> 01:20:58,400
we're learning these parameters, we
 

3371
01:20:58,400 --> 01:21:00,070
we're learning these parameters, we
basically we'll learn the basis that is

3372
01:21:00,070 --> 01:21:00,080
basically we'll learn the basis that is
 

3373
01:21:00,080 --> 01:21:03,189
basically we'll learn the basis that is
the diagonal basis, right? Um that's

3374
01:21:03,189 --> 01:21:03,199
the diagonal basis, right? Um that's
 

3375
01:21:03,199 --> 01:21:04,470
the diagonal basis, right? Um that's
that's basically what's going to happen.

3376
01:21:04,470 --> 01:21:04,480
that's basically what's going to happen.
 

3377
01:21:04,480 --> 01:21:06,310
that's basically what's going to happen.
So what we're going to do is we're going

3378
01:21:06,310 --> 01:21:06,320
So what we're going to do is we're going
 

3379
01:21:06,320 --> 01:21:08,470
So what we're going to do is we're going
to say

3380
01:21:08,470 --> 01:21:08,480
to say
 

3381
01:21:08,480 --> 01:21:10,390
to say
let's just add this structure and let's

3382
01:21:10,390 --> 01:21:10,400
let's just add this structure and let's
 

3383
01:21:10,400 --> 01:21:12,870
let's just add this structure and let's
restrict

3384
01:21:12,870 --> 01:21:12,880
restrict
 

3385
01:21:12,880 --> 01:21:20,070
restrict
to diagonal A matrices. Okay.

3386
01:21:20,070 --> 01:21:20,080

 

3387
01:21:20,080 --> 01:21:22,870

So, I'm not going to start this thing

3388
01:21:22,870 --> 01:21:22,880
So, I'm not going to start this thing
 

3389
01:21:22,880 --> 01:21:25,030
So, I'm not going to start this thing
because I have like three minutes left.

3390
01:21:25,030 --> 01:21:25,040
because I have like three minutes left.
 

3391
01:21:25,040 --> 01:21:28,310
because I have like three minutes left.
What I'm going to say instead is what

3392
01:21:28,310 --> 01:21:28,320
What I'm going to say instead is what
 

3393
01:21:28,320 --> 01:21:30,390
What I'm going to say instead is what
are we going to do next? So, just a key

3394
01:21:30,390 --> 01:21:30,400
are we going to do next? So, just a key
 

3395
01:21:30,400 --> 01:21:32,390
are we going to do next? So, just a key
point that we already talked about, but

3396
01:21:32,390 --> 01:21:32,400
point that we already talked about, but
 

3397
01:21:32,400 --> 01:21:34,390
point that we already talked about, but
we're now going to say that we're going

3398
01:21:34,390 --> 01:21:34,400
we're now going to say that we're going
 

3399
01:21:34,400 --> 01:21:39,030
we're now going to say that we're going
to try and restrict to um these diagonal

3400
01:21:39,030 --> 01:21:39,040
to try and restrict to um these diagonal
 

3401
01:21:39,040 --> 01:21:42,149
to try and restrict to um these diagonal
A's. We're going to remove all of the

3402
01:21:42,149 --> 01:21:42,159
A's. We're going to remove all of the
 

3403
01:21:42,159 --> 01:21:44,790
A's. We're going to remove all of the
horizontal nonlinearities. We talked

3404
01:21:44,790 --> 01:21:44,800
horizontal nonlinearities. We talked
 

3405
01:21:44,800 --> 01:21:47,189
horizontal nonlinearities. We talked
about expressive power.

3406
01:21:47,189 --> 01:21:47,199
about expressive power.
 

3407
01:21:47,199 --> 01:21:49,110
about expressive power.
And the way we're going to handle this

3408
01:21:49,110 --> 01:21:49,120
And the way we're going to handle this
 

3409
01:21:49,120 --> 01:21:50,550
And the way we're going to handle this
expressive power issue is we're

3410
01:21:50,550 --> 01:21:50,560
expressive power issue is we're
 

3411
01:21:50,560 --> 01:21:51,990
expressive power issue is we're
basically going to say here you're going

3412
01:21:51,990 --> 01:21:52,000
basically going to say here you're going
 

3413
01:21:52,000 --> 01:21:58,790
basically going to say here you're going
to have your um ignore this for now.

3414
01:21:58,790 --> 01:21:58,800

 

3415
01:21:58,800 --> 01:22:00,149

Ignore this part. We'll talk about

3416
01:22:00,149 --> 01:22:00,159
Ignore this part. We'll talk about
 

3417
01:22:00,159 --> 01:22:02,870
Ignore this part. We'll talk about
gating later. Just focus on

3418
01:22:02,870 --> 01:22:02,880
gating later. Just focus on
 

3419
01:22:02,880 --> 01:22:05,990
gating later. Just focus on
this part.

3420
01:22:05,990 --> 01:22:06,000
this part.
 

3421
01:22:06,000 --> 01:22:08,149
this part.
Um and here what this is this Mamba

3422
01:22:08,149 --> 01:22:08,159
Um and here what this is this Mamba
 

3423
01:22:08,159 --> 01:22:10,070
Um and here what this is this Mamba
architecture is just saying look here

3424
01:22:10,070 --> 01:22:10,080
architecture is just saying look here
 

3425
01:22:10,080 --> 01:22:11,910
architecture is just saying look here
you have

3426
01:22:11,910 --> 01:22:11,920
you have
 

3427
01:22:11,920 --> 01:22:15,270
you have
some kind of linear projection. Okay.

3428
01:22:15,270 --> 01:22:15,280
some kind of linear projection. Okay.
 

3429
01:22:15,280 --> 01:22:17,750
some kind of linear projection. Okay.
Then you have a a small con. Maybe you

3430
01:22:17,750 --> 01:22:17,760
Then you have a a small con. Maybe you
 

3431
01:22:17,760 --> 01:22:22,070
Then you have a a small con. Maybe you
want to do some uh you know uh

3432
01:22:22,070 --> 01:22:22,080
want to do some uh you know uh
 

3433
01:22:22,080 --> 01:22:24,229
want to do some uh you know uh
processing of your data. And then here

3434
01:22:24,229 --> 01:22:24,239
processing of your data. And then here
 

3435
01:22:24,239 --> 01:22:28,629
processing of your data. And then here
you have these two nonlinearities.

3436
01:22:28,629 --> 01:22:28,639
you have these two nonlinearities.
 

3437
01:22:28,639 --> 01:22:31,270
you have these two nonlinearities.
Then you have your state space model.

3438
01:22:31,270 --> 01:22:31,280
Then you have your state space model.
 

3439
01:22:31,280 --> 01:22:33,110
Then you have your state space model.
Then this is this is the gating that we

3440
01:22:33,110 --> 01:22:33,120
Then this is this is the gating that we
 

3441
01:22:33,120 --> 01:22:34,470
Then this is this is the gating that we
haven't talked about but we will talk

3442
01:22:34,470 --> 01:22:34,480
haven't talked about but we will talk
 

3443
01:22:34,480 --> 01:22:37,510
haven't talked about but we will talk
about later. And then again you have a

3444
01:22:37,510 --> 01:22:37,520
about later. And then again you have a
 

3445
01:22:37,520 --> 01:22:40,870
about later. And then again you have a
linear layer. Okay. So you do have these

3446
01:22:40,870 --> 01:22:40,880
linear layer. Okay. So you do have these
 

3447
01:22:40,880 --> 01:22:43,189
linear layer. Okay. So you do have these
nonlinearities.

3448
01:22:43,189 --> 01:22:43,199
nonlinearities.
 

3449
01:22:43,199 --> 01:22:45,030
nonlinearities.
We're going to use the tricks of making

3450
01:22:45,030 --> 01:22:45,040
We're going to use the tricks of making
 

3451
01:22:45,040 --> 01:22:48,950
We're going to use the tricks of making
sure A is diagonal and using the FFT.

3452
01:22:48,950 --> 01:22:48,960
sure A is diagonal and using the FFT.
 

3453
01:22:48,960 --> 01:22:50,390
sure A is diagonal and using the FFT.
One thing to question, one question that

3454
01:22:50,390 --> 01:22:50,400
One thing to question, one question that
 

3455
01:22:50,400 --> 01:22:52,870
One thing to question, one question that
you might have is wait,

3456
01:22:52,870 --> 01:22:52,880
you might have is wait,
 

3457
01:22:52,880 --> 01:22:55,510
you might have is wait,
if doing convolutions using the FFT was

3458
01:22:55,510 --> 01:22:55,520
if doing convolutions using the FFT was
 

3459
01:22:55,520 --> 01:22:56,709
if doing convolutions using the FFT was
so much better, why don't we talk about

3460
01:22:56,709 --> 01:22:56,719
so much better, why don't we talk about
 

3461
01:22:56,719 --> 01:22:59,990
so much better, why don't we talk about
this in the connet part of the class?

3462
01:22:59,990 --> 01:23:00,000
this in the connet part of the class?
 

3463
01:23:00,000 --> 01:23:02,950
this in the connet part of the class?
And it turns out that the the key reason

3464
01:23:02,950 --> 01:23:02,960
And it turns out that the the key reason
 

3465
01:23:02,960 --> 01:23:05,830
And it turns out that the the key reason
is that for this n login game to really

3466
01:23:05,830 --> 01:23:05,840
is that for this n login game to really
 

3467
01:23:05,840 --> 01:23:07,830
is that for this n login game to really
kick in, you want to be thinking about

3468
01:23:07,830 --> 01:23:07,840
kick in, you want to be thinking about
 

3469
01:23:07,840 --> 01:23:09,830
kick in, you want to be thinking about
really long convolutions. when you have

3470
01:23:09,830 --> 01:23:09,840
really long convolutions. when you have
 

3471
01:23:09,840 --> 01:23:12,310
really long convolutions. when you have
when your convolutions are small, it

3472
01:23:12,310 --> 01:23:12,320
when your convolutions are small, it
 

3473
01:23:12,320 --> 01:23:13,510
when your convolutions are small, it
doesn't make that much of a difference

3474
01:23:13,510 --> 01:23:13,520
doesn't make that much of a difference
 

3475
01:23:13,520 --> 01:23:16,550
doesn't make that much of a difference
to just do it straight as a convolution.

3476
01:23:16,550 --> 01:23:16,560
to just do it straight as a convolution.
 

3477
01:23:16,560 --> 01:23:18,310
to just do it straight as a convolution.
And so the gains weren't enough to

3478
01:23:18,310 --> 01:23:18,320
And so the gains weren't enough to
 

3479
01:23:18,320 --> 01:23:20,390
And so the gains weren't enough to
really use this that much in in

3480
01:23:20,390 --> 01:23:20,400
really use this that much in in
 

3481
01:23:20,400 --> 01:23:22,149
really use this that much in in
convolutional neural nets, but in in

3482
01:23:22,149 --> 01:23:22,159
convolutional neural nets, but in in
 

3483
01:23:22,159 --> 01:23:25,189
convolutional neural nets, but in in
state space land, uh that starts to that

3484
01:23:25,189 --> 01:23:25,199
state space land, uh that starts to that
 

3485
01:23:25,199 --> 01:23:28,229
state space land, uh that starts to that
starts to really matter.

3486
01:23:28,229 --> 01:23:28,239
starts to really matter.
 

3487
01:23:28,239 --> 01:23:31,910
starts to really matter.
So in summary, uh state space models are

3488
01:23:31,910 --> 01:23:31,920
So in summary, uh state space models are
 

3489
01:23:31,920 --> 01:23:34,149
So in summary, uh state space models are
nice because you know in train time you

3490
01:23:34,149 --> 01:23:34,159
nice because you know in train time you
 

3491
01:23:34,159 --> 01:23:36,390
nice because you know in train time you
can do all of these things parallelly

3492
01:23:36,390 --> 01:23:36,400
can do all of these things parallelly
 

3493
01:23:36,400 --> 01:23:39,830
can do all of these things parallelly
and then at inference time this is

3494
01:23:39,830 --> 01:23:39,840
and then at inference time this is
 

3495
01:23:39,840 --> 01:23:43,030
and then at inference time this is
really easy to compute the the next

3496
01:23:43,030 --> 01:23:43,040
really easy to compute the the next
 

3497
01:23:43,040 --> 01:23:44,310
really easy to compute the the next
state, right? Because you just have

3498
01:23:44,310 --> 01:23:44,320
state, right? Because you just have
 

3499
01:23:44,320 --> 01:23:46,070
state, right? Because you just have
you've collected all of your history

3500
01:23:46,070 --> 01:23:46,080
you've collected all of your history
 

3501
01:23:46,080 --> 01:23:48,790
you've collected all of your history
into this h of t. To compute h of t plus

3502
01:23:48,790 --> 01:23:48,800
into this h of t. To compute h of t plus
 

3503
01:23:48,800 --> 01:23:52,390
into this h of t. To compute h of t plus
one, you just do a h of t minus one plus

3504
01:23:52,390 --> 01:23:52,400
one, you just do a h of t minus one plus
 

3505
01:23:52,400 --> 01:23:56,629
one, you just do a h of t minus one plus
the input. So uh at inference time these

3506
01:23:56,629 --> 01:23:56,639
the input. So uh at inference time these
 

3507
01:23:56,639 --> 01:23:58,629
the input. So uh at inference time these
are these are quick to update as well

3508
01:23:58,629 --> 01:23:58,639
are these are quick to update as well
 

3509
01:23:58,639 --> 01:24:00,470
are these are quick to update as well
right so you you're not even doing

3510
01:24:00,470 --> 01:24:00,480
right so you you're not even doing
 

3511
01:24:00,480 --> 01:24:03,189
right so you you're not even doing
convolutions at inference time

3512
01:24:03,189 --> 01:24:03,199
convolutions at inference time
 

3513
01:24:03,199 --> 01:24:04,709
convolutions at inference time
because all of your history is captured

3514
01:24:04,709 --> 01:24:04,719
because all of your history is captured
 

3515
01:24:04,719 --> 01:24:07,030
because all of your history is captured
into this one uh one hidden state. So

3516
01:24:07,030 --> 01:24:07,040
into this one uh one hidden state. So
 

3517
01:24:07,040 --> 01:24:09,110
into this one uh one hidden state. So
they can be cheaper than other models to

3518
01:24:09,110 --> 01:24:09,120
they can be cheaper than other models to
 

3519
01:24:09,120 --> 01:24:11,110
they can be cheaper than other models to
implement at inference time as well. So

3520
01:24:11,110 --> 01:24:11,120
implement at inference time as well. So
 

3521
01:24:11,120 --> 01:24:14,550
implement at inference time as well. So
I will stop at that because uh and uh if

3522
01:24:14,550 --> 01:24:14,560
I will stop at that because uh and uh if
 

3523
01:24:14,560 --> 01:24:15,830
I will stop at that because uh and uh if
there's a last question I can take it.

3524
01:24:15,830 --> 01:24:15,840
there's a last question I can take it.
 

3525
01:24:15,840 --> 01:24:18,709
there's a last question I can take it.
If not we will continue uh Thursday. Any

3526
01:24:18,709 --> 01:24:18,719
If not we will continue uh Thursday. Any
 

3527
01:24:18,719 --> 01:24:23,189
If not we will continue uh Thursday. Any
questions?

3528
01:24:23,189 --> 01:24:23,199

 

3529
01:24:23,199 --> 01:24:32,550

Okay, great. And see you Thursday.

3530
01:24:32,550 --> 01:24:32,560

 

3531
01:24:32,560 --> 01:24:35,560

>> Yeah.

